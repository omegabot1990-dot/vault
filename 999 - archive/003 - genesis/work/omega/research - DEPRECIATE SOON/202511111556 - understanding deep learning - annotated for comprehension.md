---
tags:
  - work
aliases:
  - Understanding Deep Learning
title: understanding deep learning - annotated for comprehension
description: all things deep learning
parent nodes:
  - "[[research]]"
child nodes:
annotation-target: understanding_deep_learning.pdf
---



>%%
>```annotation-json
>{"created":"2025-11-11T15:05:55.613Z","updated":"2025-11-11T15:05:55.613Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":471670,"end":471762},{"type":"TextQuoteSelector","exact":"number of input variables can be very large, and thestatistics are similar at every position","prefix":"racteristics of image data. The ","suffix":"; it’s not sensible to re-learn "}]}]}
>```
>%%
>*%%PREFIX%%racteristics of image data. The%%HIGHLIGHT%% ==number of input variables can be very large, and thestatistics are similar at every position== %%POSTFIX%%; it’s not sensible to re-learn*
>%%LINK%%[[#^0qmos9kruv1|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0qmos9kruv1


>%%
>```annotation-json
>{"created":"2025-11-11T15:06:30.926Z","updated":"2025-11-11T15:06:30.926Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":471921,"end":471949},{"type":"TextQuoteSelector","exact":"ext sequences vary in length","prefix":"sets havethe complication that t","suffix":", and unlike images, there is no"}]}]}
>```
>%%
>*%%PREFIX%%sets havethe complication that t%%HIGHLIGHT%% ==ext sequences vary in length== %%POSTFIX%%, and unlike images, there is no*
>%%LINK%%[[#^sie6xs9t7o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^sie6xs9t7o


>%%
>```annotation-json
>{"created":"2025-11-11T15:06:38.016Z","updated":"2025-11-11T15:06:38.016Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":471980,"end":472004},{"type":"TextQuoteSelector","exact":"o easyway to resize them","prefix":"h, and unlike images, there is n","suffix":".12.1 Processing text dataTo mot"}]}]}
>```
>%%
>*%%PREFIX%%h, and unlike images, there is n%%HIGHLIGHT%% ==o easyway to resize them== %%POSTFIX%%.12.1 Processing text dataTo mot*
>%%LINK%%[[#^43k4nmc3mri|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^43k4nmc3mri


>%%
>```annotation-json
>{"created":"2025-11-11T15:09:07.973Z","text":"The properties, relationships, and significance of individual words or tokens remain relatively constant regardless of their location in a sentence or body of text.","updated":"2025-11-11T15:09:07.973Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":471722,"end":471762},{"type":"TextQuoteSelector","exact":"statistics are similar at every position","prefix":"ables can be very large, and the","suffix":"; it’s not sensible to re-learn "}]}]}
>```
>%%
>*%%PREFIX%%ables can be very large, and the%%HIGHLIGHT%% ==statistics are similar at every position== %%POSTFIX%%; it’s not sensible to re-learn*
>%%LINK%%[[#^6rlbcwy1lq4|show annotation]]
>%%COMMENT%%
>The properties, relationships, and significance of individual words or tokens remain relatively constant regardless of their location in a sentence or body of text.
>%%TAGS%%
>
^6rlbcwy1lq4


>%%
>```annotation-json
>{"created":"2025-11-11T15:11:38.927Z","updated":"2025-11-11T15:11:38.927Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":472284,"end":472386},{"type":"TextQuoteSelector","exact":"The goal is to design a network to process this text into a representation suitable fordownstream task","prefix":" as goodas the food and service.","suffix":"s. For example, it might be used"}]}]}
>```
>%%
>*%%PREFIX%%as goodas the food and service.%%HIGHLIGHT%% ==The goal is to design a network to process this text into a representation suitable fordownstream task== %%POSTFIX%%s. For example, it might be used*
>%%LINK%%[[#^iv2lizmyoz9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^iv2lizmyoz9


>%%
>```annotation-json
>{"created":"2025-11-11T15:13:08.402Z","updated":"2025-11-11T15:13:08.402Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":472813,"end":472942},{"type":"TextQuoteSelector","exact":"ealistically sized body of text might have hundreds oreven thousands of words, so fully connected neural networks are impractical","prefix":"for this small passage. A more r","suffix":".Draft: please send errata to ud"}]}]}
>```
>%%
>*%%PREFIX%%for this small passage. A more r%%HIGHLIGHT%% ==ealistically sized body of text might have hundreds oreven thousands of words, so fully connected neural networks are impractical== %%POSTFIX%%.Draft: please send errata to ud*
>%%LINK%%[[#^sq2shvij0j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^sq2shvij0j


>%%
>```annotation-json
>{"created":"2025-11-11T15:13:24.172Z","updated":"2025-11-11T15:13:24.172Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":473123,"end":473139},{"type":"TextQuoteSelector","exact":"different length","prefix":" (one ormore sentences) is of a ","suffix":"; hence, it’s not even obvious h"}]}]}
>```
>%%
>*%%PREFIX%%(one ormore sentences) is of a%%HIGHLIGHT%% ==different length== %%POSTFIX%%; hence, it’s not even obvious h*
>%%LINK%%[[#^v5pxpyw843|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^v5pxpyw843


>%%
>```annotation-json
>{"created":"2025-11-11T15:13:57.866Z","updated":"2025-11-11T15:13:57.866Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":473209,"end":473407},{"type":"TextQuoteSelector","exact":"These observations suggest that the network should share parametersacross words at different input positions, similarly to how convolutional networks shareparameters across different image positions","prefix":"apply a fullyconnected network. ","suffix":".Third, language is ambiguous; i"}]}]}
>```
>%%
>*%%PREFIX%%apply a fullyconnected network.%%HIGHLIGHT%% ==These observations suggest that the network should share parametersacross words at different input positions, similarly to how convolutional networks shareparameters across different image positions== %%POSTFIX%%.Third, language is ambiguous; i*
>%%LINK%%[[#^jhuku1ppnk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jhuku1ppnk


>%%
>```annotation-json
>{"created":"2025-11-11T15:15:06.655Z","updated":"2025-11-11T15:15:06.655Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":472585,"end":472624},{"type":"TextQuoteSelector","exact":"ncoded input can be surpris-ingly large","prefix":"diate observations. First, the e","suffix":". In this case, each of the 37 w"}]}]}
>```
>%%
>*%%PREFIX%%diate observations. First, the e%%HIGHLIGHT%% ==ncoded input can be surpris-ingly large== %%POSTFIX%%. In this case, each of the 37 w*
>%%LINK%%[[#^g4olfhubtp|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^g4olfhubtp


>%%
>```annotation-json
>{"created":"2025-11-11T15:15:22.445Z","updated":"2025-11-11T15:15:22.445Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":473415,"end":473435},{"type":"TextQuoteSelector","exact":"language is ambiguou","prefix":"ifferent image positions.Third, ","suffix":"s; it is unclear from the syntax"}]}]}
>```
>%%
>*%%PREFIX%%ifferent image positions.Third,%%HIGHLIGHT%% ==language is ambiguou== %%POSTFIX%%s; it is unclear from the syntax*
>%%LINK%%[[#^ugxe8hoy2w|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ugxe8hoy2w


>%%
>```annotation-json
>{"created":"2025-11-11T15:15:41.480Z","updated":"2025-11-11T15:15:41.480Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":473693,"end":473702},{"type":"TextQuoteSelector","exact":"attention","prefix":"mers,the former word should pay ","suffix":" to the latter. This implies tha"}]}]}
>```
>%%
>*%%PREFIX%%mers,the former word should pay%%HIGHLIGHT%% ==attention== %%POSTFIX%%to the latter. This implies tha*
>%%LINK%%[[#^qsty4z5a1v|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qsty4z5a1v


>%%
>```annotation-json
>{"created":"2025-11-11T15:15:52.313Z","updated":"2025-11-11T15:15:52.313Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":473437,"end":473472},{"type":"TextQuoteSelector","exact":" it is unclear from the syntax alon","prefix":"ns.Third, language is ambiguous;","suffix":"e that the pronoun itrefers to t"}]}]}
>```
>%%
>*%%PREFIX%%ns.Third, language is ambiguous;%%HIGHLIGHT%% ==it is unclear from the syntax alon== %%POSTFIX%%e that the pronoun itrefers to t*
>%%LINK%%[[#^s0rq9vi8yy|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^s0rq9vi8yy


>%%
>```annotation-json
>{"created":"2025-11-11T15:16:16.885Z","updated":"2025-11-11T15:16:16.885Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":473737,"end":473856},{"type":"TextQuoteSelector","exact":"here must beconnections between the words and that the strength of these connections will dependon the words themselves","prefix":" the latter. This implies that t","suffix":". Moreover, these connections ne"}]}]}
>```
>%%
>*%%PREFIX%%the latter. This implies that t%%HIGHLIGHT%% ==here must beconnections between the words and that the strength of these connections will dependon the words themselves== %%POSTFIX%%. Moreover, these connections ne*
>%%LINK%%[[#^ddwy9ckwq88|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ddwy9ckwq88


>%%
>```annotation-json
>{"created":"2025-11-11T15:16:26.047Z","updated":"2025-11-11T15:16:26.047Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":473874,"end":473923},{"type":"TextQuoteSelector","exact":"connections need to extend across large textspans","prefix":"rds themselves. Moreover, these ","suffix":". For example, the word their in"}]}]}
>```
>%%
>*%%PREFIX%%rds themselves. Moreover, these%%HIGHLIGHT%% ==connections need to extend across large textspans== %%POSTFIX%%. For example, the word their in*
>%%LINK%%[[#^wag5a5z504d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wag5a5z504d


>%%
>```annotation-json
>{"created":"2025-11-11T15:18:02.871Z","updated":"2025-11-11T15:18:02.871Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":473148,"end":473207},{"type":"TextQuoteSelector","exact":"it’s not even obvious how to apply a fullyconnected network","prefix":"s of a different length; hence, ","suffix":". These observations suggest tha"}]}]}
>```
>%%
>*%%PREFIX%%s of a different length; hence,%%HIGHLIGHT%% ==it’s not even obvious how to apply a fullyconnected network== %%POSTFIX%%. These observations suggest tha*
>%%LINK%%[[#^pclyootuqk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^pclyootuqk


>%%
>```annotation-json
>{"created":"2025-11-11T15:30:27.369Z","text":"1. Input embedding is large\n2. The sizes of the inputs are of different lengths\n3. Language is ambiguous","updated":"2025-11-11T15:30:27.369Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":472010,"end":472030},{"type":"TextQuoteSelector","exact":"Processing text data","prefix":" no easyway to resize them.12.1 ","suffix":"To motivate the transformer, con"}]}]}
>```
>%%
>*%%PREFIX%%no easyway to resize them.12.1%%HIGHLIGHT%% ==Processing text data== %%POSTFIX%%To motivate the transformer, con*
>%%LINK%%[[#^yuyy7e6jjs|show annotation]]
>%%COMMENT%%
>1. Input embedding is large
>2. The sizes of the inputs are of different lengths
>3. Language is ambiguous
>%%TAGS%%
>
^yuyy7e6jjs


>%%
>```annotation-json
>{"created":"2025-11-11T15:38:15.740Z","updated":"2025-11-11T15:38:15.740Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":474105,"end":474179},{"type":"TextQuoteSelector","exact":"use parametersharing to cope with long input passages of differing lengths","prefix":"el for processing text will (i) ","suffix":" and (ii) contain connectionsbet"}]}]}
>```
>%%
>*%%PREFIX%%el for processing text will (i)%%HIGHLIGHT%% ==use parametersharing to cope with long input passages of differing lengths== %%POSTFIX%%and (ii) contain connectionsbet*
>%%LINK%%[[#^u86ndzhb40l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^u86ndzhb40l


>%%
>```annotation-json
>{"created":"2025-11-11T15:38:23.611Z","updated":"2025-11-11T15:38:23.611Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":474189,"end":474271},{"type":"TextQuoteSelector","exact":"contain connectionsbetween word representations that depend on the words themselve","prefix":"s of differing lengths and (ii) ","suffix":"s. The transformeracquires both "}]}]}
>```
>%%
>*%%PREFIX%%s of differing lengths and (ii)%%HIGHLIGHT%% ==contain connectionsbetween word representations that depend on the words themselve== %%POSTFIX%%s. The transformeracquires both*
>%%LINK%%[[#^zw1ssxdbte|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zw1ssxdbte


>%%
>```annotation-json
>{"created":"2025-11-11T15:38:28.413Z","updated":"2025-11-11T15:38:28.413Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":474323,"end":474349},{"type":"TextQuoteSelector","exact":"dot-product self-attention","prefix":"quires both properties by using ","suffix":".A standard neural network layer"}]}]}
>```
>%%
>*%%PREFIX%%quires both properties by using%%HIGHLIGHT%% ==dot-product self-attention== %%POSTFIX%%.A standard neural network layer*
>%%LINK%%[[#^88yn3cxyge|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^88yn3cxyge


>%%
>```annotation-json
>{"created":"2025-11-11T15:38:32.829Z","updated":"2025-11-11T15:38:32.829Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":474495,"end":474513},{"type":"TextQuoteSelector","exact":"f[x] = ReLU[β + Ωx","prefix":"vation function like a ReLU, so:","suffix":"], (12.1)where β contains the bi"}]}]}
>```
>%%
>*%%PREFIX%%vation function like a ReLU, so:%%HIGHLIGHT%% ==f[x] = ReLU[β + Ωx== %%POSTFIX%%], (12.1)where β contains the bi*
>%%LINK%%[[#^r1hqdwofb4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r1hqdwofb4


>%%
>```annotation-json
>{"created":"2025-11-11T15:38:43.487Z","updated":"2025-11-11T15:38:43.487Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":474578,"end":474702},{"type":"TextQuoteSelector","exact":"A self-attention block sa[•] takes N inputs x1,...,xN , each of dimension D ×1, andreturns N output vectors of the same size","prefix":"ses, and Ω contains the weights.","suffix":". In the context of NLP, each in"}]}]}
>```
>%%
>*%%PREFIX%%ses, and Ω contains the weights.%%HIGHLIGHT%% ==A self-attention block sa[•] takes N inputs x1,...,xN , each of dimension D ×1, andreturns N output vectors of the same size== %%POSTFIX%%. In the context of NLP, each in*
>%%LINK%%[[#^qo5rqz1zt3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qo5rqz1zt3


>%%
>```annotation-json
>{"created":"2025-11-11T15:38:55.524Z","updated":"2025-11-11T15:38:55.524Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":474780,"end":474823},{"type":"TextQuoteSelector","exact":"a set of values are computed for each input","prefix":"a word or word fragment. First, ","suffix":":vm = βv + Ωvxm, (12.2)where βv "}]}]}
>```
>%%
>*%%PREFIX%%a word or word fragment. First,%%HIGHLIGHT%% ==a set of values are computed for each input== %%POSTFIX%%:vm = βv + Ωvxm, (12.2)where βv*
>%%LINK%%[[#^yodtb1qxt8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yodtb1qxt8


>%%
>```annotation-json
>{"created":"2025-11-11T15:38:59.717Z","updated":"2025-11-11T15:38:59.717Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":474824,"end":474838},{"type":"TextQuoteSelector","exact":"vm = βv + Ωvxm","prefix":"ues are computed for each input:","suffix":", (12.2)where βv ∈RD×1 and Ωv ∈R"}]}]}
>```
>%%
>*%%PREFIX%%ues are computed for each input:%%HIGHLIGHT%% ==vm = βv + Ωvxm== %%POSTFIX%%, (12.2)where βv ∈RD×1 and Ωv ∈R*
>%%LINK%%[[#^zx89ah2lsel|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zx89ah2lsel


>%%
>```annotation-json
>{"created":"2025-11-11T15:39:18.491Z","updated":"2025-11-11T15:39:18.491Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":474917,"end":474998},{"type":"TextQuoteSelector","exact":"Then the nth output san[x1,...,xN ] is a weighted sum of all the values v1,...,vN","prefix":"iases and weights, respectively.","suffix":" :san[x1,...,xN ] =N∑m=1a[xm,xn]"}]}]}
>```
>%%
>*%%PREFIX%%iases and weights, respectively.%%HIGHLIGHT%% ==Then the nth output san[x1,...,xN ] is a weighted sum of all the values v1,...,vN== %%POSTFIX%%:san[x1,...,xN ] =N∑m=1a[xm,xn]*
>%%LINK%%[[#^i358pe7kzub|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^i358pe7kzub


>%%
>```annotation-json
>{"created":"2025-11-11T15:39:42.985Z","updated":"2025-11-11T15:39:42.985Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":475000,"end":475032},{"type":"TextQuoteSelector","exact":"san[x1,...,xN ] =N∑m=1a[xm,xn]vm","prefix":"um of all the values v1,...,vN :","suffix":". (12.3)The scalar weight a[xm,x"}]}]}
>```
>%%
>*%%PREFIX%%um of all the values v1,...,vN :%%HIGHLIGHT%% ==san[x1,...,xN ] =N∑m=1a[xm,xn]vm== %%POSTFIX%%. (12.3)The scalar weight a[xm,x*
>%%LINK%%[[#^9nlncf7cdcf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9nlncf7cdcf


>%%
>```annotation-json
>{"created":"2025-11-11T15:39:50.272Z","updated":"2025-11-11T15:39:50.272Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":475040,"end":475120},{"type":"TextQuoteSelector","exact":"The scalar weight a[xm,xn] is the attention that the nth output pays to input xm","prefix":"..,xN ] =N∑m=1a[xm,xn]vm. (12.3)","suffix":". The Nweights a[•,xn] are non-n"}]}]}
>```
>%%
>*%%PREFIX%%..,xN ] =N∑m=1a[xm,xn]vm. (12.3)%%HIGHLIGHT%% ==The scalar weight a[xm,xn] is the attention that the nth output pays to input xm== %%POSTFIX%%. The Nweights a[•,xn] are non-n*
>%%LINK%%[[#^0jkbyd4xkqun|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0jkbyd4xkqun


>%%
>```annotation-json
>{"created":"2025-11-11T15:39:55.307Z","updated":"2025-11-11T15:39:55.307Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":475122,"end":475174},{"type":"TextQuoteSelector","exact":"The Nweights a[•,xn] are non-negative and sum to one","prefix":"he nth output pays to input xm. ","suffix":". Hence, self-attention can be t"}]}]}
>```
>%%
>*%%PREFIX%%he nth output pays to input xm.%%HIGHLIGHT%% ==The Nweights a[•,xn] are non-negative and sum to one== %%POSTFIX%%. Hence, self-attention can be t*
>%%LINK%%[[#^36yfar3e8nw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^36yfar3e8nw


>%%
>```annotation-json
>{"created":"2025-11-11T15:40:07.684Z","updated":"2025-11-11T15:40:07.684Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":475218,"end":475283},{"type":"TextQuoteSelector","exact":"routing the values in different proportions to create each output","prefix":"f-attention can be thoughtof as ","suffix":" (figure 12.1).The following sec"}]}]}
>```
>%%
>*%%PREFIX%%f-attention can be thoughtof as%%HIGHLIGHT%% ==routing the values in different proportions to create each output== %%POSTFIX%%(figure 12.1).The following sec*
>%%LINK%%[[#^x150ljiz9ms|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^x150ljiz9ms


>%%
>```annotation-json
>{"created":"2025-11-11T15:42:42.451Z","text":"Why self-attention?\n1. Parameter sharing because of long inputs of different lengths\n2. Connection between input representations depending on the inputs\n\nThe nth output is the weighted sum of all the values from 1 to N.\n$a[x_m, x_n]$ is the **attention** the nth output pays to the input $x_m$ .\nSelf-attention is basically **routing**.\n\n","updated":"2025-11-11T15:42:42.451Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":474009,"end":474035},{"type":"TextQuoteSelector","exact":"Dot-product self-attention","prefix":"o refers to the restaurant.12.2 ","suffix":"The previous section argued that"}]}]}
>```
>%%
>*%%PREFIX%%o refers to the restaurant.12.2%%HIGHLIGHT%% ==Dot-product self-attention== %%POSTFIX%%The previous section argued that*
>%%LINK%%[[#^5knn2mz6wge|show annotation]]
>%%COMMENT%%
>Why self-attention?
>1. Parameter sharing because of long inputs of different lengths
>2. Connection between input representations depending on the inputs
>
>The nth output is the weighted sum of all the values from 1 to N.
>$a[x_m, x_n]$ is the **attention** the nth output pays to the input $x_m$ .
>Self-attention is basically **routing**.
>
>
>%%TAGS%%
>
^5knn2mz6wge


>%%
>```annotation-json
>{"created":"2025-11-11T15:54:17.231Z","updated":"2025-11-11T15:54:17.231Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":476458,"end":476529},{"type":"TextQuoteSelector","exact":"ame weights Ωv ∈RD×D and biases βv ∈RD are appliedto each input xn ∈ RD","prefix":"esEquation 12.2 shows that the s","suffix":". This computation scales linear"}]}]}
>```
>%%
>*%%PREFIX%%esEquation 12.2 shows that the s%%HIGHLIGHT%% ==ame weights Ωv ∈RD×D and biases βv ∈RD are appliedto each input xn ∈ RD== %%POSTFIX%%. This computation scales linear*
>%%LINK%%[[#^0qg6lcsfry99|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0qg6lcsfry99


>%%
>```annotation-json
>{"created":"2025-11-11T15:54:25.888Z","updated":"2025-11-11T15:54:25.888Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":476537,"end":476590},{"type":"TextQuoteSelector","exact":"omputation scales linearly with the sequence length N","prefix":"iedto each input xn ∈ RD. This c","suffix":",so it requires fewer parameters"}]}]}
>```
>%%
>*%%PREFIX%%iedto each input xn ∈ RD. This c%%HIGHLIGHT%% ==omputation scales linearly with the sequence length N== %%POSTFIX%%,so it requires fewer parameters*
>%%LINK%%[[#^0stezengxyc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0stezengxyc


>%%
>```annotation-json
>{"created":"2025-11-11T15:54:36.982Z","updated":"2025-11-11T15:54:36.982Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":476736,"end":476782},{"type":"TextQuoteSelector","exact":"sparse matrix operationwith shared parameters ","prefix":" computation can be viewed as a ","suffix":"(figure 12.2b).The attention wei"}]}]}
>```
>%%
>*%%PREFIX%%computation can be viewed as a%%HIGHLIGHT%% ==sparse matrix operationwith shared parameters== %%POSTFIX%%(figure 12.2b).The attention wei*
>%%LINK%%[[#^tcogxw3gmgs|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tcogxw3gmgs


>%%
>```annotation-json
>{"created":"2025-11-11T15:55:24.971Z","updated":"2025-11-11T15:55:24.971Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":476797,"end":476868},{"type":"TextQuoteSelector","exact":"The attention weights a[xm,xn] combine the values from different inputs","prefix":"hared parameters (figure 12.2b).","suffix":". Theyare also sparse since ther"}]}]}
>```
>%%
>*%%PREFIX%%hared parameters (figure 12.2b).%%HIGHLIGHT%% ==The attention weights a[xm,xn] combine the values from different inputs== %%POSTFIX%%. Theyare also sparse since ther*
>%%LINK%%[[#^x8kwiqu9md|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^x8kwiqu9md


>%%
>```annotation-json
>{"created":"2025-11-11T15:55:37.144Z","updated":"2025-11-11T15:55:37.144Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":476883,"end":476999},{"type":"TextQuoteSelector","exact":"sparse since there is only one weight for each ordered pair of inputs (xm,xn),regardless of the size of these inputs","prefix":" different inputs. Theyare also ","suffix":" (figure 12.2c). It follows that"}]}]}
>```
>%%
>*%%PREFIX%%different inputs. Theyare also%%HIGHLIGHT%% ==sparse since there is only one weight for each ordered pair of inputs (xm,xn),regardless of the size of these inputs== %%POSTFIX%%(figure 12.2c). It follows that*
>%%LINK%%[[#^div3c24idr6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^div3c24idr6



>%%
>```annotation-json
>{"created":"2025-11-11T15:56:25.638Z","updated":"2025-11-11T15:56:25.638Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":477036,"end":477055},{"type":"TextQuoteSelector","exact":"number of attention","prefix":"ure 12.2c). It follows that the ","suffix":" Problem 12.1weights has a quadr"}]}]}
>```
>%%
>*%%PREFIX%%ure 12.2c). It follows that the%%HIGHLIGHT%% ==number of attention== %%POSTFIX%%Problem 12.1weights has a quadr*
>%%LINK%%[[#^kt2ie8rnz6j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kt2ie8rnz6j


>%%
>```annotation-json
>{"created":"2025-11-11T15:56:30.146Z","updated":"2025-11-11T15:56:30.146Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":477068,"end":477179},{"type":"TextQuoteSelector","exact":"weights has a quadratic dependence on the sequence length N, but is independent of thelength D of each input xn","prefix":"number of attention Problem 12.1","suffix":".12.2.2 Computing attention weig"}]}]}
>```
>%%
>*%%PREFIX%%number of attention Problem 12.1%%HIGHLIGHT%% ==weights has a quadratic dependence on the sequence length N, but is independent of thelength D of each input xn== %%POSTFIX%%.12.2.2 Computing attention weig*
>%%LINK%%[[#^n7chzypuq1|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^n7chzypuq1


>%%
>```annotation-json
>{"created":"2025-11-11T15:59:53.327Z","text":"The value computation scales **linearly** with sequence length N.\nThis makes it a sparse matrix operation with shared parameters.\nThe attention matrix scales **quadratically** with sequence length N.\nThis is also a sparse matrix because each ordered input pair $(x_m, x_n)$ has one weight.\n\n","updated":"2025-11-11T15:59:53.327Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":476398,"end":476428},{"type":"TextQuoteSelector","exact":"Computing and weighting values","prefix":" routing of the N values.12.2.1 ","suffix":"Equation 12.2 shows that the sam"}]}]}
>```
>%%
>*%%PREFIX%%routing of the N values.12.2.1%%HIGHLIGHT%% ==Computing and weighting values== %%POSTFIX%%Equation 12.2 shows that the sam*
>%%LINK%%[[#^4ub45lteaw8|show annotation]]
>%%COMMENT%%
>The value computation scales **linearly** with sequence length N.
>This makes it a sparse matrix operation with shared parameters.
>The attention matrix scales **quadratically** with sequence length N.
>This is also a sparse matrix because each ordered input pair $(x_m, x_n)$ has one weight.
>
>
>%%TAGS%%
>
^4ub45lteaw8


>%%
>```annotation-json
>{"created":"2025-11-11T16:07:16.569Z","updated":"2025-11-11T16:07:16.569Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":477510,"end":477519},{"type":"TextQuoteSelector","exact":"nonlinear","prefix":"l self-attention computation is ","suffix":". As we’ll see shortly, the atte"}]}]}
>```
>%%
>*%%PREFIX%%l self-attention computation is%%HIGHLIGHT%% ==nonlinear== %%POSTFIX%%. As we’ll see shortly, the atte*
>%%LINK%%[[#^kz4ui7mhpvk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kz4ui7mhpvk


>%%
>```annotation-json
>{"created":"2025-11-11T16:07:32.791Z","updated":"2025-11-11T16:07:32.791Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":477637,"end":477706},{"type":"TextQuoteSelector","exact":"hypernetwork,where one network branch computes the weights of another","prefix":" input. This is an example of a ","suffix":".Draft: please send errata to ud"}]}]}
>```
>%%
>*%%PREFIX%%input. This is an example of a%%HIGHLIGHT%% ==hypernetwork,where one network branch computes the weights of another== %%POSTFIX%%.Draft: please send errata to ud*
>%%LINK%%[[#^mfcfkrxc3p|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mfcfkrxc3p


>%%
>```annotation-json
>{"created":"2025-11-11T16:07:41.088Z","updated":"2025-11-11T16:07:41.088Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":478400,"end":478414},{"type":"TextQuoteSelector","exact":"qn = βq + Ωqxn","prefix":"r transformations to the inputs:","suffix":"km = βk + Ωkxm, (12.4)where {qn}"}]}]}
>```
>%%
>*%%PREFIX%%r transformations to the inputs:%%HIGHLIGHT%% ==qn = βq + Ωqxn== %%POSTFIX%%km = βk + Ωkxm, (12.4)where {qn}*
>%%LINK%%[[#^g7gl5lutk5v|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^g7gl5lutk5v


>%%
>```annotation-json
>{"created":"2025-11-11T16:07:44.697Z","updated":"2025-11-11T16:07:44.697Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":478414,"end":478428},{"type":"TextQuoteSelector","exact":"km = βk + Ωkxm","prefix":"ons to the inputs:qn = βq + Ωqxn","suffix":", (12.4)where {qn} and {km} are "}]}]}
>```
>%%
>*%%PREFIX%%ons to the inputs:qn = βq + Ωqxn%%HIGHLIGHT%% ==km = βk + Ωkxm== %%POSTFIX%%, (12.4)where {qn} and {km} are*
>%%LINK%%[[#^8sfdhtm5t7n|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8sfdhtm5t7n


>%%
>```annotation-json
>{"created":"2025-11-11T16:07:50.315Z","updated":"2025-11-11T16:07:50.315Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":478442,"end":478483},{"type":"TextQuoteSelector","exact":"{qn} and {km} are termed queries and keys","prefix":"Ωqxnkm = βk + Ωkxm, (12.4)where ","suffix":", respectively. Then we compute "}]}]}
>```
>%%
>*%%PREFIX%%Ωqxnkm = βk + Ωkxm, (12.4)where%%HIGHLIGHT%% =={qn} and {km} are termed queries and keys== %%POSTFIX%%, respectively. Then we compute*
>%%LINK%%[[#^keb3bxobj98|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^keb3bxobj98


>%%
>```annotation-json
>{"created":"2025-11-11T16:07:58.847Z","updated":"2025-11-11T16:07:58.847Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":478630,"end":478655},{"type":"TextQuoteSelector","exact":"a[xm,xn] = softmaxm[kT•qn","prefix":"ults through a softmax function:","suffix":"]= exp [kTmqn]∑Nm′=1 exp [kTm′qn"}]}]}
>```
>%%
>*%%PREFIX%%ults through a softmax function:%%HIGHLIGHT%% ==a[xm,xn] = softmaxm[kT•qn== %%POSTFIX%%]= exp [kTmqn]∑Nm′=1 exp [kTm′qn*
>%%LINK%%[[#^t8017qfhcfg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^t8017qfhcfg


>%%
>```annotation-json
>{"created":"2025-11-11T16:08:02.656Z","updated":"2025-11-11T16:08:02.656Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":478656,"end":478688},{"type":"TextQuoteSelector","exact":"= exp [kTmqn]∑Nm′=1 exp [kTm′qn]","prefix":"ction:a[xm,xn] = softmaxm[kT•qn]","suffix":", (12.5)so for each xn, they are"}]}]}
>```
>%%
>*%%PREFIX%%ction:a[xm,xn] = softmaxm[kT•qn]%%HIGHLIGHT%% === exp [kTmqn]∑Nm′=1 exp [kTm′qn]== %%POSTFIX%%, (12.5)so for each xn, they are*
>%%LINK%%[[#^7oih9oiqewg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7oih9oiqewg


>%%
>```annotation-json
>{"created":"2025-11-11T16:08:33.868Z","updated":"2025-11-11T16:08:33.868Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":478948,"end":479125},{"type":"TextQuoteSelector","exact":"the dot product operation returns a measure ofsimilarity between its inputs, so the weights a[x•,xn] depend on the relative similaritiesbetween the nth query and all of the keys","prefix":"e the following interpretation: ","suffix":". The softmax function means tha"}]}]}
>```
>%%
>*%%PREFIX%%e the following interpretation:%%HIGHLIGHT%% ==the dot product operation returns a measure ofsimilarity between its inputs, so the weights a[x•,xn] depend on the relative similaritiesbetween the nth query and all of the keys== %%POSTFIX%%. The softmax function means tha*
>%%LINK%%[[#^w2goc1n4r7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w2goc1n4r7


>%%
>```annotation-json
>{"created":"2025-11-11T16:08:48.388Z","updated":"2025-11-11T16:08:48.388Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":479236,"end":479285},{"type":"TextQuoteSelector","exact":"The queries andkeys must have the same dimensions","prefix":"contribute to the final result. ","suffix":". However, these can differ from"}]}]}
>```
>%%
>*%%PREFIX%%contribute to the final result.%%HIGHLIGHT%% ==The queries andkeys must have the same dimensions== %%POSTFIX%%. However, these can differ from*
>%%LINK%%[[#^j1pp705qqy|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^j1pp705qqy


>%%
>```annotation-json
>{"created":"2025-11-11T16:09:08.307Z","updated":"2025-11-11T16:09:08.307Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":479815,"end":479866},{"type":"TextQuoteSelector","exact":"values, which is usually the same size as the input","prefix":"se matrix from figure 12.2c.the ","suffix":", so the representation doesn’t "}]}]}
>```
>%%
>*%%PREFIX%%se matrix from figure 12.2c.the%%HIGHLIGHT%% ==values, which is usually the same size as the input== %%POSTFIX%%, so the representation doesn’t*
>%%LINK%%[[#^hdy0dpacbdk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hdy0dpacbdk


>%%
>```annotation-json
>{"created":"2025-11-11T16:09:12.944Z","updated":"2025-11-11T16:09:12.944Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":479869,"end":479921},{"type":"TextQuoteSelector","exact":"o the representation doesn’t Problem 12.2change size","prefix":"ly the same size as the input, s","suffix":".12.2.3 Self-attention summaryTh"}]}]}
>```
>%%
>*%%PREFIX%%ly the same size as the input, s%%HIGHLIGHT%% ==o the representation doesn’t Problem 12.2change size== %%POSTFIX%%.12.2.3 Self-attention summaryTh*
>%%LINK%%[[#^05lxlicj7jzh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^05lxlicj7jzh


>%%
>```annotation-json
>{"created":"2025-11-11T16:09:34.556Z","text":"Overall, self-attention computation is **non-linear**.\nIt is a *hypernetwork*.\nQueries and Keys have the same dimensions and are linear transformations, the dot-product of which is passed through a **softmax** function (non-linearity). \nValues typically have the same dimensions as the input.\n","updated":"2025-11-11T16:09:34.556Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":477187,"end":477214},{"type":"TextQuoteSelector","exact":"Computing attention weights","prefix":"ength D of each input xn.12.2.2 ","suffix":"In the previous section, we saw "}]}]}
>```
>%%
>*%%PREFIX%%ength D of each input xn.12.2.2%%HIGHLIGHT%% ==Computing attention weights== %%POSTFIX%%In the previous section, we saw*
>%%LINK%%[[#^0uhgnhn3gwb|show annotation]]
>%%COMMENT%%
>Overall, self-attention computation is **non-linear**.
>It is a *hypernetwork*.
>Queries and Keys have the same dimensions and are linear transformations, the dot-product of which is passed through a **softmax** function (non-linearity). 
>Values typically have the same dimensions as the input.
>
>%%TAGS%%
>
^0uhgnhn3gwb


>%%
>```annotation-json
>{"created":"2025-11-11T16:18:39.615Z","updated":"2025-11-11T16:18:39.615Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":479951,"end":480352},{"type":"TextQuoteSelector","exact":"The nth output is a weighted sum of the same linear transformation v• = βv + Ωvx•applied to all of the inputs, where these attention weights are positive and sum to one.The weights depend on a measure of similarity between input xn and the other inputs.There is no activation function, but the mechanism is nonlinear due to the dot-productand a softmax operation used to compute the attention weights.","prefix":"ze.12.2.3 Self-attention summary","suffix":"Note that this mechanism fulfill"}]}]}
>```
>%%
>*%%PREFIX%%ze.12.2.3 Self-attention summary%%HIGHLIGHT%% ==The nth output is a weighted sum of the same linear transformation v• = βv + Ωvx•applied to all of the inputs, where these attention weights are positive and sum to one.The weights depend on a measure of similarity between input xn and the other inputs.There is no activation function, but the mechanism is nonlinear due to the dot-productand a softmax operation used to compute the attention weights.== %%POSTFIX%%Note that this mechanism fulfill*
>%%LINK%%[[#^6s8y4zkxo3o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6s8y4zkxo3o


>%%
>```annotation-json
>{"created":"2025-11-11T16:19:12.422Z","updated":"2025-11-11T16:19:12.422Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":480462,"end":480484},{"type":"TextQuoteSelector","exact":" = {βv,Ωv,βq,Ωq,βk,Ωk}","prefix":"singleshared set of parameters φ","suffix":". This is independent of theDraf"}]}]}
>```
>%%
>*%%PREFIX%%singleshared set of parameters φ%%HIGHLIGHT%% === {βv,Ωv,βq,Ωq,βk,Ωk}== %%POSTFIX%%. This is independent of theDraf*
>%%LINK%%[[#^v825kzc7lu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^v825kzc7lu


>%%
>```annotation-json
>{"created":"2025-11-11T16:19:35.404Z","updated":"2025-11-11T16:19:35.404Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":480419,"end":480462},{"type":"TextQuoteSelector","exact":"there is a singleshared set of parameters φ","prefix":"he initial requirements. First, ","suffix":" = {βv,Ωv,βq,Ωq,βk,Ωk}. This is "}]}]}
>```
>%%
>*%%PREFIX%%he initial requirements. First,%%HIGHLIGHT%% ==there is a singleshared set of parameters φ== %%POSTFIX%%= {βv,Ωv,βq,Ωq,βk,Ωk}. This is*
>%%LINK%%[[#^7slkj2ck19d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7slkj2ck19d


>%%
>```annotation-json
>{"created":"2025-11-11T16:19:45.828Z","updated":"2025-11-11T16:19:45.828Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":480494,"end":480512},{"type":"TextQuoteSelector","exact":"independent of the","prefix":" = {βv,Ωv,βq,Ωq,βk,Ωk}. This is ","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%= {βv,Ωv,βq,Ωq,βk,Ωk}. This is%%HIGHLIGHT%% ==independent of the== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^ca7ycssmwjw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ca7ycssmwjw


>%%
>```annotation-json
>{"created":"2025-11-11T16:19:50.904Z","updated":"2025-11-11T16:19:50.904Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":481119,"end":481137},{"type":"TextQuoteSelector","exact":"number of inputs N","prefix":"t of the same size as the input.","suffix":", so the network can be applied "}]}]}
>```
>%%
>*%%PREFIX%%t of the same size as the input.%%HIGHLIGHT%% ==number of inputs N== %%POSTFIX%%, so the network can be applied*
>%%LINK%%[[#^149kqlrwz7v|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^149kqlrwz7v


>%%
>```annotation-json
>{"created":"2025-11-11T16:20:07.582Z","updated":"2025-11-11T16:20:07.582Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":481208,"end":481352},{"type":"TextQuoteSelector","exact":"here are connections between the inputs (words), and the strength of these connectionsdepends on the inputs themselves via the attention weights","prefix":"erent sequence lengths. Second,t","suffix":".12.2.4 Matrix formThe above com"}]}]}
>```
>%%
>*%%PREFIX%%erent sequence lengths. Second,t%%HIGHLIGHT%% ==here are connections between the inputs (words), and the strength of these connectionsdepends on the inputs themselves via the attention weights== %%POSTFIX%%.12.2.4 Matrix formThe above com*
>%%LINK%%[[#^0j2qy6p2gqbh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0j2qy6p2gqbh


>%%
>```annotation-json
>{"created":"2025-11-11T16:21:39.869Z","text":"1. The nth output is a weighted sum based on the linear transformation and attention matrix.\n2. The weights depend on the similarity between the inputs.\n3. There is no activation function, *dot-product* and *softmax* makes it non-linear.\n4. One shared set of 6 parameters. Independent of N.\n5. The strength of the connection between words is related via attention weights.","updated":"2025-11-11T16:21:39.869Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":479929,"end":479951},{"type":"TextQuoteSelector","exact":"Self-attention summary","prefix":" Problem 12.2change size.12.2.3 ","suffix":"The nth output is a weighted sum"}]}]}
>```
>%%
>*%%PREFIX%%Problem 12.2change size.12.2.3%%HIGHLIGHT%% ==Self-attention summary== %%POSTFIX%%The nth output is a weighted sum*
>%%LINK%%[[#^pjjd2b99sjp|show annotation]]
>%%COMMENT%%
>1. The nth output is a weighted sum based on the linear transformation and attention matrix.
>2. The weights depend on the similarity between the inputs.
>3. There is no activation function, *dot-product* and *softmax* makes it non-linear.
>4. One shared set of 6 parameters. Independent of N.
>5. The strength of the connection between words is related via attention weights.
>%%TAGS%%
>
^pjjd2b99sjp


>%%
>```annotation-json
>{"created":"2025-11-11T16:28:28.455Z","updated":"2025-11-11T16:28:28.455Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":481532,"end":481548},{"type":"TextQuoteSelector","exact":"V[X] = βv1T+ ΩvX","prefix":"es, and keys can be computed as:","suffix":"Q[X] = βq1T+ ΩqXK[X] = βk1T+ ΩkX"}]}]}
>```
>%%
>*%%PREFIX%%es, and keys can be computed as:%%HIGHLIGHT%% ==V[X] = βv1T+ ΩvX== %%POSTFIX%%Q[X] = βq1T+ ΩqXK[X] = βk1T+ ΩkX*
>%%LINK%%[[#^t644j9m5fhq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^t644j9m5fhq


>%%
>```annotation-json
>{"created":"2025-11-11T16:28:37.748Z","updated":"2025-11-11T16:28:37.748Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":481548,"end":481564},{"type":"TextQuoteSelector","exact":"Q[X] = βq1T+ ΩqX","prefix":" be computed as:V[X] = βv1T+ ΩvX","suffix":"K[X] = βk1T+ ΩkX, (12.6)where 1 "}]}]}
>```
>%%
>*%%PREFIX%%be computed as:V[X] = βv1T+ ΩvX%%HIGHLIGHT%% ==Q[X] = βq1T+ ΩqX== %%POSTFIX%%K[X] = βk1T+ ΩkX, (12.6)where 1*
>%%LINK%%[[#^s0h2xdqya|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^s0h2xdqya


>%%
>```annotation-json
>{"created":"2025-11-11T16:29:03.532Z","updated":"2025-11-11T16:29:03.532Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":481564,"end":481580},{"type":"TextQuoteSelector","exact":"K[X] = βk1T+ ΩkX","prefix":"V[X] = βv1T+ ΩvXQ[X] = βq1T+ ΩqX","suffix":", (12.6)where 1 is an N ×1 vecto"}]}]}
>```
>%%
>*%%PREFIX%%V[X] = βv1T+ ΩvXQ[X] = βq1T+ ΩqX%%HIGHLIGHT%% ==K[X] = βk1T+ ΩkX== %%POSTFIX%%, (12.6)where 1 is an N ×1 vecto*
>%%LINK%%[[#^c56oipyh0o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c56oipyh0o


>%%
>```annotation-json
>{"created":"2025-11-11T16:30:10.810Z","updated":"2025-11-11T16:30:10.810Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":481670,"end":481702},{"type":"TextQuoteSelector","exact":"Sa[X] = V[X] ·Softmax[K[X]T Q[X]","prefix":"f-attention computation is then:","suffix":"], (12.7)This work is subject to"}]}]}
>```
>%%
>*%%PREFIX%%f-attention computation is then:%%HIGHLIGHT%% ==Sa[X] = V[X] ·Softmax[K[X]T Q[X]== %%POSTFIX%%], (12.7)This work is subject to*
>%%LINK%%[[#^hxwtc0r361j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hxwtc0r361j


>%%
>```annotation-json
>{"created":"2025-11-11T16:33:34.696Z","updated":"2025-11-11T16:33:34.696Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":482336,"end":482440},{"type":"TextQuoteSelector","exact":"unction Softmax[•] takes a matrix and performs the softmax operationindependently on each of its columns","prefix":"ses, they arelearned.where the f","suffix":" (figure 12.4). In this formulat"}]}]}
>```
>%%
>*%%PREFIX%%ses, they arelearned.where the f%%HIGHLIGHT%% ==unction Softmax[•] takes a matrix and performs the softmax operationindependently on each of its columns== %%POSTFIX%%(figure 12.4). In this formulat*
>%%LINK%%[[#^gwbmhhkwnxn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gwbmhhkwnxn


>%%
>```annotation-json
>{"created":"2025-11-11T16:34:00.827Z","updated":"2025-11-11T16:34:00.827Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":482747,"end":482771},{"type":"TextQuoteSelector","exact":"Sa[X] = V ·Softmax[KT Q]","prefix":" this dependence and just write:","suffix":". (12.8)12.3 Extensions to dot-p"}]}]}
>```
>%%
>*%%PREFIX%%this dependence and just write:%%HIGHLIGHT%% ==Sa[X] = V ·Softmax[KT Q]== %%POSTFIX%%. (12.8)12.3 Extensions to dot-p*
>%%LINK%%[[#^5421b38k80l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5421b38k80l


>%%
>```annotation-json
>{"created":"2025-11-11T16:37:14.758Z","updated":"2025-11-11T16:37:14.758Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":483177,"end":483230},{"type":"TextQuoteSelector","exact":" it is equivariant with respect to input permutations","prefix":"of the inputs xn.More precisely,","suffix":". However, order isimportant whe"}]}]}
>```
>%%
>*%%PREFIX%%of the inputs xn.More precisely,%%HIGHLIGHT%% ==it is equivariant with respect to input permutations== %%POSTFIX%%. However, order isimportant whe*
>%%LINK%%[[#^62a7m3vzxcl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^62a7m3vzxcl


>%%
>```annotation-json
>{"created":"2025-11-11T16:37:34.768Z","updated":"2025-11-11T16:37:34.768Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":483506,"end":483575},{"type":"TextQuoteSelector","exact":"A matrix Π is added to the input X that encodespositional information","prefix":".Absolute positional encodings: ","suffix":" (figure 12.5). Each column of Π"}]}]}
>```
>%%
>*%%PREFIX%%.Absolute positional encodings:%%HIGHLIGHT%% ==A matrix Π is added to the input X that encodespositional information== %%POSTFIX%%(figure 12.5). Each column of Π*
>%%LINK%%[[#^tmgchyo98be|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tmgchyo98be


>%%
>```annotation-json
>{"created":"2025-11-11T16:37:43.728Z","updated":"2025-11-11T16:37:43.728Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":483591,"end":483696},{"type":"TextQuoteSelector","exact":"Each column of Π is unique and hence containsinformation about the absolute position in the input sequenc","prefix":"onal information (figure 12.5). ","suffix":"e. This matrix can bechosen by h"}]}]}
>```
>%%
>*%%PREFIX%%onal information (figure 12.5).%%HIGHLIGHT%% ==Each column of Π is unique and hence containsinformation about the absolute position in the input sequenc== %%POSTFIX%%e. This matrix can bechosen by h*
>%%LINK%%[[#^3hk3pi5xwge|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3hk3pi5xwge


>%%
>```annotation-json
>{"created":"2025-11-11T16:37:56.068Z","updated":"2025-11-11T16:37:56.068Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":483754,"end":483805},{"type":"TextQuoteSelector","exact":"added to the network inputs or at every networklaye","prefix":"n by hand or learned. It may be ","suffix":"r. Sometimes it is added to X in"}]}]}
>```
>%%
>*%%PREFIX%%n by hand or learned. It may be%%HIGHLIGHT%% ==added to the network inputs or at every networklaye== %%POSTFIX%%r. Sometimes it is added to X in*
>%%LINK%%[[#^p7orvz72j7p|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^p7orvz72j7p


>%%
>```annotation-json
>{"created":"2025-11-11T16:38:01.328Z","updated":"2025-11-11T16:38:01.328Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":483824,"end":483898},{"type":"TextQuoteSelector","exact":"added to X in the computation of the queries and keys but notto the values","prefix":"y networklayer. Sometimes it is ","suffix":".Draft: please send errata to ud"}]}]}
>```
>%%
>*%%PREFIX%%y networklayer. Sometimes it is%%HIGHLIGHT%% ==added to X in the computation of the queries and keys but notto the values== %%POSTFIX%%.Draft: please send errata to ud*
>%%LINK%%[[#^6lvv87aczdm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6lvv87aczdm


>%%
>```annotation-json
>{"created":"2025-11-11T16:38:28.857Z","updated":"2025-11-11T16:38:28.857Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":484371,"end":484485},{"type":"TextQuoteSelector","exact":"Each element of theattention matrix corresponds to a particular offset between key position a and queryposition b.","prefix":"code this information directly. ","suffix":" Relative positional encodings l"}]}]}
>```
>%%
>*%%PREFIX%%code this information directly.%%HIGHLIGHT%% ==Each element of theattention matrix corresponds to a particular offset between key position a and queryposition b.== %%POSTFIX%%Relative positional encodings l*
>%%LINK%%[[#^gld2kb1037a|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gld2kb1037a


>%%
>```annotation-json
>{"created":"2025-11-11T16:38:39.272Z","updated":"2025-11-11T16:38:39.272Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":484487,"end":484703},{"type":"TextQuoteSelector","exact":"elative positional encodings learn a parameter πa,b for each offset and usethis to modify the attention matrix by adding these values, multiplying by them, orusing them to alter the attention matrix in some other way","prefix":"osition a and queryposition b. R","suffix":".12.3.2 Scaled dot-product self-"}]}]}
>```
>%%
>*%%PREFIX%%osition a and queryposition b. R%%HIGHLIGHT%% ==elative positional encodings learn a parameter πa,b for each offset and usethis to modify the attention matrix by adding these values, multiplying by them, orusing them to alter the attention matrix in some other way== %%POSTFIX%%.12.3.2 Scaled dot-product self-*
>%%LINK%%[[#^xzzuvsmhl9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xzzuvsmhl9


>%%
>```annotation-json
>{"created":"2025-11-11T16:43:34.541Z","updated":"2025-11-11T16:43:34.541Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":483717,"end":483741},{"type":"TextQuoteSelector","exact":"chosen by hand or learne","prefix":"put sequence. This matrix can be","suffix":"d. It may be added to the networ"}]}]}
>```
>%%
>*%%PREFIX%%put sequence. This matrix can be%%HIGHLIGHT%% ==chosen by hand or learne== %%POSTFIX%%d. It may be added to the networ*
>%%LINK%%[[#^lr7m1dimcqc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lr7m1dimcqc


>%%
>```annotation-json
>{"created":"2025-11-11T16:40:39.729Z","text":"1. Order is essential when it comes to words in a sentence, but the architecture is agnostic to order.\n2. We can use absolute positional information for either input or just the queries and keys, and not values.\n3. We can use relative positional information based on offsets in the attention matrix and update the attention matrix by various methods.","updated":"2025-11-11T16:40:39.729Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":482960,"end":482979},{"type":"TextQuoteSelector","exact":"Positional encoding","prefix":" always used in practice.12.3.1 ","suffix":"Observant readers will have noti"}]}]}
>```
>%%
>*%%PREFIX%%always used in practice.12.3.1%%HIGHLIGHT%% ==Positional encoding== %%POSTFIX%%Observant readers will have noti*
>%%LINK%%[[#^3fxbygb1ezd|show annotation]]
>%%COMMENT%%
>1. Order is essential when it comes to words in a sentence, but the architecture is agnostic to order.
>2. We can use absolute positional information for either input or just the queries and keys, and not values.
>3. We can use relative positional information based on offsets in the attention matrix and update the attention matrix by various methods.
>%%TAGS%%
>
^3fxbygb1ezd


>%%
>```annotation-json
>{"created":"2025-11-11T18:55:10.555Z","updated":"2025-11-11T18:55:10.555Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":484748,"end":484919},{"type":"TextQuoteSelector","exact":"dot products in the attention computation can have large magnitudes and movethe arguments to the softmax function into a region where the largest value completelydominates","prefix":"d dot-product self-attentionThe ","suffix":". Small changes to the inputs to"}]}]}
>```
>%%
>*%%PREFIX%%d dot-product self-attentionThe%%HIGHLIGHT%% ==dot products in the attention computation can have large magnitudes and movethe arguments to the softmax function into a region where the largest value completelydominates== %%POSTFIX%%. Small changes to the inputs to*
>%%LINK%%[[#^j7fee6uic3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^j7fee6uic3


>%%
>```annotation-json
>{"created":"2025-11-11T18:55:19.174Z","updated":"2025-11-11T18:55:19.174Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485030,"end":485056},{"type":"TextQuoteSelector","exact":"he gradients are very smal","prefix":"Problem 12.4 the output (i.e., t","suffix":"l), making the model diﬀicult to"}]}]}
>```
>%%
>*%%PREFIX%%Problem 12.4 the output (i.e., t%%HIGHLIGHT%% ==he gradients are very smal== %%POSTFIX%%l), making the model diﬀicult to*
>%%LINK%%[[#^bcw0x3it52j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bcw0x3it52j


>%%
>```annotation-json
>{"created":"2025-11-11T18:55:24.561Z","updated":"2025-11-11T18:55:24.561Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485071,"end":485094},{"type":"TextQuoteSelector","exact":"model diﬀicult to train","prefix":"nts are very small), making the ","suffix":". Toprevent this, the dot produc"}]}]}
>```
>%%
>*%%PREFIX%%nts are very small), making the%%HIGHLIGHT%% ==model diﬀicult to train== %%POSTFIX%%. Toprevent this, the dot produc*
>%%LINK%%[[#^a92rsx7mfsa|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^a92rsx7mfsa


>%%
>```annotation-json
>{"created":"2025-11-11T18:55:31.364Z","updated":"2025-11-11T18:55:31.364Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485133,"end":485179},{"type":"TextQuoteSelector","exact":"scaled by the square root of the dimension Dq ","prefix":"vent this, the dot products are ","suffix":"of thequeries and keys (i.e., th"}]}]}
>```
>%%
>*%%PREFIX%%vent this, the dot products are%%HIGHLIGHT%% ==scaled by the square root of the dimension Dq== %%POSTFIX%%of thequeries and keys (i.e., th*
>%%LINK%%[[#^b3hotd4mhf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^b3hotd4mhf


>%%
>```annotation-json
>{"created":"2025-11-11T18:55:36.101Z","updated":"2025-11-11T18:55:36.101Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485266,"end":485293},{"type":"TextQuoteSelector","exact":"Sa[X] = V ·Softmax[KT Q√Dq]","prefix":"and Ωk, which must be the same):","suffix":". (12.9)This is known as scaled "}]}]}
>```
>%%
>*%%PREFIX%%and Ωk, which must be the same):%%HIGHLIGHT%% ==Sa[X] = V ·Softmax[KT Q√Dq]== %%POSTFIX%%. (12.9)This is known as scaled*
>%%LINK%%[[#^kq2m9szg9sh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kq2m9szg9sh


>%%
>```annotation-json
>{"created":"2025-11-11T18:55:40.930Z","updated":"2025-11-11T18:55:40.930Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485318,"end":485352},{"type":"TextQuoteSelector","exact":"scaled dot-product self-attention.","prefix":"T Q√Dq]. (12.9)This is known as ","suffix":"12.3.3 Multiple headsMultiple se"}]}]}
>```
>%%
>*%%PREFIX%%T Q√Dq]. (12.9)This is known as%%HIGHLIGHT%% ==scaled dot-product self-attention.== %%POSTFIX%%12.3.3 Multiple headsMultiple se*
>%%LINK%%[[#^4a9p93yy54m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4a9p93yy54m


>%%
>```annotation-json
>{"created":"2025-11-11T18:55:50.782Z","text":"The dot-products are scaled by the sq. root of the dimension of queries/keys to avoid large magnitudes (easier to train).","updated":"2025-11-11T18:55:50.782Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":484711,"end":484744},{"type":"TextQuoteSelector","exact":"Scaled dot-product self-attention","prefix":"matrix in some other way.12.3.2 ","suffix":"The dot products in the attentio"}]}]}
>```
>%%
>*%%PREFIX%%matrix in some other way.12.3.2%%HIGHLIGHT%% ==Scaled dot-product self-attention== %%POSTFIX%%The dot products in the attentio*
>%%LINK%%[[#^gno7vlmaywb|show annotation]]
>%%COMMENT%%
>The dot-products are scaled by the sq. root of the dimension of queries/keys to avoid large magnitudes (easier to train).
>%%TAGS%%
>
^gno7vlmaywb


>%%
>```annotation-json
>{"created":"2025-11-11T19:08:06.052Z","updated":"2025-11-11T19:08:06.052Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485461,"end":485486},{"type":"TextQuoteSelector","exact":"multi-head self-attention","prefix":"n parallel, and this is known as","suffix":". Now H different sets of values"}]}]}
>```
>%%
>*%%PREFIX%%n parallel, and this is known as%%HIGHLIGHT%% ==multi-head self-attention== %%POSTFIX%%. Now H different sets of values*
>%%LINK%%[[#^tuw6eltemqm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tuw6eltemqm


>%%
>```annotation-json
>{"created":"2025-11-11T19:08:10.754Z","updated":"2025-11-11T19:08:10.754Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485551,"end":485568},{"type":"TextQuoteSelector","exact":"Vh = βvh1T+ Ωvh X","prefix":" keys, and queries are computed:","suffix":"Qh = βqh1T+ Ωqh XKh = βkh1T+ Ωkh"}]}]}
>```
>%%
>*%%PREFIX%%keys, and queries are computed:%%HIGHLIGHT%% ==Vh = βvh1T+ Ωvh X== %%POSTFIX%%Qh = βqh1T+ Ωqh XKh = βkh1T+ Ωkh*
>%%LINK%%[[#^2yrd6f8cqyf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2yrd6f8cqyf


>%%
>```annotation-json
>{"created":"2025-11-11T19:08:14.179Z","updated":"2025-11-11T19:08:14.179Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485568,"end":485585},{"type":"TextQuoteSelector","exact":"Qh = βqh1T+ Ωqh X","prefix":"s are computed:Vh = βvh1T+ Ωvh X","suffix":"Kh = βkh1T+ Ωkh X. (12.10)The ht"}]}]}
>```
>%%
>*%%PREFIX%%s are computed:Vh = βvh1T+ Ωvh X%%HIGHLIGHT%% ==Qh = βqh1T+ Ωqh X== %%POSTFIX%%Kh = βkh1T+ Ωkh X. (12.10)The ht*
>%%LINK%%[[#^c3mthvkww9a|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c3mthvkww9a


>%%
>```annotation-json
>{"created":"2025-11-11T19:08:17.599Z","updated":"2025-11-11T19:08:17.599Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485585,"end":485602},{"type":"TextQuoteSelector","exact":"Kh = βkh1T+ Ωkh X","prefix":" = βvh1T+ Ωvh XQh = βqh1T+ Ωqh X","suffix":". (12.10)The hth self-attention "}]}]}
>```
>%%
>*%%PREFIX%%= βvh1T+ Ωvh XQh = βqh1T+ Ωqh X%%HIGHLIGHT%% ==Kh = βkh1T+ Ωkh X== %%POSTFIX%%. (12.10)The hth self-attention*
>%%LINK%%[[#^0qza3bpxx4mo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0qza3bpxx4mo


>%%
>```annotation-json
>{"created":"2025-11-11T19:08:26.707Z","updated":"2025-11-11T19:08:26.707Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485670,"end":485701},{"type":"TextQuoteSelector","exact":"Sah[X] = Vh ·Softmax[KTh Qh√Dq]","prefix":"anism or head can be written as:","suffix":", (12.11)where we have different"}]}]}
>```
>%%
>*%%PREFIX%%anism or head can be written as:%%HIGHLIGHT%% ==Sah[X] = Vh ·Softmax[KTh Qh√Dq]== %%POSTFIX%%, (12.11)where we have different*
>%%LINK%%[[#^cwpoowburf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cwpoowburf


>%%
>```annotation-json
>{"created":"2025-11-11T19:09:16.075Z","updated":"2025-11-11T19:09:16.075Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485807,"end":485920},{"type":"TextQuoteSelector","exact":"f the dimension of the inputs xm is D and there are H heads, the values,queries, and keys will all be of size D/H","prefix":",Ωkh} for eachhead. Typically, i","suffix":", as this allows for an eﬀicient"}]}]}
>```
>%%
>*%%PREFIX%%,Ωkh} for eachhead. Typically, i%%HIGHLIGHT%% ==f the dimension of the inputs xm is D and there are H heads, the values,queries, and keys will all be of size D/H== %%POSTFIX%%, as this allows for an eﬀicient*
>%%LINK%%[[#^rz6wrd5cy2b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rz6wrd5cy2b


>%%
>```annotation-json
>{"created":"2025-11-11T19:09:22.799Z","updated":"2025-11-11T19:09:22.799Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485945,"end":485967},{"type":"TextQuoteSelector","exact":"ﬀicient implementation","prefix":"ize D/H, as this allows for an e","suffix":".Problem 12.5 The outputs of the"}]}]}
>```
>%%
>*%%PREFIX%%ize D/H, as this allows for an e%%HIGHLIGHT%% ==ﬀicient implementation== %%POSTFIX%%.Problem 12.5 The outputs of the*
>%%LINK%%[[#^xznj4tsh1hf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xznj4tsh1hf


>%%
>```annotation-json
>{"created":"2025-11-11T19:09:30.653Z","updated":"2025-11-11T19:09:30.653Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485981,"end":486114},{"type":"TextQuoteSelector","exact":"The outputs of these self-attention mechanisms are vertically concatenated, and anotherlinear transform Ωc is applied to combine them","prefix":"ent implementation.Problem 12.5 ","suffix":" (figure 12.6):This work is subj"}]}]}
>```
>%%
>*%%PREFIX%%ent implementation.Problem 12.5%%HIGHLIGHT%% ==The outputs of these self-attention mechanisms are vertically concatenated, and anotherlinear transform Ωc is applied to combine them== %%POSTFIX%%(figure 12.6):This work is subj*
>%%LINK%%[[#^isnftilrx6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^isnftilrx6


>%%
>```annotation-json
>{"created":"2025-11-11T19:09:42.085Z","updated":"2025-11-11T19:09:42.085Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":486550,"end":486597},{"type":"TextQuoteSelector","exact":"MhSa[X] = Ωc[Sa1[X]T ,Sa2[X]T ,...,SaH [X]T ]T.","prefix":"on Ωc is used to recombine them.","suffix":" (12.12)Multiple heads seem to b"}]}]}
>```
>%%
>*%%PREFIX%%on Ωc is used to recombine them.%%HIGHLIGHT%% ==MhSa[X] = Ωc[Sa1[X]T ,Sa2[X]T ,...,SaH [X]T ]T.== %%POSTFIX%%(12.12)Multiple heads seem to b*
>%%LINK%%[[#^sg9urb8tl5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^sg9urb8tl5


>%%
>```annotation-json
>{"created":"2025-11-11T19:09:57.356Z","updated":"2025-11-11T19:09:57.356Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":486676,"end":486811},{"type":"TextQuoteSelector","exact":"t has been Notebook 12.2Multi-headself-attentionspeculated that they make the self-attention network more robust to bad initializations","prefix":"make self-attention work well. I","suffix":".12.4 Transformer layersSelf-att"}]}]}
>```
>%%
>*%%PREFIX%%make self-attention work well. I%%HIGHLIGHT%% ==t has been Notebook 12.2Multi-headself-attentionspeculated that they make the self-attention network more robust to bad initializations== %%POSTFIX%%.12.4 Transformer layersSelf-att*
>%%LINK%%[[#^fdjg5hqplgq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fdjg5hqplgq


>%%
>```annotation-json
>{"created":"2025-11-11T19:10:06.439Z","text":"Multiple self-attention can be applied in parallel.\n\nIf the input dimension is D and there are H heads, then queries, keys, and values will have a dimension of D/H.","updated":"2025-11-11T19:10:06.439Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":485359,"end":485373},{"type":"TextQuoteSelector","exact":"Multiple heads","prefix":"t-product self-attention.12.3.3 ","suffix":"Multiple self-attention mechanis"}]}]}
>```
>%%
>*%%PREFIX%%t-product self-attention.12.3.3%%HIGHLIGHT%% ==Multiple heads== %%POSTFIX%%Multiple self-attention mechanis*
>%%LINK%%[[#^q6ykz3v1ho|show annotation]]
>%%COMMENT%%
>Multiple self-attention can be applied in parallel.
>
>If the input dimension is D and there are H heads, then queries, keys, and values will have a dimension of D/H.
>%%TAGS%%
>
^q6ykz3v1ho


>%%
>```annotation-json
>{"created":"2025-11-11T19:14:38.526Z","updated":"2025-11-11T19:14:38.526Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":488286,"end":488301},{"type":"TextQuoteSelector","exact":"X ← X + MhSa[X]","prefix":"ries of operations(figure 12.7):","suffix":"X ← LayerNorm[X]xn ← xn + mlp[xn"}]}]}
>```
>%%
>*%%PREFIX%%ries of operations(figure 12.7):%%HIGHLIGHT%% ==X ← X + MhSa[X]== %%POSTFIX%%X ← LayerNorm[X]xn ← xn + mlp[xn*
>%%LINK%%[[#^hmn98ubqnlv|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hmn98ubqnlv


>%%
>```annotation-json
>{"created":"2025-11-11T19:14:44.458Z","updated":"2025-11-11T19:14:44.458Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":488301,"end":488317},{"type":"TextQuoteSelector","exact":"X ← LayerNorm[X]","prefix":"ons(figure 12.7):X ← X + MhSa[X]","suffix":"xn ← xn + mlp[xn] ∀n ∈{1,...,N}X"}]}]}
>```
>%%
>*%%PREFIX%%ons(figure 12.7):X ← X + MhSa[X]%%HIGHLIGHT%% ==X ← LayerNorm[X]== %%POSTFIX%%xn ← xn + mlp[xn] ∀n ∈{1,...,N}X*
>%%LINK%%[[#^md684a6uebe|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^md684a6uebe


>%%
>```annotation-json
>{"created":"2025-11-11T19:14:48.171Z","updated":"2025-11-11T19:14:48.171Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":488317,"end":488348},{"type":"TextQuoteSelector","exact":"xn ← xn + mlp[xn] ∀n ∈{1,...,N}","prefix":":X ← X + MhSa[X]X ← LayerNorm[X]","suffix":"X ← LayerNorm[X], (12.13)where t"}]}]}
>```
>%%
>*%%PREFIX%%:X ← X + MhSa[X]X ← LayerNorm[X]%%HIGHLIGHT%% ==xn ← xn + mlp[xn] ∀n ∈{1,...,N}== %%POSTFIX%%X ← LayerNorm[X], (12.13)where t*
>%%LINK%%[[#^ncofp3vmt4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ncofp3vmt4


>%%
>```annotation-json
>{"created":"2025-11-11T19:14:55.380Z","updated":"2025-11-11T19:14:55.380Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":488348,"end":488364},{"type":"TextQuoteSelector","exact":"X ← LayerNorm[X]","prefix":"]xn ← xn + mlp[xn] ∀n ∈{1,...,N}","suffix":", (12.13)where the column vector"}]}]}
>```
>%%
>*%%PREFIX%%]xn ← xn + mlp[xn] ∀n ∈{1,...,N}%%HIGHLIGHT%% ==X ← LayerNorm[X]== %%POSTFIX%%, (12.13)where the column vector*
>%%LINK%%[[#^due06idsfn7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^due06idsfn7


>%%
>```annotation-json
>{"created":"2025-11-11T19:15:12.891Z","text":"The transformer features a self-attention unit, followed by an MLP unit (for each token), both of which are configured as residual networks, and utilise layer-based normalisation (TokenNorm).","updated":"2025-11-11T19:15:12.891Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":486817,"end":486835},{"type":"TextQuoteSelector","exact":"Transformer layers","prefix":"ust to bad initializations.12.4 ","suffix":"Self-attention is just one part "}]}]}
>```
>%%
>*%%PREFIX%%ust to bad initializations.12.4%%HIGHLIGHT%% ==Transformer layers== %%POSTFIX%%Self-attention is just one part*
>%%LINK%%[[#^buy672knuvi|show annotation]]
>%%COMMENT%%
>The transformer features a self-attention unit, followed by an MLP unit (for each token), both of which are configured as residual networks, and utilise layer-based normalisation (TokenNorm).
>%%TAGS%%
>
^buy672knuvi


>%%
>```annotation-json
>{"created":"2025-11-11T19:18:08.773Z","updated":"2025-11-11T19:18:08.773Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":488041,"end":488166},{"type":"TextQuoteSelector","exact":"This is similar to BatchNorm but uses statistics across thetokens within a single input sequence to perform the normalization","prefix":"on andfully connected networks. ","suffix":" (section 11.4 andfigure 11.14)."}]}]}
>```
>%%
>*%%PREFIX%%on andfully connected networks.%%HIGHLIGHT%% ==This is similar to BatchNorm but uses statistics across thetokens within a single input sequence to perform the normalization== %%POSTFIX%%(section 11.4 andfigure 11.14).*
>%%LINK%%[[#^uymq9fffzk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uymq9fffzk


>%%
>```annotation-json
>{"created":"2025-11-11T19:18:11.942Z","updated":"2025-11-11T19:18:11.942Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":487962,"end":487971},{"type":"TextQuoteSelector","exact":"LayerNorm","prefix":"ddition, it is typical to add a ","suffix":" operation after both the self-a"}]}]}
>```
>%%
>*%%PREFIX%%ddition, it is typical to add a%%HIGHLIGHT%% ==LayerNorm== %%POSTFIX%%operation after both the self-a*
>%%LINK%%[[#^0lmuh1c4yfw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0lmuh1c4yfw


>%%
>```annotation-json
>{"created":"2025-11-11T19:21:46.719Z","updated":"2025-11-11T19:21:46.719Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":487764,"end":487835},{"type":"TextQuoteSelector","exact":"fully connected network mlp[x•] (that operates separately on each word)","prefix":" is applied again.followed by a ","suffix":".Both units are residual network"}]}]}
>```
>%%
>*%%PREFIX%%is applied again.followed by a%%HIGHLIGHT%% ==fully connected network mlp[x•] (that operates separately on each word)== %%POSTFIX%%.Both units are residual network*
>%%LINK%%[[#^egp63eifse|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^egp63eifse


>%%
>```annotation-json
>{"created":"2025-11-11T19:21:49.973Z","updated":"2025-11-11T19:21:49.973Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":487851,"end":487868},{"type":"TextQuoteSelector","exact":"residual networks","prefix":"ly on each word).Both units are ","suffix":" (i.e., their output is added ba"}]}]}
>```
>%%
>*%%PREFIX%%ly on each word).Both units are%%HIGHLIGHT%% ==residual networks== %%POSTFIX%%(i.e., their output is added ba*
>%%LINK%%[[#^wo2j7ef0z7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wo2j7ef0z7


>%%
>```annotation-json
>{"created":"2025-11-11T19:25:18.313Z","updated":"2025-11-11T19:25:18.313Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":489211,"end":489228},{"type":"TextQuoteSelector","exact":"ub-word tokenizer","prefix":"able. b) At each iteration,the s","suffix":" looks for the most commonly occ"}]}]}
>```
>%%
>*%%PREFIX%%able. b) At each iteration,the s%%HIGHLIGHT%% ==ub-word tokenizer== %%POSTFIX%%looks for the most commonly occ*
>%%LINK%%[[#^r01o4nguuu9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r01o4nguuu9


>%%
>```annotation-json
>{"created":"2025-11-11T19:28:28.094Z","updated":"2025-11-11T19:28:28.094Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":488736,"end":488809},{"type":"TextQuoteSelector","exact":" starts with atokenizer that splits the text into words or word fragments","prefix":"P) tasks. A typical NLP pipeline","suffix":". Then each of these tokensThis "}]}]}
>```
>%%
>*%%PREFIX%%P) tasks. A typical NLP pipeline%%HIGHLIGHT%% ==starts with atokenizer that splits the text into words or word fragments== %%POSTFIX%%. Then each of these tokensThis*
>%%LINK%%[[#^8dpvt83q92|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8dpvt83q92


>%%
>```annotation-json
>{"created":"2025-11-11T19:28:37.432Z","updated":"2025-11-11T19:28:37.432Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":490273,"end":490302},{"type":"TextQuoteSelector","exact":"mapped to a learned embedding","prefix":"gmail.com.218 12 Transformersis ","suffix":". These embeddings are passed th"}]}]}
>```
>%%
>*%%PREFIX%%gmail.com.218 12 Transformersis%%HIGHLIGHT%% ==mapped to a learned embedding== %%POSTFIX%%. These embeddings are passed th*
>%%LINK%%[[#^k2noytkjr7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^k2noytkjr7


>%%
>```annotation-json
>{"created":"2025-11-11T19:28:57.636Z","text":"NLP pipeline starts with *tokenizing* and then *embedding* before the transformers are applied.","updated":"2025-11-11T19:28:57.636Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":488535,"end":488579},{"type":"TextQuoteSelector","exact":"Transformers for natural language processing","prefix":"f these transformer layers.12.5 ","suffix":"The previous section described t"}]}]}
>```
>%%
>*%%PREFIX%%f these transformer layers.12.5%%HIGHLIGHT%% ==Transformers for natural language processing== %%POSTFIX%%The previous section described t*
>%%LINK%%[[#^o2fmjxxopc9|show annotation]]
>%%COMMENT%%
>NLP pipeline starts with *tokenizing* and then *embedding* before the transformers are applied.
>%%TAGS%%
>
^o2fmjxxopc9


>%%
>```annotation-json
>{"created":"2025-11-11T19:34:07.976Z","updated":"2025-11-11T19:34:07.976Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":490476,"end":490485},{"type":"TextQuoteSelector","exact":"tokenizer","prefix":"ocessing pipeline begins with a ","suffix":". This splits the text into smal"}]}]}
>```
>%%
>*%%PREFIX%%ocessing pipeline begins with a%%HIGHLIGHT%% ==tokenizer== %%POSTFIX%%. This splits the text into smal*
>%%LINK%%[[#^nqsk5uz94a|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nqsk5uz94a


>%%
>```annotation-json
>{"created":"2025-11-11T19:34:14.864Z","updated":"2025-11-11T19:34:14.864Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":490554,"end":490584},{"type":"TextQuoteSelector","exact":"vocabulary of possible tokens.","prefix":"nstituent units (tokens) from a ","suffix":" In the discussion above,we have"}]}]}
>```
>%%
>*%%PREFIX%%nstituent units (tokens) from a%%HIGHLIGHT%% ==vocabulary of possible tokens.== %%POSTFIX%%In the discussion above,we have*
>%%LINK%%[[#^n4gzz4jnoh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^n4gzz4jnoh


>%%
>```annotation-json
>{"created":"2025-11-11T19:34:35.810Z","updated":"2025-11-11T19:34:35.810Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":490698,"end":490763},{"type":"TextQuoteSelector","exact":"evitably, some words (e.g., names) will not be in the vocabulary.","prefix":"ere are several diﬀiculties.• In","suffix":"• It’s unclear how to handle pun"}]}]}
>```
>%%
>*%%PREFIX%%ere are several diﬀiculties.• In%%HIGHLIGHT%% ==evitably, some words (e.g., names) will not be in the vocabulary.== %%POSTFIX%%• It’s unclear how to handle pun*
>%%LINK%%[[#^0rurx8rec8wa|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0rurx8rec8wa


>%%
>```annotation-json
>{"created":"2025-11-11T19:34:40.112Z","updated":"2025-11-11T19:34:40.112Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":490767,"end":490803},{"type":"TextQuoteSelector","exact":"’s unclear how to handle punctuation","prefix":"ll not be in the vocabulary.• It","suffix":", but this is important. If a se"}]}]}
>```
>%%
>*%%PREFIX%%ll not be in the vocabulary.• It%%HIGHLIGHT%% ==’s unclear how to handle punctuation== %%POSTFIX%%, but this is important. If a se*
>%%LINK%%[[#^fusi3tewa2h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fusi3tewa2h


>%%
>```annotation-json
>{"created":"2025-11-11T19:34:49.190Z","updated":"2025-11-11T19:34:49.190Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":490901,"end":490994},{"type":"TextQuoteSelector","exact":"he vocabulary would need different tokens for versions of the same word withdifferent suﬀixes","prefix":"must encode this information.• T","suffix":" (e.g., walk, walks, walked, wal"}]}]}
>```
>%%
>*%%PREFIX%%must encode this information.• T%%HIGHLIGHT%% ==he vocabulary would need different tokens for versions of the same word withdifferent suﬀixes== %%POSTFIX%%(e.g., walk, walks, walked, wal*
>%%LINK%%[[#^nm34reafd4g|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nm34reafd4g


>%%
>```annotation-json
>{"created":"2025-11-11T19:35:13.911Z","updated":"2025-11-11T19:35:13.911Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":491319,"end":491525},{"type":"TextQuoteSelector","exact":"a compromise between letters and full words is used, and the final vo-Notebook 12.3Tokenization cabulary includes both common words and word fragments from which larger and lessfrequent words can be compose","prefix":"tions between them.In practice, ","suffix":"d. The vocabulary is computed us"}]}]}
>```
>%%
>*%%PREFIX%%tions between them.In practice,%%HIGHLIGHT%% ==a compromise between letters and full words is used, and the final vo-Notebook 12.3Tokenization cabulary includes both common words and word fragments from which larger and lessfrequent words can be compose== %%POSTFIX%%d. The vocabulary is computed us*
>%%LINK%%[[#^37egu5d68cf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^37egu5d68cf


>%%
>```annotation-json
>{"created":"2025-11-11T19:35:19.403Z","updated":"2025-11-11T19:35:19.403Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":491563,"end":491610},{"type":"TextQuoteSelector","exact":"sub-word tok-enizer such as byte pair encoding ","prefix":" vocabulary is computed using a ","suffix":"(figure 12.8) that greedily merg"}]}]}
>```
>%%
>*%%PREFIX%%vocabulary is computed using a%%HIGHLIGHT%% ==sub-word tok-enizer such as byte pair encoding== %%POSTFIX%%(figure 12.8) that greedily merg*
>%%LINK%%[[#^tnhwvb2dv1|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tnhwvb2dv1


>%%
>```annotation-json
>{"created":"2025-11-11T19:35:25.310Z","updated":"2025-11-11T19:35:25.310Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":491630,"end":491699},{"type":"TextQuoteSelector","exact":"reedily merges commonly occurringsub-strings based on their frequency","prefix":"ir encoding (figure 12.8) that g","suffix":".12.5.2 EmbeddingsEach token in "}]}]}
>```
>%%
>*%%PREFIX%%ir encoding (figure 12.8) that g%%HIGHLIGHT%% ==reedily merges commonly occurringsub-strings based on their frequency== %%POSTFIX%%.12.5.2 EmbeddingsEach token in*
>%%LINK%%[[#^xprgmj3cjq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xprgmj3cjq


>%%
>```annotation-json
>{"created":"2025-11-11T19:35:30.527Z","text":"The text is tokenized into smaller units based on a **vocabulary** of all possible tokens.\n\n1. Some words would be missing from the vocabulary.\n2. How do we handle punctuations?\n3. How do we handle suffixes?\n\nA trade-off between common words and word fragments is used.\n\nSub-word tokenizer like Byte pair encoding is used.","updated":"2025-11-11T19:35:30.527Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":490423,"end":490435},{"type":"TextQuoteSelector","exact":"Tokenization","prefix":" of these stages in turn.12.5.1 ","suffix":"A text processing pipeline begin"}]}]}
>```
>%%
>*%%PREFIX%%of these stages in turn.12.5.1%%HIGHLIGHT%% ==Tokenization== %%POSTFIX%%A text processing pipeline begin*
>%%LINK%%[[#^7gv0epm75we|show annotation]]
>%%COMMENT%%
>The text is tokenized into smaller units based on a **vocabulary** of all possible tokens.
>
>1. Some words would be missing from the vocabulary.
>2. How do we handle punctuations?
>3. How do we handle suffixes?
>
>A trade-off between common words and word fragments is used.
>
>Sub-word tokenizer like Byte pair encoding is used.
>%%TAGS%%
>
^7gv0epm75we


>%%
>```annotation-json
>{"created":"2025-11-11T19:40:07.127Z","updated":"2025-11-11T19:40:07.127Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":491770,"end":491784},{"type":"TextQuoteSelector","exact":"word embedding","prefix":"abulary V is mapped to a unique ","suffix":", and the embed-dings for the wh"}]}]}
>```
>%%
>*%%PREFIX%%abulary V is mapped to a unique%%HIGHLIGHT%% ==word embedding== %%POSTFIX%%, and the embed-dings for the wh*
>%%LINK%%[[#^8as6fp0fuos|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8as6fp0fuos


>%%
>```annotation-json
>{"created":"2025-11-11T19:40:18.141Z","updated":"2025-11-11T19:40:18.141Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":491847,"end":491863},{"type":"TextQuoteSelector","exact":"matrix Ωe ∈RD×|V","prefix":"hole vocabulary are stored in a ","suffix":"|. To accomplish this,the N inpu"}]}]}
>```
>%%
>*%%PREFIX%%hole vocabulary are stored in a%%HIGHLIGHT%% ==matrix Ωe ∈RD×|V== %%POSTFIX%%|. To accomplish this,the N inpu*
>%%LINK%%[[#^8tydtu23uhj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8tydtu23uhj


>%%
>```annotation-json
>{"created":"2025-11-11T19:40:32.598Z","updated":"2025-11-11T19:40:32.598Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":491889,"end":491946},{"type":"TextQuoteSelector","exact":"N input tokens are first encoded in the matrix T ∈ R|V|×N","prefix":"∈RD×|V|. To accomplish this,the ","suffix":" , where the nth columncorrespon"}]}]}
>```
>%%
>*%%PREFIX%%∈RD×|V|. To accomplish this,the%%HIGHLIGHT%% ==N input tokens are first encoded in the matrix T ∈ R|V|×N== %%POSTFIX%%, where the nth columncorrespon*
>%%LINK%%[[#^ghwx127fb9t|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ghwx127fb9t


>%%
>```annotation-json
>{"created":"2025-11-11T19:40:38.757Z","updated":"2025-11-11T19:40:38.757Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":492007,"end":492027},{"type":"TextQuoteSelector","exact":"|V|×1 one-hot vector","prefix":"ponds to the nth token and is a ","suffix":" (i.e., a vector where everyentr"}]}]}
>```
>%%
>*%%PREFIX%%ponds to the nth token and is a%%HIGHLIGHT%% ==|V|×1 one-hot vector== %%POSTFIX%%(i.e., a vector where everyentr*
>%%LINK%%[[#^dil0vyf42ng|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dil0vyf42ng


>%%
>```annotation-json
>{"created":"2025-11-11T19:40:55.228Z","updated":"2025-11-11T19:40:55.228Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":492149,"end":492183},{"type":"TextQuoteSelector","exact":"embeddings are computed as X = ΩeT","prefix":" which is set to one). Theinput ","suffix":", and Ωe is learned like any oth"}]}]}
>```
>%%
>*%%PREFIX%%which is set to one). Theinput%%HIGHLIGHT%% ==embeddings are computed as X = ΩeT== %%POSTFIX%%, and Ωe is learned like any oth*
>%%LINK%%[[#^c7faz0x1cnk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c7faz0x1cnk


>%%
>```annotation-json
>{"created":"2025-11-11T19:41:01.594Z","updated":"2025-11-11T19:41:01.594Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":492189,"end":492234},{"type":"TextQuoteSelector","exact":"Ωe is learned like any other networkparameter","prefix":"gs are computed as X = ΩeT, and ","suffix":" (figure 12.9). A typical embedd"}]}]}
>```
>%%
>*%%PREFIX%%gs are computed as X = ΩeT, and%%HIGHLIGHT%% ==Ωe is learned like any other networkparameter== %%POSTFIX%%(figure 12.9). A typical embedd*
>%%LINK%%[[#^1prqqkazrlfj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1prqqkazrlfj


>%%
>```annotation-json
>{"created":"2025-11-11T19:41:06.690Z","updated":"2025-11-11T19:41:06.690Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":492261,"end":492284},{"type":"TextQuoteSelector","exact":"mbedding size D is 1024","prefix":"meter (figure 12.9). A typical e","suffix":", and a typical total vocab-ular"}]}]}
>```
>%%
>*%%PREFIX%%meter (figure 12.9). A typical e%%HIGHLIGHT%% ==mbedding size D is 1024== %%POSTFIX%%, and a typical total vocab-ular*
>%%LINK%%[[#^8xpc4f76n8u|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8xpc4f76n8u


>%%
>```annotation-json
>{"created":"2025-11-11T19:41:17.838Z","updated":"2025-11-11T19:41:17.838Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":492292,"end":492336},{"type":"TextQuoteSelector","exact":"typical total vocab-ulary size |V| is 30,000","prefix":"embedding size D is 1024, and a ","suffix":", so even before the main networ"}]}]}
>```
>%%
>*%%PREFIX%%embedding size D is 1024, and a%%HIGHLIGHT%% ==typical total vocab-ulary size |V| is 30,000== %%POSTFIX%%, so even before the main networ*
>%%LINK%%[[#^h0egf8yy5a|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^h0egf8yy5a


>%%
>```annotation-json
>{"created":"2025-11-11T19:41:21.984Z","text":"The tokens are embedded into a unique embedding matrix. \nThe matrix values are learned in the same manner as other parameters.\n\nEmbedding size = 1024\nVocabulary size = 30,000","updated":"2025-11-11T19:41:21.984Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":491707,"end":491717},{"type":"TextQuoteSelector","exact":"Embeddings","prefix":"based on their frequency.12.5.2 ","suffix":"Each token in the vocabulary V i"}]}]}
>```
>%%
>*%%PREFIX%%based on their frequency.12.5.2%%HIGHLIGHT%% ==Embeddings== %%POSTFIX%%Each token in the vocabulary V i*
>%%LINK%%[[#^hro2rlvc3b|show annotation]]
>%%COMMENT%%
>The tokens are embedded into a unique embedding matrix. 
>The matrix values are learned in the same manner as other parameters.
>
>Embedding size = 1024
>Vocabulary size = 30,000
>%%TAGS%%
>
^hro2rlvc3b


>%%
>```annotation-json
>{"created":"2025-11-11T19:46:12.590Z","updated":"2025-11-11T19:46:12.590Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":492510,"end":492538},{"type":"TextQuoteSelector","exact":"eries of Ktransformer layers","prefix":"g the text is passed through a s","suffix":", called a transformer model. Th"}]}]}
>```
>%%
>*%%PREFIX%%g the text is passed through a s%%HIGHLIGHT%% ==eries of Ktransformer layers== %%POSTFIX%%, called a transformer model. Th*
>%%LINK%%[[#^liyzd3ueswk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^liyzd3ueswk


>%%
>```annotation-json
>{"created":"2025-11-11T19:46:25.618Z","updated":"2025-11-11T19:46:25.618Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":492615,"end":492674},{"type":"TextQuoteSelector","exact":"encoder transforms the text embeddings into a representatio","prefix":" types of transformermodels. An ","suffix":"n that cansupport a variety of t"}]}]}
>```
>%%
>*%%PREFIX%%types of transformermodels. An%%HIGHLIGHT%% ==encoder transforms the text embeddings into a representatio== %%POSTFIX%%n that cansupport a variety of t*
>%%LINK%%[[#^iiv89592svm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^iiv89592svm


>%%
>```annotation-json
>{"created":"2025-11-11T19:46:35.575Z","updated":"2025-11-11T19:46:35.575Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":492714,"end":492767},{"type":"TextQuoteSelector","exact":"decoder predicts the next token to continue the input","prefix":"ansupport a variety of tasks. A ","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%ansupport a variety of tasks. A%%HIGHLIGHT%% ==decoder predicts the next token to continue the input== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^k0ovtgz7xh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^k0ovtgz7xh


>%%
>```annotation-json
>{"created":"2025-11-11T19:46:43.607Z","updated":"2025-11-11T19:46:43.607Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":493341,"end":493395},{"type":"TextQuoteSelector","exact":"ncoder-decoders are used in sequence-to-sequence tasks","prefix":"ord an in X are the same.text. E","suffix":", where one text string isconver"}]}]}
>```
>%%
>*%%PREFIX%%ord an in X are the same.text. E%%HIGHLIGHT%% ==ncoder-decoders are used in sequence-to-sequence tasks== %%POSTFIX%%, where one text string isconver*
>%%LINK%%[[#^tooyi2blbmk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tooyi2blbmk


>%%
>```annotation-json
>{"created":"2025-11-11T19:52:20.486Z","updated":"2025-11-11T19:52:20.486Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":494162,"end":494192},{"type":"TextQuoteSelector","exact":"BERT exploit transfer learning","prefix":"-art models.Encoder models like ","suffix":" (section 9.3.6). During pre-tra"}]}]}
>```
>%%
>*%%PREFIX%%-art models.Encoder models like%%HIGHLIGHT%% ==BERT exploit transfer learning== %%POSTFIX%%(section 9.3.6). During pre-tra*
>%%LINK%%[[#^lly65i7l6bh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lly65i7l6bh


>%%
>```annotation-json
>{"created":"2025-11-11T19:52:32.545Z","updated":"2025-11-11T19:52:32.545Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":494210,"end":494339},{"type":"TextQuoteSelector","exact":"During pre-training, the parameters of the transformer architecture are learned using self-supervisionfrom a large corpus of text","prefix":"nsfer learning (section 9.3.6). ","suffix":". The goal here is for the model"}]}]}
>```
>%%
>*%%PREFIX%%nsfer learning (section 9.3.6).%%HIGHLIGHT%% ==During pre-training, the parameters of the transformer architecture are learned using self-supervisionfrom a large corpus of text== %%POSTFIX%%. The goal here is for the model*
>%%LINK%%[[#^4ted69pvpvu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4ted69pvpvu


>%%
>```annotation-json
>{"created":"2025-11-11T19:52:46.183Z","updated":"2025-11-11T19:52:46.183Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":494376,"end":494432},{"type":"TextQuoteSelector","exact":"earn general informationabout the statistics of language","prefix":" goal here is for the model to l","suffix":". In the fine-tuning stage, the "}]}]}
>```
>%%
>*%%PREFIX%%goal here is for the model to l%%HIGHLIGHT%% ==earn general informationabout the statistics of language== %%POSTFIX%%. In the fine-tuning stage, the*
>%%LINK%%[[#^saz7k44vj1g|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^saz7k44vj1g


>%%
>```annotation-json
>{"created":"2025-11-11T19:52:53.796Z","updated":"2025-11-11T19:52:53.796Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":494441,"end":494567},{"type":"TextQuoteSelector","exact":"fine-tuning stage, the resulting network is adaptedto solve a particular task using a smaller body of supervised training data","prefix":" statistics of language. In the ","suffix":".Draft: please send errata to ud"}]}]}
>```
>%%
>*%%PREFIX%%statistics of language. In the%%HIGHLIGHT%% ==fine-tuning stage, the resulting network is adaptedto solve a particular task using a smaller body of supervised training data== %%POSTFIX%%.Draft: please send errata to ud*
>%%LINK%%[[#^byx6fstiwrs|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^byx6fstiwrs


>%%
>```annotation-json
>{"created":"2025-11-11T19:59:17.058Z","text":"Exploits transfer learning; parameters are learned during the pre-training stage via self-supervision from a large corpus of text. \n\nThen, it is fine-tuned based on the task type of supervised training data.","updated":"2025-11-11T19:59:17.058Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":493544,"end":493571},{"type":"TextQuoteSelector","exact":"Encoder model example: BERT","prefix":"ns 12.6–12.8, respectively.12.6 ","suffix":"BERT is an encoder model that us"}]}]}
>```
>%%
>*%%PREFIX%%ns 12.6–12.8, respectively.12.6%%HIGHLIGHT%% ==Encoder model example: BERT== %%POSTFIX%%BERT is an encoder model that us*
>%%LINK%%[[#^x6ulfywthr|show annotation]]
>%%COMMENT%%
>Exploits transfer learning; parameters are learned during the pre-training stage via self-supervision from a large corpus of text. 
>
>Then, it is fine-tuned based on the task type of supervised training data.
>%%TAGS%%
>
^x6ulfywthr


>%%
>```annotation-json
>{"created":"2025-11-13T18:11:21.075Z","updated":"2025-11-13T18:11:21.075Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":495734,"end":495748},{"type":"TextQuoteSelector","exact":"elf-supervisio","prefix":", the network is trained using s","suffix":"n. This allows theuse of enormou"}]}]}
>```
>%%
>*%%PREFIX%%, the network is trained using s%%HIGHLIGHT%% ==elf-supervisio== %%POSTFIX%%n. This allows theuse of enormou*
>%%LINK%%[[#^rcwd7arwy5b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rcwd7arwy5b


>%%
>```annotation-json
>{"created":"2025-11-13T18:11:37.433Z","updated":"2025-11-13T18:11:37.433Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":496246,"end":496252},{"type":"TextQuoteSelector","exact":"syntax","prefix":"rmer network to understand some ","suffix":".For example, it might learn tha"}]}]}
>```
>%%
>*%%PREFIX%%rmer network to understand some%%HIGHLIGHT%% ==syntax== %%POSTFIX%%.For example, it might learn tha*
>%%LINK%%[[#^l01tfbw700s|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^l01tfbw700s


>%%
>```annotation-json
>{"created":"2025-11-13T18:11:43.527Z","updated":"2025-11-13T18:11:43.527Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":496420,"end":496458},{"type":"TextQuoteSelector","exact":"uperficialcommon sense about the world","prefix":"also allows the model to learn s","suffix":". For example, after training, t"}]}]}
>```
>%%
>*%%PREFIX%%also allows the model to learn s%%HIGHLIGHT%% ==uperficialcommon sense about the world== %%POSTFIX%%. For example, after training, t*
>%%LINK%%[[#^6d6avr2egnn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6d6avr2egnn


>%%
>```annotation-json
>{"created":"2025-11-13T18:11:56.067Z","text":"Pre-training is based on self-supervision using a large corpus of data through masking and prediction.\nIt helps learn basic statistics about language (syntax) and provides a superficial understanding of the world.\n","updated":"2025-11-13T18:11:56.067Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":495665,"end":495677},{"type":"TextQuoteSelector","exact":"Pre-training","prefix":"rms to the loss function.12.6.1 ","suffix":"In the pre-training stage, the n"}]}]}
>```
>%%
>*%%PREFIX%%rms to the loss function.12.6.1%%HIGHLIGHT%% ==Pre-training== %%POSTFIX%%In the pre-training stage, the n*
>%%LINK%%[[#^9qgbjn9b72|show annotation]]
>%%COMMENT%%
>Pre-training is based on self-supervision using a large corpus of data through masking and prediction.
>It helps learn basic statistics about language (syntax) and provides a superficial understanding of the world.
>
>%%TAGS%%
>
^9qgbjn9b72


>%%
>```annotation-json
>{"created":"2025-11-13T18:14:25.677Z","updated":"2025-11-13T18:14:25.677Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":497698,"end":497739},{"type":"TextQuoteSelector","exact":"pecialize the network toa particular task","prefix":"del parameters are adjusted to s","suffix":". An extra layer is appended ont"}]}]}
>```
>%%
>*%%PREFIX%%del parameters are adjusted to s%%HIGHLIGHT%% ==pecialize the network toa particular task== %%POSTFIX%%. An extra layer is appended ont*
>%%LINK%%[[#^e5kdrkc5ck|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^e5kdrkc5ck


>%%
>```annotation-json
>{"created":"2025-11-13T18:16:41.813Z","updated":"2025-11-13T18:16:41.813Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":497906,"end":497918},{"type":"TextQuoteSelector","exact":"pecial token","prefix":"ext classification: In BERT, a s","suffix":" known as the classification or "}]}]}
>```
>%%
>*%%PREFIX%%ext classification: In BERT, a s%%HIGHLIGHT%% ==pecial token== %%POSTFIX%%known as the classification or*
>%%LINK%%[[#^dpykg964sl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dpykg964sl


>%%
>```annotation-json
>{"created":"2025-11-13T18:16:47.684Z","updated":"2025-11-13T18:16:47.684Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":497933,"end":497960},{"type":"TextQuoteSelector","exact":"lassification or <cls>token","prefix":", a special token known as the c","suffix":" is placed at the start of each "}]}]}
>```
>%%
>*%%PREFIX%%, a special token known as the c%%HIGHLIGHT%% ==lassification or <cls>token== %%POSTFIX%%is placed at the start of each*
>%%LINK%%[[#^9eg7wx1mucr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9eg7wx1mucr


>%%
>```annotation-json
>{"created":"2025-11-13T18:16:57.468Z","updated":"2025-11-13T18:16:57.468Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":497979,"end":498018},{"type":"TextQuoteSelector","exact":"tart of each string during pre-training","prefix":"or <cls>token is placed at the s","suffix":". For text classificationtasks l"}]}]}
>```
>%%
>*%%PREFIX%%or <cls>token is placed at the s%%HIGHLIGHT%% ==tart of each string during pre-training== %%POSTFIX%%. For text classificationtasks l*
>%%LINK%%[[#^gi6l5w1fzv|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gi6l5w1fzv


>%%
>```annotation-json
>{"created":"2025-11-13T18:17:08.848Z","updated":"2025-11-13T18:17:08.848Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":498159,"end":498262},{"type":"TextQuoteSelector","exact":"vector associated with the <cls> token is mapped to asingle number and passed through a logistic sigmoi","prefix":"ornegative emotional tone), the ","suffix":"d (figure 12.11a). This contribu"}]}]}
>```
>%%
>*%%PREFIX%%ornegative emotional tone), the%%HIGHLIGHT%% ==vector associated with the <cls> token is mapped to asingle number and passed through a logistic sigmoi== %%POSTFIX%%d (figure 12.11a). This contribu*
>%%LINK%%[[#^mbmotkiftpb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mbmotkiftpb


>%%
>```annotation-json
>{"created":"2025-11-13T18:17:13.042Z","updated":"2025-11-13T18:17:13.042Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":498312,"end":498336},{"type":"TextQuoteSelector","exact":"inary cross-entropy loss","prefix":" This contributes toa standard b","suffix":" (section 5.4).Draft: please sen"}]}]}
>```
>%%
>*%%PREFIX%%This contributes toa standard b%%HIGHLIGHT%% ==inary cross-entropy loss== %%POSTFIX%%(section 5.4).Draft: please sen*
>%%LINK%%[[#^sekzrk2k35i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^sekzrk2k35i


>%%
>```annotation-json
>{"created":"2025-11-13T18:17:29.323Z","updated":"2025-11-13T18:17:29.323Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":498585,"end":498687},{"type":"TextQuoteSelector","exact":"each inputembedding xn is mapped to an E ×1 vector where the E entries correspond to the Eentity types","prefix":"on, or no-entity). To this end, ","suffix":". This is passed through a softm"}]}]}
>```
>%%
>*%%PREFIX%%on, or no-entity). To this end,%%HIGHLIGHT%% ==each inputembedding xn is mapped to an E ×1 vector where the E entries correspond to the Eentity types== %%POSTFIX%%. This is passed through a softm*
>%%LINK%%[[#^ecsgugsnyup|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ecsgugsnyup


>%%
>```annotation-json
>{"created":"2025-11-13T18:17:33.410Z","updated":"2025-11-13T18:17:33.410Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":498715,"end":498730},{"type":"TextQuoteSelector","exact":"oftmax function","prefix":"ypes. This is passed through a s","suffix":" to create probabilities for eac"}]}]}
>```
>%%
>*%%PREFIX%%ypes. This is passed through a s%%HIGHLIGHT%% ==oftmax function== %%POSTFIX%%to create probabilities for eac*
>%%LINK%%[[#^ga2f1jrcklr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ga2f1jrcklr


>%%
>```annotation-json
>{"created":"2025-11-13T18:17:37.720Z","updated":"2025-11-13T18:17:37.720Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":498792,"end":498821},{"type":"TextQuoteSelector","exact":"multiclass cross-entropy loss","prefix":"achclass, which contribute to a ","suffix":" (figure 12.11b).Text span predi"}]}]}
>```
>%%
>*%%PREFIX%%achclass, which contribute to a%%HIGHLIGHT%% ==multiclass cross-entropy loss== %%POSTFIX%%(figure 12.11b).Text span predi*
>%%LINK%%[[#^vqhb6ra240r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vqhb6ra240r


>%%
>```annotation-json
>{"created":"2025-11-13T18:17:48.093Z","updated":"2025-11-13T18:17:48.093Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":498906,"end":498995},{"type":"TextQuoteSelector","exact":"question and apassage from Wikipedia containing the answer are concatenated and tokenized","prefix":".1 question answering task, the ","suffix":". BERTis then used to predict th"}]}]}
>```
>%%
>*%%PREFIX%%.1 question answering task, the%%HIGHLIGHT%% ==question and apassage from Wikipedia containing the answer are concatenated and tokenized== %%POSTFIX%%. BERTis then used to predict th*
>%%LINK%%[[#^ajlluaoaz9m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ajlluaoaz9m


>%%
>```annotation-json
>{"created":"2025-11-13T18:18:06.257Z","text":"The pre-trained network is then trained in a supervised manner to specialise in a particular task.\n\n1. Text classification uses a *<cls>* token at the beginning of each sentence, which is then mapped to a single number and passed into a logistic sigmoid function (binary cross-entropy).\n \n2. Word classification maps each word to a particular entity type. Once mapped to a $E \\times 1$ vector, a softmax function is used (multi-class cross-entropy loss). \n\n3. Text span prediction can help with question answering.","updated":"2025-11-13T18:18:06.257Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":497623,"end":497634},{"type":"TextQuoteSelector","exact":"Fine-tuning","prefix":"ion, or is not an entity.12.6.2 ","suffix":"In the fine-tuning stage, the mo"}]}]}
>```
>%%
>*%%PREFIX%%ion, or is not an entity.12.6.2%%HIGHLIGHT%% ==Fine-tuning== %%POSTFIX%%In the fine-tuning stage, the mo*
>%%LINK%%[[#^qkpoqixd3ej|show annotation]]
>%%COMMENT%%
>The pre-trained network is then trained in a supervised manner to specialise in a particular task.
>
>1. Text classification uses a *<cls>* token at the beginning of each sentence, which is then mapped to a single number and passed into a logistic sigmoid function (binary cross-entropy).
> 
>2. Word classification maps each word to a particular entity type. Once mapped to a $E \times 1$ vector, a softmax function is used (multi-class cross-entropy loss). 
>
>3. Text span prediction can help with question answering.
>%%TAGS%%
>
^qkpoqixd3ej


>%%
>```annotation-json
>{"created":"2025-11-13T18:25:40.833Z","updated":"2025-11-13T18:25:40.833Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":499873,"end":499909},{"type":"TextQuoteSelector","exact":"generate the next token in a sequenc","prefix":" the decoder has onepurpose: to ","suffix":"e. It can generate a coherent te"}]}]}
>```
>%%
>*%%PREFIX%%the decoder has onepurpose: to%%HIGHLIGHT%% ==generate the next token in a sequenc== %%POSTFIX%%e. It can generate a coherent te*
>%%LINK%%[[#^fs2txi0lswl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fs2txi0lswl


>%%
>```annotation-json
>{"created":"2025-11-13T18:25:46.704Z","updated":"2025-11-13T18:25:46.704Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":499507,"end":499514},{"type":"TextQuoteSelector","exact":"decoder","prefix":"iption of GPT3, an example of a ","suffix":" model.The basic architecture is"}]}]}
>```
>%%
>*%%PREFIX%%iption of GPT3, an example of a%%HIGHLIGHT%% ==decoder== %%POSTFIX%%model.The basic architecture is*
>%%LINK%%[[#^bn7uligmp2b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bn7uligmp2b


>%%
>```annotation-json
>{"created":"2025-11-13T18:28:27.134Z","updated":"2025-11-13T18:28:27.134Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":500047,"end":500075},{"type":"TextQuoteSelector","exact":"autoregressive language mode","prefix":"uage modelingGPT3 constructs an ","suffix":"l. This is easiest to understand"}]}]}
>```
>%%
>*%%PREFIX%%uage modelingGPT3 constructs an%%HIGHLIGHT%% ==autoregressive language mode== %%POSTFIX%%l. This is easiest to understand*
>%%LINK%%[[#^3bdaka8nh5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3bdaka8nh5


>%%
>```annotation-json
>{"created":"2025-11-13T18:28:44.776Z","updated":"2025-11-13T18:28:44.776Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":500916,"end":500965},{"type":"TextQuoteSelector","exact":"Pr(t1,t2,...,tN ) = Pr(t1)N∏n=2Pr(tn|t1,...,tn−1)","prefix":" Decoder model example: GPT3 223","suffix":". (12.15)The autoregressive form"}]}]}
>```
>%%
>*%%PREFIX%%Decoder model example: GPT3 223%%HIGHLIGHT%% ==Pr(t1,t2,...,tN ) = Pr(t1)N∏n=2Pr(tn|t1,...,tn−1)== %%POSTFIX%%. (12.15)The autoregressive form*
>%%LINK%%[[#^ybsvqy7n2i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ybsvqy7n2i


>%%
>```annotation-json
>{"created":"2025-11-13T18:29:04.298Z","updated":"2025-11-13T18:29:04.298Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":501041,"end":501140},{"type":"TextQuoteSelector","exact":"maximizing the logprobability of the tokens in the loss function and the next token prediction task","prefix":"nstrates the connection between ","suffix":".12.7.2 Masked self-attentionTo "}]}]}
>```
>%%
>*%%PREFIX%%nstrates the connection between%%HIGHLIGHT%% ==maximizing the logprobability of the tokens in the loss function and the next token prediction task== %%POSTFIX%%.12.7.2 Masked self-attentionTo*
>%%LINK%%[[#^4ril9fxyjio|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4ril9fxyjio


>%%
>```annotation-json
>{"created":"2025-11-13T18:38:04.631Z","updated":"2025-11-13T18:38:04.631Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":501192,"end":501269},{"type":"TextQuoteSelector","exact":"maximize the log probability of the input text under the autore-gressive mode","prefix":"attentionTo train a decoder, we ","suffix":"l. Ideally, we would pass in the"}]}]}
>```
>%%
>*%%PREFIX%%attentionTo train a decoder, we%%HIGHLIGHT%% ==maximize the log probability of the input text under the autore-gressive mode== %%POSTFIX%%l. Ideally, we would pass in the*
>%%LINK%%[[#^e4fwqpbs1al|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^e4fwqpbs1al


>%%
>```annotation-json
>{"created":"2025-11-13T18:38:36.125Z","updated":"2025-11-13T18:38:36.125Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":501708,"end":501757},{"type":"TextQuoteSelector","exact":"tokens only interact in the self-attention layers","prefix":"train properly.Fortunately, the ","suffix":" in a transformernetwork. Hence,"}]}]}
>```
>%%
>*%%PREFIX%%train properly.Fortunately, the%%HIGHLIGHT%% ==tokens only interact in the self-attention layers== %%POSTFIX%%in a transformernetwork. Hence,*
>%%LINK%%[[#^4pv6ilc8t44|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4pv6ilc8t44


>%%
>```annotation-json
>{"created":"2025-11-13T18:38:43.828Z","updated":"2025-11-13T18:38:43.828Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":501608,"end":501613},{"type":"TextQuoteSelector","exact":"cheat","prefix":"pear weak. Hence, the systemcan ","suffix":" rather than learn to predict th"}]}]}
>```
>%%
>*%%PREFIX%%pear weak. Hence, the systemcan%%HIGHLIGHT%% ==cheat== %%POSTFIX%%rather than learn to predict th*
>%%LINK%%[[#^whn7fhbi22b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^whn7fhbi22b


>%%
>```annotation-json
>{"created":"2025-11-13T18:38:48.092Z","updated":"2025-11-13T18:38:48.092Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":501667,"end":501690},{"type":"TextQuoteSelector","exact":"will not train properly","prefix":"predict the following words and ","suffix":".Fortunately, the tokens only in"}]}]}
>```
>%%
>*%%PREFIX%%predict the following words and%%HIGHLIGHT%% ==will not train properly== %%POSTFIX%%.Fortunately, the tokens only in*
>%%LINK%%[[#^cdunmyl5998|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cdunmyl5998


>%%
>```annotation-json
>{"created":"2025-11-13T18:39:02.566Z","updated":"2025-11-13T18:39:02.566Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":501839,"end":501891},{"type":"TextQuoteSelector","exact":"attention to theanswer and the right context is zero","prefix":"e resolved by ensuring that the ","suffix":". This can be achieved by settin"}]}]}
>```
>%%
>*%%PREFIX%%e resolved by ensuring that the%%HIGHLIGHT%% ==attention to theanswer and the right context is zero== %%POSTFIX%%. This can be achieved by settin*
>%%LINK%%[[#^p6uwsgks3x|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^p6uwsgks3x


>%%
>```annotation-json
>{"created":"2025-11-13T18:39:18.038Z","updated":"2025-11-13T18:39:18.038Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":502008,"end":502079},{"type":"TextQuoteSelector","exact":"negative infinity beforethey are passed through the softmax[•] function","prefix":" computation (equation 12.5) to ","suffix":". This is known as masked self-a"}]}]}
>```
>%%
>*%%PREFIX%%computation (equation 12.5) to%%HIGHLIGHT%% ==negative infinity beforethey are passed through the softmax[•] function== %%POSTFIX%%. This is known as masked self-a*
>%%LINK%%[[#^zzqz1sfkg0l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zzqz1sfkg0l


>%%
>```annotation-json
>{"created":"2025-11-13T18:39:21.547Z","updated":"2025-11-13T18:39:21.547Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":502098,"end":502119},{"type":"TextQuoteSelector","exact":"masked self-attention","prefix":"x[•] function. This is known as ","suffix":".The effect is to make the weigh"}]}]}
>```
>%%
>*%%PREFIX%%x[•] function. This is known as%%HIGHLIGHT%% ==masked self-attention== %%POSTFIX%%.The effect is to make the weigh*
>%%LINK%%[[#^32iom9blor6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^32iom9blor6


>%%
>```annotation-json
>{"created":"2025-11-13T18:40:02.083Z","updated":"2025-11-13T18:40:02.083Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":502666,"end":502842},{"type":"TextQuoteSelector","exact":"after the transformer layers, a linear layer mapseach word embedding to the size of the vocabulary, followed by a softmax[•] functionthat converts these values to probabilities","prefix":" in the sequence. Consequently, ","suffix":". During training, we aim to max"}]}]}
>```
>%%
>*%%PREFIX%%in the sequence. Consequently,%%HIGHLIGHT%% ==after the transformer layers, a linear layer mapseach word embedding to the size of the vocabulary, followed by a softmax[•] functionthat converts these values to probabilities== %%POSTFIX%%. During training, we aim to max*
>%%LINK%%[[#^uclmj7xqbif|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uclmj7xqbif


>%%
>```annotation-json
>{"created":"2025-11-13T18:40:11.032Z","updated":"2025-11-13T18:40:11.032Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":502864,"end":503023},{"type":"TextQuoteSelector","exact":"aim to maximize the sumof the log probabilities of the next token in the ground truth sequence at every positionusing a standard multiclass cross-entropy loss ","prefix":"babilities. During training, we ","suffix":"(figure 12.12).12.7.3 Generating"}]}]}
>```
>%%
>*%%PREFIX%%babilities. During training, we%%HIGHLIGHT%% ==aim to maximize the sumof the log probabilities of the next token in the ground truth sequence at every positionusing a standard multiclass cross-entropy loss== %%POSTFIX%%(figure 12.12).12.7.3 Generating*
>%%LINK%%[[#^6a3xao7fdrv|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6a3xao7fdrv


>%%
>```annotation-json
>{"created":"2025-11-13T18:40:18.574Z","text":"Here, we use autoregressive modelling with masked attention to train the model.\n\nIf we use the whole sequence, the model can cheat; therefore, we only allow it to interact with current and past tokens through masking. ","updated":"2025-11-13T18:40:18.574Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":501148,"end":501169},{"type":"TextQuoteSelector","exact":"Masked self-attention","prefix":"xt token prediction task.12.7.2 ","suffix":"To train a decoder, we maximize "}]}]}
>```
>%%
>*%%PREFIX%%xt token prediction task.12.7.2%%HIGHLIGHT%% ==Masked self-attention== %%POSTFIX%%To train a decoder, we maximize*
>%%LINK%%[[#^n7w9briwrk|show annotation]]
>%%COMMENT%%
>Here, we use autoregressive modelling with masked attention to train the model.
>
>If we use the whole sequence, the model can cheat; therefore, we only allow it to interact with current and past tokens through masking. 
>%%TAGS%%
>
^n7w9briwrk


>%%
>```annotation-json
>{"created":"2025-11-13T18:42:53.450Z","updated":"2025-11-13T18:42:53.450Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":502393,"end":502499},{"type":"TextQuoteSelector","exact":"ransformer layers use masked self-attention so that they canonly attend to the current and previous tokens","prefix":"ransformernetwork, but now the t","suffix":". Each of the output embeddings "}]}]}
>```
>%%
>*%%PREFIX%%ransformernetwork, but now the t%%HIGHLIGHT%% ==ransformer layers use masked self-attention so that they canonly attend to the current and previous tokens== %%POSTFIX%%. Each of the output embeddings*
>%%LINK%%[[#^001ytc33cv9hx|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^001ytc33cv9hx


>%%
>```annotation-json
>{"created":"2025-11-13T18:51:01.425Z","updated":"2025-11-13T18:51:01.425Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":503135,"end":503151},{"type":"TextQuoteSelector","exact":"generative model","prefix":"model is the first example of a ","suffix":" discussedin this book. Since it"}]}]}
>```
>%%
>*%%PREFIX%%model is the first example of a%%HIGHLIGHT%% ==generative model== %%POSTFIX%%discussedin this book. Since it*
>%%LINK%%[[#^tsjtk6wqqmm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tsjtk6wqqmm


>%%
>```annotation-json
>{"created":"2025-11-13T18:52:30.315Z","updated":"2025-11-13T18:52:30.315Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":503833,"end":503923},{"type":"TextQuoteSelector","exact":"computation canbe made quite eﬀicient as prior embeddings do not depend on subsequent ones","prefix":"erate large bodies of text. The ","suffix":" due toDraft: please send errata"}]}]}
>```
>%%
>*%%PREFIX%%erate large bodies of text. The%%HIGHLIGHT%% ==computation canbe made quite eﬀicient as prior embeddings do not depend on subsequent ones== %%POSTFIX%%due toDraft: please send errata*
>%%LINK%%[[#^te94v1lhsas|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^te94v1lhsas


>%%
>```annotation-json
>{"created":"2025-11-13T18:52:38.323Z","updated":"2025-11-13T18:52:38.323Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":504970,"end":505017},{"type":"TextQuoteSelector","exact":"much of the earlier computation can be recycled","prefix":"e masked self-attention. Hence, ","suffix":" as weProblem 12.7 generate subs"}]}]}
>```
>%%
>*%%PREFIX%%e masked self-attention. Hence,%%HIGHLIGHT%% ==much of the earlier computation can be recycled== %%POSTFIX%%as weProblem 12.7 generate subs*
>%%LINK%%[[#^gtrkoszv5bf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gtrkoszv5bf


>%%
>```annotation-json
>{"created":"2025-11-13T18:52:51.270Z","updated":"2025-11-13T18:52:51.270Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":505175,"end":505271},{"type":"TextQuoteSelector","exact":"beam search keeps track of multiple possible sentence completions to find the overall mostlikely","prefix":",Notebook 12.4Decodingstrategies","suffix":" (which is not necessarily found"}]}]}
>```
>%%
>*%%PREFIX%%,Notebook 12.4Decodingstrategies%%HIGHLIGHT%% ==beam search keeps track of multiple possible sentence completions to find the overall mostlikely== %%POSTFIX%%(which is not necessarily found*
>%%LINK%%[[#^10vc7youupqj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^10vc7youupqj


>%%
>```annotation-json
>{"created":"2025-11-13T18:52:58.738Z","updated":"2025-11-13T18:52:58.738Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":505365,"end":505452},{"type":"TextQuoteSelector","exact":"Top-k sampling randomly draws the next word from only the top-K mostlikely possibilitie","prefix":" likely next word ateach step). ","suffix":"s to prevent the system from acc"}]}]}
>```
>%%
>*%%PREFIX%%likely next word ateach step).%%HIGHLIGHT%% ==Top-k sampling randomly draws the next word from only the top-K mostlikely possibilitie== %%POSTFIX%%s to prevent the system from acc*
>%%LINK%%[[#^qk02qdiq8r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qk02qdiq8r


>%%
>```annotation-json
>{"created":"2025-11-13T18:53:11.007Z","updated":"2025-11-13T18:53:11.007Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":505512,"end":505545},{"type":"TextQuoteSelector","exact":"long tail oflow-probability token","prefix":" accidentally choosing from the ","suffix":"s and leading to an unnecessary "}]}]}
>```
>%%
>*%%PREFIX%%accidentally choosing from the%%HIGHLIGHT%% ==long tail oflow-probability token== %%POSTFIX%%s and leading to an unnecessary*
>%%LINK%%[[#^fvppdykok3j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fvppdykok3j


>%%
>```annotation-json
>{"created":"2025-11-13T18:53:33.848Z","text":"We start with a special *<start>* token, then we feed tokens word by word, adding to the sequence while simultaneously sampling from the distribution.\n\nMasked self-attention makes it efficient, earlier computation can be recycled.","updated":"2025-11-13T18:53:33.848Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":503045,"end":503075},{"type":"TextQuoteSelector","exact":"Generating text from a decoder","prefix":"ropy loss (figure 12.12).12.7.3 ","suffix":"The autoregressive language mode"}]}]}
>```
>%%
>*%%PREFIX%%ropy loss (figure 12.12).12.7.3%%HIGHLIGHT%% ==Generating text from a decoder== %%POSTFIX%%The autoregressive language mode*
>%%LINK%%[[#^7kvfntkubma|show annotation]]
>%%COMMENT%%
>We start with a special *<start>* token, then we feed tokens word by word, adding to the sequence while simultaneously sampling from the distribution.
>
>Masked self-attention makes it efficient, earlier computation can be recycled.
>%%TAGS%%
>
^7kvfntkubma


>%%
>```annotation-json
>{"created":"2025-11-13T19:01:45.798Z","updated":"2025-11-13T19:01:45.798Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":507413,"end":507454},{"type":"TextQuoteSelector","exact":"can perform manytasks without fine-tuning","prefix":"dels on this scale is that they ","suffix":". If we provide several examples"}]}]}
>```
>%%
>*%%PREFIX%%dels on this scale is that they%%HIGHLIGHT%% ==can perform manytasks without fine-tuning== %%POSTFIX%%. If we provide several examples*
>%%LINK%%[[#^c0qsl7kg6uw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c0qsl7kg6uw


>%%
>```annotation-json
>{"created":"2025-11-13T19:02:06.922Z","updated":"2025-11-13T19:02:06.922Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":508806,"end":508850},{"type":"TextQuoteSelector","exact":"normous language models are few-shotlearners","prefix":"onsequently, it is argued that e","suffix":"; they can learn to do novel tas"}]}]}
>```
>%%
>*%%PREFIX%%onsequently, it is argued that e%%HIGHLIGHT%% ==normous language models are few-shotlearners== %%POSTFIX%%; they can learn to do novel tas*
>%%LINK%%[[#^mav847p3mrq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mav847p3mrq


>%%
>```annotation-json
>{"created":"2025-11-13T19:02:15.221Z","updated":"2025-11-13T19:02:15.221Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":508923,"end":508956},{"type":"TextQuoteSelector","exact":"performance is erratic in practic","prefix":"on just a few examples. However,","suffix":"e, and the extent to which it is"}]}]}
>```
>%%
>*%%PREFIX%%on just a few examples. However,%%HIGHLIGHT%% ==performance is erratic in practic== %%POSTFIX%%e, and the extent to which it is*
>%%LINK%%[[#^foi72yfgtuo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^foi72yfgtuo


>%%
>```annotation-json
>{"created":"2025-11-14T10:14:36.332Z","text":"Enormous language models are few-shot learners.\n\nThey can perform numerous tasks without fine-tuning.","updated":"2025-11-14T10:14:36.332Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":505604,"end":505630},{"type":"TextQuoteSelector","exact":"GPT3 and few-shot learning","prefix":"sary linguistic dead end.12.7.4 ","suffix":"Large language models like GPT3 "}]}]}
>```
>%%
>*%%PREFIX%%sary linguistic dead end.12.7.4%%HIGHLIGHT%% ==GPT3 and few-shot learning== %%POSTFIX%%Large language models like GPT3*
>%%LINK%%[[#^t23z36smq08|show annotation]]
>%%COMMENT%%
>Enormous language models are few-shot learners.
>
>They can perform numerous tasks without fine-tuning.
>%%TAGS%%
>
^t23z36smq08


>%%
>```annotation-json
>{"created":"2025-11-14T10:20:31.265Z","updated":"2025-11-14T10:20:31.265Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":509768,"end":509789},{"type":"TextQuoteSelector","exact":"sequence-to-sequence ","prefix":"en languages is an example of a ","suffix":"task. This re-quires an encoder "}]}]}
>```
>%%
>*%%PREFIX%%en languages is an example of a%%HIGHLIGHT%% ==sequence-to-sequence== %%POSTFIX%%task. This re-quires an encoder*
>%%LINK%%[[#^7np0cgvdac|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7np0cgvdac


>%%
>```annotation-json
>{"created":"2025-11-14T10:20:41.193Z","updated":"2025-11-14T10:20:41.193Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":509976,"end":509997},{"type":"TextQuoteSelector","exact":"encoder-decoder model","prefix":"his task can be tackledusing an ","suffix":".Consider translating from Engli"}]}]}
>```
>%%
>*%%PREFIX%%his task can be tackledusing an%%HIGHLIGHT%% ==encoder-decoder model== %%POSTFIX%%.Consider translating from Engli*
>%%LINK%%[[#^chev1lrlte|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^chev1lrlte


>%%
>```annotation-json
>{"created":"2025-11-14T10:21:48.110Z","updated":"2025-11-14T10:21:48.110Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":510411,"end":510469},{"type":"TextQuoteSelector","exact":"he decoderlayers also attend to the output of the encoder.","prefix":"ord at each position. However, t","suffix":" Consequently, each French outpu"}]}]}
>```
>%%
>*%%PREFIX%%ord at each position. However, t%%HIGHLIGHT%% ==he decoderlayers also attend to the output of the encoder.== %%POSTFIX%%Consequently, each French outpu*
>%%LINK%%[[#^mik474r1ic|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mik474r1ic


>%%
>```annotation-json
>{"created":"2025-11-14T10:22:23.036Z","updated":"2025-11-14T10:22:23.036Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":511499,"end":511543},{"type":"TextQuoteSelector","exact":"encoder-decoder attention orcross-attention,","prefix":"sion of self-attention known as ","suffix":" where the queries are computed "}]}]}
>```
>%%
>*%%PREFIX%%sion of self-attention known as%%HIGHLIGHT%% ==encoder-decoder attention orcross-attention,== %%POSTFIX%%where the queries are computed*
>%%LINK%%[[#^9be528p59c|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9be528p59c


>%%
>```annotation-json
>{"created":"2025-11-14T10:22:38.671Z","updated":"2025-11-14T10:22:38.671Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":511550,"end":511653},{"type":"TextQuoteSelector","exact":"the queries are computed from the decoder embeddings and thekeys and values from the encoder embeddings","prefix":"ention orcross-attention, where ","suffix":" (figure 12.14).12.9 Transformer"}]}]}
>```
>%%
>*%%PREFIX%%ention orcross-attention, where%%HIGHLIGHT%% ==the queries are computed from the decoder embeddings and thekeys and values from the encoder embeddings== %%POSTFIX%%(figure 12.14).12.9 Transformer*
>%%LINK%%[[#^gd4yod2cg2r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gd4yod2cg2r


>%%
>```annotation-json
>{"created":"2025-11-14T10:25:26.550Z","text":"Translating between languages can be done with a *decoder-encoder* model. In such models, the decoder also attends to the outputs of the encoder.\nThe keys and values are computed based on the encoder (embeddings), and the queries are computed from the decoder (embeddings); this is *cross-attention*.","updated":"2025-11-14T10:25:26.550Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":509669,"end":509719},{"type":"TextQuoteSelector","exact":"Encoder-decoder model example: machine translation","prefix":"ord in the output sequence.12.8 ","suffix":"Translation between languages is"}]}]}
>```
>%%
>*%%PREFIX%%ord in the output sequence.12.8%%HIGHLIGHT%% ==Encoder-decoder model example: machine translation== %%POSTFIX%%Translation between languages is*
>%%LINK%%[[#^s3pdz9iu3v8|show annotation]]
>%%COMMENT%%
>Translating between languages can be done with a *decoder-encoder* model. In such models, the decoder also attends to the outputs of the encoder.
>The keys and values are computed based on the encoder (embeddings), and the queries are computed from the decoder (embeddings); this is *cross-attention*.
>%%TAGS%%
>
^s3pdz9iu3v8


>%%
>```annotation-json
>{"created":"2025-11-14T10:44:40.811Z","updated":"2025-11-14T10:44:40.811Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":511787,"end":511866},{"type":"TextQuoteSelector","exact":"thecomputational complexity scales quadratically with the length of the sequenc","prefix":"teracts with every other token, ","suffix":"e. For adecoder model, each toke"}]}]}
>```
>%%
>*%%PREFIX%%teracts with every other token,%%HIGHLIGHT%% ==thecomputational complexity scales quadratically with the length of the sequenc== %%POSTFIX%%e. For adecoder model, each toke*
>%%LINK%%[[#^k6jr3180lng|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^k6jr3180lng


>%%
>```annotation-json
>{"created":"2025-11-14T10:47:57.390Z","updated":"2025-11-14T10:47:57.390Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":513198,"end":513235},{"type":"TextQuoteSelector","exact":"rune the self-attention in-teractions","prefix":" sequences. One approach is to p","suffix":" or, equivalently, to sparsify t"}]}]}
>```
>%%
>*%%PREFIX%%sequences. One approach is to p%%HIGHLIGHT%% ==rune the self-attention in-teractions== %%POSTFIX%%or, equivalently, to sparsify t*
>%%LINK%%[[#^uhfl74cwimq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uhfl74cwimq


>%%
>```annotation-json
>{"created":"2025-11-14T10:48:03.651Z","updated":"2025-11-14T10:48:03.651Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":513257,"end":513288},{"type":"TextQuoteSelector","exact":"sparsify the interaction matrix","prefix":"teractions or, equivalently, to ","suffix":" (figures 12.15c-h). Forexample,"}]}]}
>```
>%%
>*%%PREFIX%%teractions or, equivalently, to%%HIGHLIGHT%% ==sparsify the interaction matrix== %%POSTFIX%%(figures 12.15c-h). Forexample,*
>%%LINK%%[[#^3xcxi10jcyf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3xcxi10jcyf


>%%
>```annotation-json
>{"created":"2025-11-14T10:48:15.829Z","updated":"2025-11-14T10:48:15.829Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":513350,"end":513437},{"type":"TextQuoteSelector","exact":"onvolutional structure so that each token only in-teracts with a few neighboring tokens","prefix":"e, this can be restricted to a c","suffix":". Across multiple layers, tokens"}]}]}
>```
>%%
>*%%PREFIX%%e, this can be restricted to a c%%HIGHLIGHT%% ==onvolutional structure so that each token only in-teracts with a few neighboring tokens== %%POSTFIX%%. Across multiple layers, tokens*
>%%LINK%%[[#^01egsv4xdmn9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^01egsv4xdmn9


>%%
>```annotation-json
>{"created":"2025-11-14T10:48:23.855Z","updated":"2025-11-14T10:48:23.855Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":513571,"end":513610},{"type":"TextQuoteSelector","exact":"ernelcan vary in size and dilation rate","prefix":"for convolution in images, the k","suffix":".A pure convolutional approach r"}]}]}
>```
>%%
>*%%PREFIX%%for convolution in images, the k%%HIGHLIGHT%% ==ernelcan vary in size and dilation rate== %%POSTFIX%%.A pure convolutional approach r*
>%%LINK%%[[#^suf1nhxqrae|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^suf1nhxqrae


>%%
>```annotation-json
>{"created":"2025-11-14T10:48:38.238Z","updated":"2025-11-14T10:48:38.238Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":513748,"end":513766},{"type":"TextQuoteSelector","exact":"llow select tokens","prefix":"to speed up this process is to a","suffix":" (perhaps atthe start of every s"}]}]}
>```
>%%
>*%%PREFIX%%to speed up this process is to a%%HIGHLIGHT%% ==llow select tokens== %%POSTFIX%%(perhaps atthe start of every s*
>%%LINK%%[[#^3jc5wdn5bwg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3jc5wdn5bwg


>%%
>```annotation-json
>{"created":"2025-11-14T10:48:44.270Z","updated":"2025-11-14T10:48:44.270Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":513807,"end":513837},{"type":"TextQuoteSelector","exact":"to attend to all other tokens ","prefix":" atthe start of every sentence) ","suffix":"(encoder model) or all previoust"}]}]}
>```
>%%
>*%%PREFIX%%atthe start of every sentence)%%HIGHLIGHT%% ==to attend to all other tokens== %%POSTFIX%%(encoder model) or all previoust*
>%%LINK%%[[#^anaoeen51n4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^anaoeen51n4


>%%
>```annotation-json
>{"created":"2025-11-14T10:49:03.265Z","updated":"2025-11-14T10:49:03.265Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":513921,"end":513949},{"type":"TextQuoteSelector","exact":"mall number of global tokens","prefix":"). A similar idea is to have a s","suffix":" thatconnect to all the other to"}]}]}
>```
>%%
>*%%PREFIX%%). A similar idea is to have a s%%HIGHLIGHT%% ==mall number of global tokens== %%POSTFIX%%thatconnect to all the other to*
>%%LINK%%[[#^09hxy6afvj6l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^09hxy6afvj6l


>%%
>```annotation-json
>{"created":"2025-11-14T10:49:13.149Z","updated":"2025-11-14T10:49:13.149Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":514030,"end":514101},{"type":"TextQuoteSelector","exact":"do notrepresent any word but serve to provide long-distance connections","prefix":"es. Like the <cls> token, these ","suffix":".12.10 Transformers for imagesTr"}]}]}
>```
>%%
>*%%PREFIX%%es. Like the <cls> token, these%%HIGHLIGHT%% ==do notrepresent any word but serve to provide long-distance connections== %%POSTFIX%%.12.10 Transformers for imagesTr*
>%%LINK%%[[#^dy2v4wrcwq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dy2v4wrcwq


>%%
>```annotation-json
>{"created":"2025-11-14T10:49:16.540Z","updated":"2025-11-14T10:49:16.540Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":514011,"end":514016},{"type":"TextQuoteSelector","exact":"<cls>","prefix":"tokens and themselves. Like the ","suffix":" token, these do notrepresent an"}]}]}
>```
>%%
>*%%PREFIX%%tokens and themselves. Like the%%HIGHLIGHT%% ==<cls>== %%POSTFIX%%token, these do notrepresent an*
>%%LINK%%[[#^x47l71yhzf9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^x47l71yhzf9


>%%
>```annotation-json
>{"created":"2025-11-14T10:49:43.384Z","text":"The computational complexity of the transformer scales quadratically with the sequence length.\n\nWe can mitigate this by sparsifying the interaction with pruning.\n1. Set up a convolutional style setup (local), which can vary in size and dilation.\n2. Set up global tokens that can provide long-distance connections.","updated":"2025-11-14T10:49:43.384Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":511674,"end":511705},{"type":"TextQuoteSelector","exact":"Transformers for long sequences","prefix":" embeddings (figure 12.14).12.9 ","suffix":"Since each token in a transforme"}]}]}
>```
>%%
>*%%PREFIX%%embeddings (figure 12.14).12.9%%HIGHLIGHT%% ==Transformers for long sequences== %%POSTFIX%%Since each token in a transforme*
>%%LINK%%[[#^qo4v0od1nnq|show annotation]]
>%%COMMENT%%
>The computational complexity of the transformer scales quadratically with the sequence length.
>
>We can mitigate this by sparsifying the interaction with pruning.
>1. Set up a convolutional style setup (local), which can vary in size and dilation.
>2. Set up global tokens that can provide long-distance connections.
>%%TAGS%%
>
^qo4v0od1nnq


>%%
>```annotation-json
>{"created":"2025-11-14T10:58:58.082Z","updated":"2025-11-14T10:58:58.082Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":514428,"end":514490},{"type":"TextQuoteSelector","exact":"here are many more pixels in an image than words in a sentence","prefix":" for images 229reasons. First, t","suffix":", so thequadratic complexity of "}]}]}
>```
>%%
>*%%PREFIX%%for images 229reasons. First, t%%HIGHLIGHT%% ==here are many more pixels in an image than words in a sentence== %%POSTFIX%%, so thequadratic complexity of*
>%%LINK%%[[#^mfe0pjuoncc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mfe0pjuoncc


>%%
>```annotation-json
>{"created":"2025-11-14T10:59:04.126Z","updated":"2025-11-14T10:59:04.126Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":514575,"end":514733},{"type":"TextQuoteSelector","exact":"convolutionalnets have a good inductive bias because each layer is equivariant to spatial translation,and they take into account the 2D structure of the image","prefix":"a practical bottleneck. Second, ","suffix":". However, this must be learnedi"}]}]}
>```
>%%
>*%%PREFIX%%a practical bottleneck. Second,%%HIGHLIGHT%% ==convolutionalnets have a good inductive bias because each layer is equivariant to spatial translation,and they take into account the 2D structure of the image== %%POSTFIX%%. However, this must be learnedi*
>%%LINK%%[[#^tkykx84vk5l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tkykx84vk5l


>%%
>```annotation-json
>{"created":"2025-11-14T10:59:09.817Z","updated":"2025-11-14T10:59:09.817Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":514749,"end":514788},{"type":"TextQuoteSelector","exact":"must be learnedin a transformer network","prefix":"ure of the image. However, this ","suffix":".Regardless of these apparent di"}]}]}
>```
>%%
>*%%PREFIX%%ure of the image. However, this%%HIGHLIGHT%% ==must be learnedin a transformer network== %%POSTFIX%%.Regardless of these apparent di*
>%%LINK%%[[#^yw8ftc5z4zr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yw8ftc5z4zr


>%%
>```annotation-json
>{"created":"2025-11-14T10:59:19.563Z","updated":"2025-11-14T10:59:19.563Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":514974,"end":515114},{"type":"TextQuoteSelector","exact":"artly because of the enormous scale at which they can be constructedand the large amounts of data that can be used to pre-train the networks","prefix":"cation and othertasks. This is p","suffix":". This sectiondescribes transfor"}]}]}
>```
>%%
>*%%PREFIX%%cation and othertasks. This is p%%HIGHLIGHT%% ==artly because of the enormous scale at which they can be constructedand the large amounts of data that can be used to pre-train the networks== %%POSTFIX%%. This sectiondescribes transfor*
>%%LINK%%[[#^6gnnabzuupf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6gnnabzuupf


>%%
>```annotation-json
>{"created":"2025-11-14T10:59:49.781Z","text":"Transformers are not intuitively applicable to images because,\n1. Large number of pixels\n2. CNNs have high inductive bias\n\nThis has been mitigated by \n1. Scale of construction of models\n2. Large amount of data that can be used for pre-training","updated":"2025-11-14T10:59:49.781Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":514108,"end":514131},{"type":"TextQuoteSelector","exact":"Transformers for images","prefix":"long-distance connections.12.10 ","suffix":"Transformers were initially deve"}]}]}
>```
>%%
>*%%PREFIX%%long-distance connections.12.10%%HIGHLIGHT%% ==Transformers for images== %%POSTFIX%%Transformers were initially deve*
>%%LINK%%[[#^l8wx1euq6dk|show annotation]]
>%%COMMENT%%
>Transformers are not intuitively applicable to images because,
>1. Large number of pixels
>2. CNNs have high inductive bias
>
>This has been mitigated by 
>1. Scale of construction of models
>2. Large amount of data that can be used for pre-training
>%%TAGS%%
>
^l8wx1euq6dk


>%%
>```annotation-json
>{"created":"2025-11-14T13:34:31.530Z","updated":"2025-11-14T13:34:31.530Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":518741,"end":518862},{"type":"TextQuoteSelector","exact":"trong inductive bias of convolutional networks can onlybe superseded by employing extremely large amounts of training dat","prefix":"utsupervised pre-training. The s","suffix":"a.12.10.3 Multi-scale vision tra"}]}]}
>```
>%%
>*%%PREFIX%%utsupervised pre-training. The s%%HIGHLIGHT%% ==trong inductive bias of convolutional networks can onlybe superseded by employing extremely large amounts of training dat== %%POSTFIX%%a.12.10.3 Multi-scale vision tra*
>%%LINK%%[[#^c877dqmaxb8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c877dqmaxb8


>%%
>```annotation-json
>{"created":"2025-11-14T17:21:42.562Z","updated":"2025-11-14T17:21:42.562Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":515458,"end":515498},{"type":"TextQuoteSelector","exact":"could still only operate on 64×64 images","prefix":"ontained6.8 billion parameters) ","suffix":". Moreover, to make thistractabl"}]}]}
>```
>%%
>*%%PREFIX%%ontained6.8 billion parameters)%%HIGHLIGHT%% ==could still only operate on 64×64 images== %%POSTFIX%%. Moreover, to make thistractabl*
>%%LINK%%[[#^r8rmhewlwr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r8rmhewlwr


>%%
>```annotation-json
>{"created":"2025-11-14T17:21:55.626Z","updated":"2025-11-14T17:21:55.626Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":515546,"end":515615},{"type":"TextQuoteSelector","exact":"24-bit RGB color space had to be quantized into a nine-bit colorspace","prefix":"ake thistractable, the original ","suffix":", so the system ingests (and pre"}]}]}
>```
>%%
>*%%PREFIX%%ake thistractable, the original%%HIGHLIGHT%% ==24-bit RGB color space had to be quantized into a nine-bit colorspace== %%POSTFIX%%, so the system ingests (and pre*
>%%LINK%%[[#^f4dnp9dkew|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f4dnp9dkew


>%%
>```annotation-json
>{"created":"2025-11-14T17:22:09.584Z","updated":"2025-11-14T17:22:09.584Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":515752,"end":515801},{"type":"TextQuoteSelector","exact":"earns a different positionalencoding at each pixe","prefix":"D objects, but ImageGPT simply l","suffix":"l. Hence it must learn that each"}]}]}
>```
>%%
>*%%PREFIX%%D objects, but ImageGPT simply l%%HIGHLIGHT%% ==earns a different positionalencoding at each pixe== %%POSTFIX%%l. Hence it must learn that each*
>%%LINK%%[[#^nmcg6oahjc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nmcg6oahjc


>%%
>```annotation-json
>{"created":"2025-11-14T17:22:17.564Z","updated":"2025-11-14T17:22:17.564Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":515830,"end":515937},{"type":"TextQuoteSelector","exact":"ach pixel has a close relationship withits preceding neighbors and also with nearby pixels in the row above","prefix":"ixel. Hence it must learn that e","suffix":". Figure 12.16 showsexample gene"}]}]}
>```
>%%
>*%%PREFIX%%ixel. Hence it must learn that e%%HIGHLIGHT%% ==ach pixel has a close relationship withits preceding neighbors and also with nearby pixels in the row above== %%POSTFIX%%. Figure 12.16 showsexample gene*
>%%LINK%%[[#^w7bwnq52uom|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w7bwnq52uom


>%%
>```annotation-json
>{"created":"2025-11-14T17:22:27.523Z","updated":"2025-11-14T17:22:27.523Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":516032,"end":516072},{"type":"TextQuoteSelector","exact":"used as a basis for image classification","prefix":"resentation of this decoder was ","suffix":".The final pixel embeddings are "}]}]}
>```
>%%
>*%%PREFIX%%resentation of this decoder was%%HIGHLIGHT%% ==used as a basis for image classification== %%POSTFIX%%.The final pixel embeddings are*
>%%LINK%%[[#^hzsfqnuhqr5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hzsfqnuhqr5


>%%
>```annotation-json
>{"created":"2025-11-14T17:23:04.531Z","updated":"2025-11-14T17:23:04.531Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":516783,"end":516847},{"type":"TextQuoteSelector","exact":"ails to classify images where the target object is small or thin","prefix":" image size; unsurprisingly,it f","suffix":".12.10.2 Vision Transformer (ViT"}]}]}
>```
>%%
>*%%PREFIX%%image size; unsurprisingly,it f%%HIGHLIGHT%% ==ails to classify images where the target object is small or thin== %%POSTFIX%%.12.10.2 Vision Transformer (ViT*
>%%LINK%%[[#^rt0korjdipf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rt0korjdipf


>%%
>```annotation-json
>{"created":"2025-11-14T17:23:12.254Z","updated":"2025-11-14T17:23:12.254Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":516884,"end":516903},{"type":"TextQuoteSelector","exact":"Vision Transformer ","prefix":"0.2 Vision Transformer (ViT)The ","suffix":"tackled the problem of image res"}]}]}
>```
>%%
>*%%PREFIX%%0.2 Vision Transformer (ViT)The%%HIGHLIGHT%% ==Vision Transformer== %%POSTFIX%%tackled the problem of image res*
>%%LINK%%[[#^4mx2idnfjq6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4mx2idnfjq6


>%%
>```annotation-json
>{"created":"2025-11-14T17:23:16.996Z","updated":"2025-11-14T17:23:16.996Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":516970,"end":516982},{"type":"TextQuoteSelector","exact":"6×16 patches","prefix":"tion by dividing the imageinto 1","suffix":" (figure 12.17). Each patch is m"}]}]}
>```
>%%
>*%%PREFIX%%tion by dividing the imageinto 1%%HIGHLIGHT%% ==6×16 patches== %%POSTFIX%%(figure 12.17). Each patch is m*
>%%LINK%%[[#^693lsj1m555|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^693lsj1m555


>%%
>```annotation-json
>{"created":"2025-11-14T17:23:31.045Z","updated":"2025-11-14T17:23:31.045Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":516999,"end":517151},{"type":"TextQuoteSelector","exact":"Each patch is mapped to a lower dimension via a Problem 12.8learned linear transformation, and these representations are fed into the transformernetwork","prefix":"o 16×16 patches (figure 12.17). ","suffix":". Once again, standard 1D positi"}]}]}
>```
>%%
>*%%PREFIX%%o 16×16 patches (figure 12.17).%%HIGHLIGHT%% ==Each patch is mapped to a lower dimension via a Problem 12.8learned linear transformation, and these representations are fed into the transformernetwork== %%POSTFIX%%. Once again, standard 1D positi*
>%%LINK%%[[#^az4g0jn3mwc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^az4g0jn3mwc


>%%
>```annotation-json
>{"created":"2025-11-14T17:23:39.915Z","updated":"2025-11-14T17:23:39.915Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":517165,"end":517209},{"type":"TextQuoteSelector","exact":"standard 1D positional encodings are learned","prefix":"transformernetwork. Once again, ","suffix":".This is an encoder model with a"}]}]}
>```
>%%
>*%%PREFIX%%transformernetwork. Once again,%%HIGHLIGHT%% ==standard 1D positional encodings are learned== %%POSTFIX%%.This is an encoder model with a*
>%%LINK%%[[#^4xefd284ncl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4xefd284ncl


>%%
>```annotation-json
>{"created":"2025-11-14T17:23:53.022Z","updated":"2025-11-14T17:23:53.022Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":517404,"end":517545},{"type":"TextQuoteSelector","exact":"The <cls> token is mapped via a final network layer tocreate activations that are fed into a softmax function to generate class probabilities","prefix":"eledimages from 18,000 classes. ","suffix":".After pre-training, the system "}]}]}
>```
>%%
>*%%PREFIX%%eledimages from 18,000 classes.%%HIGHLIGHT%% ==The <cls> token is mapped via a final network layer tocreate activations that are fed into a softmax function to generate class probabilities== %%POSTFIX%%.After pre-training, the system*
>%%LINK%%[[#^am8td9bdpbl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^am8td9bdpbl


>%%
>```annotation-json
>{"created":"2025-11-14T17:24:34.237Z","updated":"2025-11-14T17:24:34.237Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":518907,"end":519003},{"type":"TextQuoteSelector","exact":"Vision Transformer differs from convolutional architectures in that it operates ona single scale","prefix":"ti-scale vision transformersThe ","suffix":". Several transformer models tha"}]}]}
>```
>%%
>*%%PREFIX%%ti-scale vision transformersThe%%HIGHLIGHT%% ==Vision Transformer differs from convolutional architectures in that it operates ona single scale== %%POSTFIX%%. Several transformer models tha*
>%%LINK%%[[#^5d0jspe5686|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5d0jspe5686


>%%
>```annotation-json
>{"created":"2025-11-14T17:25:02.151Z","updated":"2025-11-14T17:25:02.151Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":520636,"end":520699},{"type":"TextQuoteSelector","exact":"multi-scale transformer is the shifted-window or SWintransforme","prefix":"rsA representative example of a ","suffix":"r. This is an encoder transforme"}]}]}
>```
>%%
>*%%PREFIX%%rsA representative example of a%%HIGHLIGHT%% ==multi-scale transformer is the shifted-window or SWintransforme== %%POSTFIX%%r. This is an encoder transforme*
>%%LINK%%[[#^5r5a1nyixld|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5r5a1nyixld


>%%
>```annotation-json
>{"created":"2025-11-14T17:25:44.945Z","updated":"2025-11-14T17:25:44.945Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":520714,"end":520869},{"type":"TextQuoteSelector","exact":"ncoder transformer that divides the image into patches andgroups these patches into a grid of windows within which self-attention is applied in-dependently","prefix":"or SWintransformer. This is an e","suffix":" (figure 12.18). These windows a"}]}]}
>```
>%%
>*%%PREFIX%%or SWintransformer. This is an e%%HIGHLIGHT%% ==ncoder transformer that divides the image into patches andgroups these patches into a grid of windows within which self-attention is applied in-dependently== %%POSTFIX%%(figure 12.18). These windows a*
>%%LINK%%[[#^jno2r9i1hkn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jno2r9i1hkn


>%%
>```annotation-json
>{"created":"2025-11-14T17:25:53.310Z","updated":"2025-11-14T17:25:53.310Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":520886,"end":521021},{"type":"TextQuoteSelector","exact":"These windows are shifted in adjacent transformers, so theeffective receptive field at a given patch can expand beyond the window borde","prefix":" in-dependently (figure 12.18). ","suffix":"r.The scale is reduced periodica"}]}]}
>```
>%%
>*%%PREFIX%%in-dependently (figure 12.18).%%HIGHLIGHT%% ==These windows are shifted in adjacent transformers, so theeffective receptive field at a given patch can expand beyond the window borde== %%POSTFIX%%r.The scale is reduced periodica*
>%%LINK%%[[#^07tmm1nq2iwp|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^07tmm1nq2iwp


>%%
>```annotation-json
>{"created":"2025-11-14T17:26:03.281Z","updated":"2025-11-14T17:26:03.281Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":521023,"end":521228},{"type":"TextQuoteSelector","exact":"The scale is reduced periodically by concatenating features from non-overlapping 2×2patches and applying a linear transformation that maps these concatenated features totwice the original number of channel","prefix":"expand beyond the window border.","suffix":"s. This architecture does not ha"}]}]}
>```
>%%
>*%%PREFIX%%expand beyond the window border.%%HIGHLIGHT%% ==The scale is reduced periodically by concatenating features from non-overlapping 2×2patches and applying a linear transformation that maps these concatenated features totwice the original number of channel== %%POSTFIX%%s. This architecture does not ha*
>%%LINK%%[[#^7esqc4gnggp|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7esqc4gnggp


>%%
>```annotation-json
>{"created":"2025-11-14T17:26:14.330Z","updated":"2025-11-14T17:26:14.330Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":521231,"end":521334},{"type":"TextQuoteSelector","exact":"This architecture does not have a <cls> tokenbut instead averages the output features at the last layer","prefix":"he original number of channels. ","suffix":". These are then mapped via alin"}]}]}
>```
>%%
>*%%PREFIX%%he original number of channels.%%HIGHLIGHT%% ==This architecture does not have a <cls> tokenbut instead averages the output features at the last layer== %%POSTFIX%%. These are then mapped via alin*
>%%LINK%%[[#^8t100muj533|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8t100muj533


>%%
>```annotation-json
>{"created":"2025-11-14T17:46:53.545Z","updated":"2025-11-14T17:46:53.545Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":528098,"end":528126},{"type":"TextQuoteSelector","exact":"SQuAD question-answering tas","prefix":"al., 2019b), which includes the ","suffix":"k (Rajpurkar et al., 2016)descri"}]}]}
>```
>%%
>*%%PREFIX%%al., 2019b), which includes the%%HIGHLIGHT%% ==SQuAD question-answering tas== %%POSTFIX%%k (Rajpurkar et al., 2016)descri*
>%%LINK%%[[#^ow7b1d1ybq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ow7b1d1ybq


>%%
>```annotation-json
>{"created":"2025-11-14T17:46:57.524Z","updated":"2025-11-14T17:46:57.524Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":528181,"end":528190},{"type":"TextQuoteSelector","exact":"SuperGLUE","prefix":"16)described in section 12.6.2, ","suffix":" (Wang et al., 2019a) and BIG-be"}]}]}
>```
>%%
>*%%PREFIX%%16)described in section 12.6.2,%%HIGHLIGHT%% ==SuperGLUE== %%POSTFIX%%(Wang et al., 2019a) and BIG-be*
>%%LINK%%[[#^qq73pfzxk5d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qq73pfzxk5d


>%%
>```annotation-json
>{"created":"2025-11-14T17:47:00.961Z","updated":"2025-11-14T17:47:00.961Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":528216,"end":528225},{"type":"TextQuoteSelector","exact":"BIG-bench","prefix":"erGLUE (Wang et al., 2019a) and ","suffix":" (Srivastava et al.,2022), which"}]}]}
>```
>%%
>*%%PREFIX%%erGLUE (Wang et al., 2019a) and%%HIGHLIGHT%% ==BIG-bench== %%POSTFIX%%(Srivastava et al.,2022), which*
>%%LINK%%[[#^fgj064a47we|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fgj064a47we


>%%
>```annotation-json
>{"created":"2025-11-14T17:47:53.165Z","updated":"2025-11-14T17:47:53.165Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":529212,"end":529320},{"type":"TextQuoteSelector","exact":"text is highlycompressible, this model has more than enough capacity to memorize the entire training dataset","prefix":"rocessors. Interestingly, since ","suffix":".This is true for many language "}]}]}
>```
>%%
>*%%PREFIX%%rocessors. Interestingly, since%%HIGHLIGHT%% ==text is highlycompressible, this model has more than enough capacity to memorize the entire training dataset== %%POSTFIX%%.This is true for many language*
>%%LINK%%[[#^w9hpfezqy0l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w9hpfezqy0l


>%%
>```annotation-json
>{"created":"2025-11-14T17:50:55.092Z","updated":"2025-11-14T17:50:55.092Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":531050,"end":531071},{"type":"TextQuoteSelector","exact":"SentencePiece library","prefix":"guage model are included in the ","suffix":" (Kudo &Richardson, 2018), which"}]}]}
>```
>%%
>*%%PREFIX%%guage model are included in the%%HIGHLIGHT%% ==SentencePiece library== %%POSTFIX%%(Kudo &Richardson, 2018), which*
>%%LINK%%[[#^656i0qhfthd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^656i0qhfthd


>%%
>```annotation-json
>{"created":"2025-11-14T17:51:01.937Z","updated":"2025-11-14T17:51:01.937Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":531098,"end":531171},{"type":"TextQuoteSelector","exact":"which works directly on Unicode characters and can work with any language","prefix":"brary (Kudo &Richardson, 2018), ","suffix":".He et al. (2020) introduce a me"}]}]}
>```
>%%
>*%%PREFIX%%brary (Kudo &Richardson, 2018),%%HIGHLIGHT%% ==which works directly on Unicode characters and can work with any language== %%POSTFIX%%.He et al. (2020) introduce a me*
>%%LINK%%[[#^q079fosumt|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^q079fosumt


>%%
>```annotation-json
>{"created":"2025-11-14T17:51:45.631Z","updated":"2025-11-14T17:51:45.631Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":532134,"end":532149},{"type":"TextQuoteSelector","exact":"teacher forcing","prefix":"f ground truth tokens (known as ","suffix":") butsees its own output when de"}]}]}
>```
>%%
>*%%PREFIX%%f ground truth tokens (known as%%HIGHLIGHT%% ==teacher forcing== %%POSTFIX%%) butsees its own output when de*
>%%LINK%%[[#^s7fsrmpvron|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^s7fsrmpvron


>%%
>```annotation-json
>{"created":"2025-11-14T17:52:08.586Z","updated":"2025-11-14T17:52:08.586Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":532411,"end":532422},{"type":"TextQuoteSelector","exact":"beam search","prefix":"rall sequence. This is known as ","suffix":". Beam search tends to produce m"}]}]}
>```
>%%
>*%%PREFIX%%rall sequence. This is known as%%HIGHLIGHT%% ==beam search== %%POSTFIX%%. Beam search tends to produce m*
>%%LINK%%[[#^z6vbxf4sib|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^z6vbxf4sib


>%%
>```annotation-json
>{"created":"2025-11-14T17:52:35.321Z","updated":"2025-11-14T17:52:35.321Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":532772,"end":532786},{"type":"TextQuoteSelector","exact":"top-K sampling","prefix":"is hasled to the development of ","suffix":", in which tokens are sampled fr"}]}]}
>```
>%%
>*%%PREFIX%%is hasled to the development of%%HIGHLIGHT%% ==top-K sampling== %%POSTFIX%%, in which tokens are sampled fr*
>%%LINK%%[[#^1xvcs5d9n1y|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1xvcs5d9n1y


>%%
>```annotation-json
>{"created":"2025-11-14T17:53:05.490Z","updated":"2025-11-14T17:53:05.490Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":533046,"end":533062},{"type":"TextQuoteSelector","exact":"nucleus sampling","prefix":" Holtzmanet al. (2020) proposed ","suffix":", in which tokens are sampled fr"}]}]}
>```
>%%
>*%%PREFIX%%Holtzmanet al. (2020) proposed%%HIGHLIGHT%% ==nucleus sampling== %%POSTFIX%%, in which tokens are sampled fr*
>%%LINK%%[[#^cgm7w61swn6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cgm7w61swn6


>%%
>```annotation-json
>{"created":"2025-11-14T18:04:13.080Z","updated":"2025-11-14T18:04:13.080Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":536883,"end":536965},{"type":"TextQuoteSelector","exact":"add the positional encodings to the D ×N data matrix X rather thanconcatenate them","prefix":"encoding Π.It might seem odd to ","suffix":". However, the data dimension D "}]}]}
>```
>%%
>*%%PREFIX%%encoding Π.It might seem odd to%%HIGHLIGHT%% ==add the positional encodings to the D ×N data matrix X rather thanconcatenate them== %%POSTFIX%%. However, the data dimension D*
>%%LINK%%[[#^fau99ibfsyj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fau99ibfsyj


>%%
>```annotation-json
>{"created":"2025-11-14T18:04:18.442Z","updated":"2025-11-14T18:04:18.442Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":536976,"end":537089},{"type":"TextQuoteSelector","exact":"the data dimension D is usually greater than the number oftokens N, so the positional encoding lies in a subspace","prefix":" thanconcatenate them. However, ","suffix":". The word embeddings in X are l"}]}]}
>```
>%%
>*%%PREFIX%%thanconcatenate them. However,%%HIGHLIGHT%% ==the data dimension D is usually greater than the number oftokens N, so the positional encoding lies in a subspace== %%POSTFIX%%. The word embeddings in X are l*
>%%LINK%%[[#^3xdvxi08j8w|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3xdvxi08j8w


>%%
>```annotation-json
>{"created":"2025-11-14T18:04:27.848Z","updated":"2025-11-14T18:04:27.848Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":537091,"end":537255},{"type":"TextQuoteSelector","exact":"The word embeddings in X are learned,so the system can theoretically keep the two components in orthogonal subspaces and retrievethe positional encodings as require","prefix":"al encoding lies in a subspace. ","suffix":"d. The predefined embeddings cho"}]}]}
>```
>%%
>*%%PREFIX%%al encoding lies in a subspace.%%HIGHLIGHT%% ==The word embeddings in X are learned,so the system can theoretically keep the two components in orthogonal subspaces and retrievethe positional encodings as require== %%POSTFIX%%d. The predefined embeddings cho*
>%%LINK%%[[#^qtvmeqvo8le|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qtvmeqvo8le


>%%
>```annotation-json
>{"created":"2025-11-14T18:04:33.319Z","updated":"2025-11-14T18:04:33.319Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":537322,"end":537352},{"type":"TextQuoteSelector","exact":"family of sinusoidal component","prefix":" by Vaswani et al.(2017) were a ","suffix":"s with two attractive properties"}]}]}
>```
>%%
>*%%PREFIX%%by Vaswani et al.(2017) were a%%HIGHLIGHT%% ==family of sinusoidal component== %%POSTFIX%%s with two attractive properties*
>%%LINK%%[[#^wm0s5ic64nj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wm0s5ic64nj


>%%
>```annotation-json
>{"created":"2025-11-14T18:04:40.808Z","updated":"2025-11-14T18:04:40.808Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":537390,"end":537471},{"type":"TextQuoteSelector","exact":"the relativeposition of two embeddings is easy to recover using a linear operatio","prefix":" two attractive properties: (i) ","suffix":"n and (ii) their dot productgene"}]}]}
>```
>%%
>*%%PREFIX%%two attractive properties: (i)%%HIGHLIGHT%% ==the relativeposition of two embeddings is easy to recover using a linear operatio== %%POSTFIX%%n and (ii) their dot productgene*
>%%LINK%%[[#^3xbumxn1yho|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3xbumxn1yho


>%%
>```annotation-json
>{"created":"2025-11-14T18:04:47.548Z","updated":"2025-11-14T18:04:47.548Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":537481,"end":537562},{"type":"TextQuoteSelector","exact":" their dot productgenerally decreased as the distance between positions increased","prefix":"sing a linear operation and (ii)","suffix":" (see Prince, 2021a, for moredet"}]}]}
>```
>%%
>*%%PREFIX%%sing a linear operation and (ii)%%HIGHLIGHT%% ==their dot productgenerally decreased as the distance between positions increased== %%POSTFIX%%(see Prince, 2021a, for moredet*
>%%LINK%%[[#^djdpjggk357|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^djdpjggk357


>%%
>```annotation-json
>{"created":"2025-11-14T18:09:25.355Z","updated":"2025-11-14T18:09:25.355Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":540158,"end":540320},{"type":"TextQuoteSelector","exact":"The first decreases the size of theattention matrix, the second makes the attention sparse, and the third modifies the attentionmechanism to make it more eﬀicient","prefix":"empted to address this problem. ","suffix":".To decrease the size of the att"}]}]}
>```
>%%
>*%%PREFIX%%empted to address this problem.%%HIGHLIGHT%% ==The first decreases the size of theattention matrix, the second makes the attention sparse, and the third modifies the attentionmechanism to make it more eﬀicient== %%POSTFIX%%.To decrease the size of the att*
>%%LINK%%[[#^r6lvzf4qw5h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r6lvzf4qw5h


>%%
>```annotation-json
>{"created":"2025-11-14T18:09:37.826Z","updated":"2025-11-14T18:09:37.826Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":540397,"end":540423},{"type":"TextQuoteSelector","exact":"memory-compressedattention","prefix":", Liu et al. (2018b) introduced ","suffix":". This applies strided convoluti"}]}]}
>```
>%%
>*%%PREFIX%%, Liu et al. (2018b) introduced%%HIGHLIGHT%% ==memory-compressedattention== %%POSTFIX%%. This applies strided convoluti*
>%%LINK%%[[#^5h690lng4f5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5h690lng4f5


>%%
>```annotation-json
>{"created":"2025-11-14T18:14:23.127Z","updated":"2025-11-14T18:14:23.127Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":541001,"end":541016},{"type":"TextQuoteSelector","exact":"local attention","prefix":"se, Liu et al. (2018b) proposed ","suffix":", in which neighboringblocks of "}]}]}
>```
>%%
>*%%PREFIX%%se, Liu et al. (2018b) proposed%%HIGHLIGHT%% ==local attention== %%POSTFIX%%, in which neighboringblocks of*
>%%LINK%%[[#^a9x06pktiuu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^a9x06pktiuu


>%%
>```annotation-json
>{"created":"2025-11-14T18:15:43.738Z","updated":"2025-11-14T18:15:43.738Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":542328,"end":542584},{"type":"TextQuoteSelector","exact":"umerator and denominator of the softmax oper-ation that computes attention have the form exp[kT q]. This can be treated as a kernel functionand, as such, can be expressed as the dot product g[k]T g[q] where g[•] is a nonlinear transforma- Problem 12.10tion","prefix":"en noted that the terms in the n","suffix":". This formulation decouples the"}]}]}
>```
>%%
>*%%PREFIX%%en noted that the terms in the n%%HIGHLIGHT%% ==umerator and denominator of the softmax oper-ation that computes attention have the form exp[kT q]. This can be treated as a kernel functionand, as such, can be expressed as the dot product g[k]T g[q] where g[•] is a nonlinear transforma- Problem 12.10tion== %%POSTFIX%%. This formulation decouples the*
>%%LINK%%[[#^up9patfe07m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^up9patfe07m


>%%
>```annotation-json
>{"created":"2025-11-14T18:15:49.096Z","updated":"2025-11-14T18:15:49.096Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":542587,"end":542810},{"type":"TextQuoteSelector","exact":"his formulation decouples the queries and keys, making the attention computation moreeﬀicient. Unfortunately, to replicate the form of the exponential terms, the transformation g[•]must map the inputs to the infinite space.","prefix":"transforma- Problem 12.10tion. T","suffix":" The linear transformer (Katharo"}]}]}
>```
>%%
>*%%PREFIX%%transforma- Problem 12.10tion. T%%HIGHLIGHT%% ==his formulation decouples the queries and keys, making the attention computation moreeﬀicient. Unfortunately, to replicate the form of the exponential terms, the transformation g[•]must map the inputs to the infinite space.== %%POSTFIX%%The linear transformer (Katharo*
>%%LINK%%[[#^dury2xvefi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dury2xvefi
