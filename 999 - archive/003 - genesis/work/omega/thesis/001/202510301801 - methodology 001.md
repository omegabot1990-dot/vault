---
tags:
  - work
aliases:
  - methodology 001
title: methodology 001
description:
parent nodes:
  - "[[202510300118 - proposal 001]]"
child nodes:
annotation-target:
---

### **Phase 1 – Literature & Feasibility Study**

- Review existing work:
    
    - ==LLMs in mental health (e.g., Wysa, Replika, Woebot, Youper).==
        
    - Emotion classification & sentiment models.
        
    - Federated learning for sensitive data.
        
    - Edge deployment & quantisation techniques.
        
- Define an ethical framework & risk boundaries (non-diagnostic, reflective use only).
    
- Scoping & Ethics
    
    - Define _non-diagnostic_ boundaries, escalation and crisis disclaimers, and consent UX.
        
    - Curate a safe, evidence-based RAG corpus (burnout, perfectionism, journaling, CBT psychoeducation).
        
    - IRB/ethics pre-screen; DPIA for GDPR; data handling SOP.
        

---

### **Phase 2 – Model Selection & Training Setup (Reasoning Adaptation)**

- Select candidate small LLM architectures:
    
    - **Phi-2**, **TinyLlama**, **Mistral-7B**, or **DistilGPT-2**.
        
- Choose fine-tuning method:
    
    - **Instruction tuning** on emotion-support dialogue datasets (**EmpatheticDialogues**, **DailyDialog++**, **RECCON**).
        
    - Use **LoRA** or **PEFT** for lightweight domain adaptation.
        
- Add **CoT/R1-style distillation** from a stronger teacher for _reasoning traces_ (planning, reframing, journaling scaffolds).
	
	- CoT/R1-style distillation = teaching a smaller model to “think out loud” like a more capable teacher, learning _how_ to reason, not just _what_ to answer.
		
	- Train a smaller, human-centric AI model by having it **imitate the reasoning patterns** of a more advanced model (the teacher) on synthetic mental health–related tasks, such as emotion journaling or cognitive reframing.  
		
	- The goal is to:
			
		- Teach structured reasoning aligned with empathy and psychological insight.
		    
		- Ensure outputs remain **explainable**, **safe**, and **context-aware**.
		    
		- Avoid relying solely on sensitive real-world user data.
	    
- Implement a **Planner–Solver–Checker** controller with unit tests using synthetic dialogues.
    

---

### **Phase 3 – RAG & Tools**

- Develop a **RAG pipeline** with curated psychoeducational documents for contextual grounding.
    
- Build a **retriever–reranker** pipeline (hybrid bi-encoder + BM25) with citation insertion.
    
- Train **emotion/state classifier** (EN first; NL via translate-train or multilingual backbone).
    
- Implement a **safety checker** (rule-based + small classifier for red-flag detection).
    
- Prototype a **lightweight NCF recommender** (implicit feedback from opt-in pilot/simulations).
    

---

### **Phase 4 – Emotional Understanding Layer**

- Train a **lightweight transformer-based emotion classifier** to detect emotional tone and context.
    
- Integrate this layer with the conversational model to guide empathetic and context-aware responses.
    
- Simulate **federated learning** (Flower or FedML) for distributed emotion model updates.
    

---

### **Phase 5 – Edge Deployment, Optimisation & Federated Simulation**

- Experiment with **quantisation** (INT8/4-bit) and **distillation** to deploy models on low-resource devices (Jetson Nano, Raspberry Pi, smartphone).
    
    - Quantise LoRA heads for domain; measure latency and energy on Jetson/RPi/Android.
        
- Measure **latency, throughput, and energy consumption**.
    
- Compare **edge vs. cloud inference**.
    
- Log **carbon/energy usage** (Joules/Wh per request).
    
- Run **federated simulations**: multiple clients with local logs → aggregate classifier/recommender weights (no raw text).
    

---

### **Phase 6 – Validation, Evaluation & User Study**

- **User Study / Expert Review**
    
    - Conduct simulated interactions with psychology students or therapists.
        
    - Evaluate empathy, coherence, and helpfulness.
        
- **Quantitative Metrics**
    
    - BLEU / ROUGE / BERTScore (for coherence).
        
    - Emotion alignment (F1-score).
        
    - Energy efficiency (Joules/conversation, latency, tokens/sec).
        
- **Qualitative Metrics**
    
    - User satisfaction, perceived empathy, and ethical compliance (Likert-scale).
        
- **Reasoning Quality**
    
    - _Faithfulness_: groundedness rate, citation correctness.
        
    - _Consistency_: contradiction rate across multi-turns.
        
    - _Planning quality_: expert rubric (journaling coverage, CBT reframing accuracy).
        
- **Conversation Quality**
    
    - Empathy/Helpfulness (Likert), coherence (BERTScore/MAUVE).
        
- **Safety/Scope**
    
    - % diagnostic claims (target ≈ 0), refusal correctness, escalation correctness.
        
- **Efficiency**
    
    - Latency, tokens/sec, energy per conversation; edge vs. server.
        
- **Multilingual**
    
    - Parallel prompts in EN/NL — measure performance deltas.
        
- **A/B Studies**
    
    - Compare with/without Planner–Checker and RAG grounding.
        

---

### **Phase 7 – Reporting & Ethics Review**

- Document architecture, training pipeline, and evaluation results.
    
- Discuss ethical implications, limitations, and real-world deployment potential.
    
- Prepare final **thesis report**, ablations, limitations, ethics appendix, and reproducible code.
    
- **Demo:** deploy a working prototype (Jetson/Android app) with on-device inference and opt-in federated toggle.
    

---