---
tags:
  - work
  - reference
aliases:
  - motivation
title: motivation for omega
description: why am i doing the project
parent nodes:
  - "[[omega]]"
child nodes:
annotation-target:
---

Growing up in India, I often heard that men should not show emotions. This belief, deeply ingrained through social conditioning, made it difficult for me to handle emotional challenges and ask for help when I needed it most. The stigma around psychology, together with limited access to affordable mental health resources, only increased that sense of isolation.

In recent years, awareness of issues like depression and anxiety has increased, but subjects such as burnout, perfectionism, emotional repression, and chronic stress are still mostly misunderstood or ignored. Many individuals internalise these experiences quietly, accepting exhaustion and self-criticism as a normal part of daily life. These less visible struggles often go unnoticed until they develop into serious problems. One-third of young people display poor knowledge of mental health problems and negative attitudes towards people with mental health problems. [^1]

An accessible, non-judgmental tool that introduces people to **psychoeducation**, **journaling**, and **emotion exploration** could serve as an early bridge to self-understanding, helping individuals develop emotional literacy and resilience well before reaching a crisis point. This belief forms the foundation of my motivation to create an empathetic, human-centred AI assistant for emotional well-being.


[^1]: [Stigma associated with mental health problems among young people in India: a systematic review of magnitude, manifestations and recommendations](https://pubmed.ncbi.nlm.nih.gov/33198678/)
---

Poor accessibility to mental-health services is driving many people to treat ChatGPT and similar tools as de facto mental-health advisers. For example, recent surveys show that roughly one-third of U.S. adults (34%) have used ChatGPT, and about 1 in 6 adults (17%) report using AI chatbots at least monthly for health information or advice, suggesting that millions already turn to AI for health and wellness-related questions.  

An accessible, anonymous assistant that introduces people to mental health care through psychoeducation and evidence-based self-help (for example: structured journaling, brief CBT exercises, grounding and breathing practices, behavioural activation, sleep hygiene, and mood tracking) could act as an early bridge to self-understanding. Such a tool would help users develop emotional literacy and resilience well before they reach crisis—lowering barriers to care, normalising help-seeking, and increasing the chance that people will access professional support when needed. Research already documents widespread informal use of LLMs for wellbeing. It shows clinicians and community members experimenting with AI tools, which underlines both the opportunity and the need for safe, evidence-based design.

---

%% 
(resources:: Resources - 202510161533)
%%
> [!info] 2025-10-16
> > [!example] **Resources:**
> > - [Mental health stigma India](https://chatgpt.com/s/t_68f0f416cd148191bc56d4d4a4d38599)


