---
tags:
  - academic
  - cc
aliases:
  - computational creativity - lecture three
title: natural language generation - statistical methods
description: computational creativity - natural language generation - statistical methods - annotated
parent nodes:
  - "[[computational creativity]]"
child nodes: 
annotation-target: computational_creativity_03b_natural_language_generation_statistical_methods.pdf
---




>%%
>```annotation-json
>{"created":"2024-10-01T13:45:39.608Z","updated":"2024-10-01T13:45:39.608Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":523,"end":535},{"type":"TextQuoteSelector","exact":"Bag of Words","prefix":"r the world at Leiden University","suffix":"Model assumption: Some words are"}]}]}
>```
>%%
>*%%PREFIX%%r the world at Leiden University%%HIGHLIGHT%% ==Bag of Words== %%POSTFIX%%Model assumption: Some words are*
>%%LINK%%[[#^ulco6zm8v7k|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ulco6zm8v7k


>%%
>```annotation-json
>{"created":"2024-10-01T13:48:28.766Z","text":"What are modelling languages with n-grams? ","updated":"2024-10-01T13:48:28.766Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":1017,"end":1049},{"type":"TextQuoteSelector","exact":"Modelling Languages with N-grams","prefix":"r the world at Leiden University","suffix":"Constructing n-grams is a common"}]}]}
>```
>%%
>*%%PREFIX%%r the world at Leiden University%%HIGHLIGHT%% ==Modelling Languages with N-grams== %%POSTFIX%%Constructing n-grams is a common*
>%%LINK%%[[#^7heevo9d4cs|show annotation]]
>%%COMMENT%%
>What are modelling languages with n-grams? 
>%%TAGS%%
>#question
^7heevo9d4cs


>%%
>```annotation-json
>{"created":"2024-10-01T13:49:03.890Z","updated":"2024-10-01T13:49:03.890Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":1316,"end":1547},{"type":"TextQuoteSelector","exact":"N-grams: sequences of n words e.g. construct n-grams of different lengths for “This is a sentence.” n = 1 (unigrams): this | is | a | sentence n = 2 (bigrams): this is | is a | a sentence n = 3 (trigrams): this is a | is a sentence","prefix":"ld a statistical language model ","suffix":"Discover the world at Leiden Uni"}]}]}
>```
>%%
>*%%PREFIX%%ld a statistical language model%%HIGHLIGHT%% ==N-grams: sequences of n words e.g. construct n-grams of different lengths for “This is a sentence.” n = 1 (unigrams): this | is | a | sentence n = 2 (bigrams): this is | is a | a sentence n = 3 (trigrams): this is a | is a sentence== %%POSTFIX%%Discover the world at Leiden Uni*
>%%LINK%%[[#^ez69bw3ctgw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ez69bw3ctgw


>%%
>```annotation-json
>{"created":"2024-10-01T13:50:58.458Z","text":"What are Markov chains?","updated":"2024-10-01T13:50:58.458Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":2563,"end":2576},{"type":"TextQuoteSelector","exact":"Markov Chains","prefix":"r the world at Leiden University","suffix":"What are Markov chains? A Markov"}]}]}
>```
>%%
>*%%PREFIX%%r the world at Leiden University%%HIGHLIGHT%% ==Markov Chains== %%POSTFIX%%What are Markov chains? A Markov*
>%%LINK%%[[#^aoj53ixzwoh|show annotation]]
>%%COMMENT%%
>What are Markov chains?
>%%TAGS%%
>#question
^aoj53ixzwoh


>%%
>```annotation-json
>{"created":"2024-10-01T13:52:02.801Z","updated":"2024-10-01T13:52:02.801Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":2600,"end":2723},{"type":"TextQuoteSelector","exact":"A Markov chain describes the probability of a system transitioning from one state to any other state within a state space. ","prefix":"v ChainsWhat are Markov chains? ","suffix":"Constructing a Language Model Ca"}]}]}
>```
>%%
>*%%PREFIX%%v ChainsWhat are Markov chains?%%HIGHLIGHT%% ==A Markov chain describes the probability of a system transitioning from one state to any other state within a state space.== %%POSTFIX%%Constructing a Language Model Ca*
>%%LINK%%[[#^q9aon72myl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^q9aon72myl


>%%
>```annotation-json
>{"created":"2024-10-01T13:52:36.332Z","updated":"2024-10-01T13:52:36.332Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":2753,"end":2855},{"type":"TextQuoteSelector","exact":"Can be constructed from a text using n-grams to calculate probabilities of transitioning between words","prefix":". Constructing a Language Model ","suffix":" Generating with Markov Chains F"}]}]}
>```
>%%
>*%%PREFIX%%. Constructing a Language Model%%HIGHLIGHT%% ==Can be constructed from a text using n-grams to calculate probabilities of transitioning between words== %%POSTFIX%%Generating with Markov Chains F*
>%%LINK%%[[#^na4wjctj4u|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^na4wjctj4u


>%%
>```annotation-json
>{"created":"2024-10-01T13:52:49.380Z","updated":"2024-10-01T13:52:49.380Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":2886,"end":2956},{"type":"TextQuoteSelector","exact":"For each state choose the next state based on transition probabilities","prefix":"s Generating with Markov Chains ","suffix":"Source: Aja HammerlyDiscover the"}]}]}
>```
>%%
>*%%PREFIX%%s Generating with Markov Chains%%HIGHLIGHT%% ==For each state choose the next state based on transition probabilities== %%POSTFIX%%Source: Aja HammerlyDiscover the*
>%%LINK%%[[#^cz8t5f09can|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cz8t5f09can


>%%
>```annotation-json
>{"created":"2024-10-01T13:53:56.870Z","text":"How to generate text using Markov's Chains?","updated":"2024-10-01T13:53:56.870Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":3015,"end":3061},{"type":"TextQuoteSelector","exact":"Process for Generating Text with Markov Chains","prefix":"r the world at Leiden University","suffix":"Process and split source text in"}]}]}
>```
>%%
>*%%PREFIX%%r the world at Leiden University%%HIGHLIGHT%% ==Process for Generating Text with Markov Chains== %%POSTFIX%%Process and split source text in*
>%%LINK%%[[#^m6ijd4tjucp|show annotation]]
>%%COMMENT%%
>How to generate text using Markov's Chains?
>%%TAGS%%
>#question
^m6ijd4tjucp


>%%
>```annotation-json
>{"created":"2024-10-01T13:54:34.752Z","updated":"2024-10-01T13:54:34.752Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":3061,"end":3212},{"type":"TextQuoteSelector","exact":"Process and split source text into tokens Tokens might be characters, words, stems etc. Processing may include cleaning up text to make it more uniform","prefix":"nerating Text with Markov Chains","suffix":" Construct n-grams of tokens (st"}]}]}
>```
>%%
>*%%PREFIX%%nerating Text with Markov Chains%%HIGHLIGHT%% ==Process and split source text into tokens Tokens might be characters, words, stems etc. Processing may include cleaning up text to make it more uniform== %%POSTFIX%%Construct n-grams of tokens (st*
>%%LINK%%[[#^8m6zvalcovt|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8m6zvalcovt


>%%
>```annotation-json
>{"created":"2024-10-01T13:56:45.905Z","updated":"2024-10-01T13:56:45.905Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":3213,"end":3345},{"type":"TextQuoteSelector","exact":"Construct n-grams of tokens (states in the Markov chain) Traverse the sequence of tokens and combine tokens into unique groups of n ","prefix":"up text to make it more uniform ","suffix":"For each n-gram record all of th"}]}]}
>```
>%%
>*%%PREFIX%%up text to make it more uniform%%HIGHLIGHT%% ==Construct n-grams of tokens (states in the Markov chain) Traverse the sequence of tokens and combine tokens into unique groups of n== %%POSTFIX%%For each n-gram record all of th*
>%%LINK%%[[#^6uxt2m31u6u|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6uxt2m31u6u


>%%
>```annotation-json
>{"created":"2024-10-01T13:57:07.084Z","updated":"2024-10-01T13:57:07.084Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":3345,"end":3479},{"type":"TextQuoteSelector","exact":"For each n-gram record all of the possible next tokens This constitutes the possible outputs (emissions) of the model in a given state","prefix":" tokens into unique groups of n ","suffix":" Given a starting n-gram, emit n"}]}]}
>```
>%%
>*%%PREFIX%%tokens into unique groups of n%%HIGHLIGHT%% ==For each n-gram record all of the possible next tokens This constitutes the possible outputs (emissions) of the model in a given state== %%POSTFIX%%Given a starting n-gram, emit n*
>%%LINK%%[[#^1sbv3km63hig|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1sbv3km63hig


>%%
>```annotation-json
>{"created":"2024-10-01T13:58:48.618Z","updated":"2024-10-01T13:58:48.618Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":3480,"end":3655},{"type":"TextQuoteSelector","exact":"Given a starting n-gram, emit next token, construct n-gram and repeat Next n-gram is constructing by dropping first token in current n-gram and adding emitted token to the end","prefix":") of the model in a given state ","suffix":"Discover the world at Leiden Uni"}]}]}
>```
>%%
>*%%PREFIX%%) of the model in a given state%%HIGHLIGHT%% ==Given a starting n-gram, emit next token, construct n-gram and repeat Next n-gram is constructing by dropping first token in current n-gram and adding emitted token to the end== %%POSTFIX%%Discover the world at Leiden Uni*
>%%LINK%%[[#^hcxb3kn5ch7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hcxb3kn5ch7


>%%
>```annotation-json
>{"created":"2024-10-01T14:02:31.227Z","text":"What are the pros and cons of Markov's Chains?","updated":"2024-10-01T14:02:31.227Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":5669,"end":5886},{"type":"TextQuoteSelector","exact":"Pros: Simple to implement Local consistency Diverse range of possible inputs Cons: Knowledge implicit in text Requires careful curation of text Lack of long-range structure Limited to words in text (no generalisation)","prefix":"t Leiden UniversityMarkov Chains","suffix":"Discover the world at Leiden Uni"}]}]}
>```
>%%
>*%%PREFIX%%t Leiden UniversityMarkov Chains%%HIGHLIGHT%% ==Pros: Simple to implement Local consistency Diverse range of possible inputs Cons: Knowledge implicit in text Requires careful curation of text Lack of long-range structure Limited to words in text (no generalisation)== %%POSTFIX%%Discover the world at Leiden Uni*
>%%LINK%%[[#^cxjc7tnta4f|show annotation]]
>%%COMMENT%%
>What are the pros and cons of Markov's Chains?
>%%TAGS%%
>#question
^cxjc7tnta4f


>%%
>```annotation-json
>{"created":"2024-10-01T14:05:44.075Z","updated":"2024-10-01T14:05:44.075Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":6018,"end":6037},{"type":"TextQuoteSelector","exact":"What do words mean?","prefix":"r the world at Leiden University","suffix":"A word can have multiple meaning"}]}]}
>```
>%%
>*%%PREFIX%%r the world at Leiden University%%HIGHLIGHT%% ==What do words mean?== %%POSTFIX%%A word can have multiple meaning*
>%%LINK%%[[#^d0rni0xs3c|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^d0rni0xs3c


>%%
>```annotation-json
>{"created":"2024-10-01T14:05:49.040Z","updated":"2024-10-01T14:05:49.040Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":6037,"end":6082},{"type":"TextQuoteSelector","exact":"A word can have multiple meanings (or senses)","prefix":"en UniversityWhat do words mean?","suffix":" e.g. the word ‘poetry’ has six "}]}]}
>```
>%%
>*%%PREFIX%%en UniversityWhat do words mean?%%HIGHLIGHT%% ==A word can have multiple meanings (or senses)== %%POSTFIX%%e.g. the word ‘poetry’ has six*
>%%LINK%%[[#^lh70eias6m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lh70eias6m


>%%
>```annotation-json
>{"created":"2024-10-01T14:05:57.748Z","updated":"2024-10-01T14:05:57.748Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":6163,"end":6217},{"type":"TextQuoteSelector","exact":"Synonyms have the same meaning in some or all contexts","prefix":"n the Oxford English Dictionary ","suffix":" e.g.    couch ↔ sofa    big ↔ l"}]}]}
>```
>%%
>*%%PREFIX%%n the Oxford English Dictionary%%HIGHLIGHT%% ==Synonyms have the same meaning in some or all contexts== %%POSTFIX%%e.g.    couch ↔ sofa    big ↔ l*
>%%LINK%%[[#^m6z19bynueo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^m6z19bynueo


>%%
>```annotation-json
>{"created":"2024-10-01T14:07:18.226Z","updated":"2024-10-01T14:07:18.226Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":6292,"end":6351},{"type":"TextQuoteSelector","exact":"Antonyms are opposite meaning w.r.t. one feature or meaning","prefix":"omobile ↔ car    bicycle ↔ bike ","suffix":" Antonyms can define binary oppo"}]}]}
>```
>%%
>*%%PREFIX%%omobile ↔ car    bicycle ↔ bike%%HIGHLIGHT%% ==Antonyms are opposite meaning w.r.t. one feature or meaning== %%POSTFIX%%Antonyms can define binary oppo*
>%%LINK%%[[#^cqlofitimrk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cqlofitimrk


>%%
>```annotation-json
>{"created":"2024-10-01T14:07:57.146Z","updated":"2024-10-01T14:07:57.146Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":6649,"end":6659},{"type":"TextQuoteSelector","exact":"Similarity","prefix":"niversityRelations Between Words","suffix":" Non-synonyms can still share so"}]}]}
>```
>%%
>*%%PREFIX%%niversityRelations Between Words%%HIGHLIGHT%% ==Similarity== %%POSTFIX%%Non-synonyms can still share so*
>%%LINK%%[[#^endzrwv6khk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^endzrwv6khk


>%%
>```annotation-json
>{"created":"2024-10-01T14:08:03.855Z","updated":"2024-10-01T14:08:03.855Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":6746,"end":6757},{"type":"TextQuoteSelector","exact":"Relatedness","prefix":"g, e.g., car∼bicycle, cow∼horse ","suffix":" Non-similar words can still be "}]}]}
>```
>%%
>*%%PREFIX%%g, e.g., car∼bicycle, cow∼horse%%HIGHLIGHT%% ==Relatedness== %%POSTFIX%%Non-similar words can still be*
>%%LINK%%[[#^qpyqnxwyu9e|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qpyqnxwyu9e


>%%
>```annotation-json
>{"created":"2024-10-01T14:09:01.756Z","updated":"2024-10-01T14:09:01.756Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":6855,"end":6864},{"type":"TextQuoteSelector","exact":"Semantics","prefix":"lar), bicycle : pedal (related) ","suffix":" Words from a domain, e.g., hosp"}]}]}
>```
>%%
>*%%PREFIX%%lar), bicycle : pedal (related)%%HIGHLIGHT%% ==Semantics== %%POSTFIX%%Words from a domain, e.g., hosp*
>%%LINK%%[[#^f5rrf3rs9vm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f5rrf3rs9vm


>%%
>```annotation-json
>{"created":"2024-10-01T14:09:15.034Z","updated":"2024-10-01T14:09:15.034Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":6957,"end":6984},{"type":"TextQuoteSelector","exact":"Subordinate / Superordinate","prefix":"e), cafes (menu, waiter, plate) ","suffix":" Subordinates are more specific "}]}]}
>```
>%%
>*%%PREFIX%%e), cafes (menu, waiter, plate)%%HIGHLIGHT%% ==Subordinate / Superordinate== %%POSTFIX%%Subordinates are more specific*
>%%LINK%%[[#^hbkce841os|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hbkce841os


>%%
>```annotation-json
>{"created":"2024-10-01T14:09:18.193Z","updated":"2024-10-01T14:09:18.193Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":7072,"end":7083},{"type":"TextQuoteSelector","exact":"Connotation","prefix":"., car < vehicle, mango < fruit ","suffix":" Words have affective meaning, e"}]}]}
>```
>%%
>*%%PREFIX%%., car < vehicle, mango < fruit%%HIGHLIGHT%% ==Connotation== %%POSTFIX%%Words have affective meaning, e*
>%%LINK%%[[#^i067q9pxdvs|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^i067q9pxdvs


>%%
>```annotation-json
>{"created":"2024-10-01T14:11:15.397Z","text":"What are word embeddings?","updated":"2024-10-01T14:11:15.397Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":8404,"end":8419},{"type":"TextQuoteSelector","exact":"Word Embeddings","prefix":"r the world at Leiden University","suffix":"Represent words as vectors in a "}]}]}
>```
>%%
>*%%PREFIX%%r the world at Leiden University%%HIGHLIGHT%% ==Word Embeddings== %%POSTFIX%%Represent words as vectors in a*
>%%LINK%%[[#^4clpg756obd|show annotation]]
>%%COMMENT%%
>What are word embeddings?
>%%TAGS%%
>#question
^4clpg756obd


>%%
>```annotation-json
>{"created":"2024-10-01T14:11:40.211Z","updated":"2024-10-01T14:11:40.211Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":8419,"end":8474},{"type":"TextQuoteSelector","exact":"Represent words as vectors in a high-dimensional space ","prefix":"Leiden UniversityWord Embeddings","suffix":"Called an embedding because word"}]}]}
>```
>%%
>*%%PREFIX%%Leiden UniversityWord Embeddings%%HIGHLIGHT%% ==Represent words as vectors in a high-dimensional space== %%POSTFIX%%Called an embedding because word*
>%%LINK%%[[#^qqj8jrtkpzo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qqj8jrtkpzo


>%%
>```annotation-json
>{"created":"2024-10-01T14:12:21.818Z","updated":"2024-10-01T14:12:21.818Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":8611,"end":8675},{"type":"TextQuoteSelector","exact":"Supports generalised model based on meaning, e.g., similar words","prefix":"o represent word meaning in NLP ","suffix":" Used in NLU (e.g. sentiment ana"}]}]}
>```
>%%
>*%%PREFIX%%o represent word meaning in NLP%%HIGHLIGHT%% ==Supports generalised model based on meaning, e.g., similar words== %%POSTFIX%%Used in NLU (e.g. sentiment ana*
>%%LINK%%[[#^00elhy1bgak4e|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^00elhy1bgak4e


>%%
>```annotation-json
>{"created":"2024-10-01T14:12:32.575Z","updated":"2024-10-01T14:12:32.575Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":8752,"end":8759},{"type":"TextQuoteSelector","exact":"tf-idf ","prefix":"G (e.g. conversational systems) ","suffix":"Sparse vectors (20-50k mostly ze"}]}]}
>```
>%%
>*%%PREFIX%%G (e.g. conversational systems)%%HIGHLIGHT%% ==tf-idf== %%POSTFIX%%Sparse vectors (20-50k mostly ze*
>%%LINK%%[[#^vjjpt4pgp4m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vjjpt4pgp4m


>%%
>```annotation-json
>{"created":"2024-10-01T14:13:07.239Z","updated":"2024-10-01T14:13:07.239Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":8839,"end":8862},{"type":"TextQuoteSelector","exact":"Word2Vec / GloVe / etc.","prefix":"frequency count of nearby words ","suffix":" Dense vectors (<1k non-zeros) p"}]}]}
>```
>%%
>*%%PREFIX%%frequency count of nearby words%%HIGHLIGHT%% ==Word2Vec / GloVe / etc.== %%POSTFIX%%Dense vectors (<1k non-zeros) p*
>%%LINK%%[[#^x08agf7joqo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^x08agf7joqo


>%%
>```annotation-json
>{"created":"2024-10-01T14:14:11.153Z","updated":"2024-10-01T14:14:11.153Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":8988,"end":8996},{"type":"TextQuoteSelector","exact":"Word2Vec","prefix":"Leiden UniversityWord Embeddings","suffix":" Trains a classifier to distingu"}]}]}
>```
>%%
>*%%PREFIX%%Leiden UniversityWord Embeddings%%HIGHLIGHT%% ==Word2Vec== %%POSTFIX%%Trains a classifier to distingu*
>%%LINK%%[[#^gpn7b65m8o6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gpn7b65m8o6


>%%
>```annotation-json
>{"created":"2024-10-01T14:14:36.236Z","updated":"2024-10-01T14:14:36.236Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":9239,"end":9244},{"type":"TextQuoteSelector","exact":"GloVe","prefix":"t word appears near other words ","suffix":" Focuses on word co-occurrences "}]}]}
>```
>%%
>*%%PREFIX%%t word appears near other words%%HIGHLIGHT%% ==GloVe== %%POSTFIX%%Focuses on word co-occurrences*
>%%LINK%%[[#^m1n2itbdlt|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^m1n2itbdlt


>%%
>```annotation-json
>{"created":"2024-10-01T14:16:15.496Z","text":"What is the continuous bag of words for Word2Vec?","updated":"2024-10-01T14:16:15.496Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":9417,"end":9450},{"type":"TextQuoteSelector","exact":"Word2Vec: Continuous Bag of Words","prefix":"r the world at Leiden University","suffix":"Learn to predict rather than cou"}]}]}
>```
>%%
>*%%PREFIX%%r the world at Leiden University%%HIGHLIGHT%% ==Word2Vec: Continuous Bag of Words== %%POSTFIX%%Learn to predict rather than cou*
>%%LINK%%[[#^6tyskhn2ugf|show annotation]]
>%%COMMENT%%
>What is the continuous bag of words for Word2Vec?
>%%TAGS%%
>#question
^6tyskhn2ugf


>%%
>```annotation-json
>{"created":"2024-10-01T14:18:00.769Z","updated":"2024-10-01T14:18:00.769Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":9450,"end":9707},{"type":"TextQuoteSelector","exact":"Learn to predict rather than count words Instead of counting how often each word wc occurs near target word wt Train a classifier on a binary prediction task: Is wc likely to appear near wt? Weights of the learned classifier are used as the word embeddings.","prefix":"ord2Vec: Continuous Bag of Words","suffix":" Text provides (implicitly) supe"}]}]}
>```
>%%
>*%%PREFIX%%ord2Vec: Continuous Bag of Words%%HIGHLIGHT%% ==Learn to predict rather than count words Instead of counting how often each word wc occurs near target word wt Train a classifier on a binary prediction task: Is wc likely to appear near wt? Weights of the learned classifier are used as the word embeddings.== %%POSTFIX%%Text provides (implicitly) supe*
>%%LINK%%[[#^vqjvzxswa3f|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vqjvzxswa3f


>%%
>```annotation-json
>{"created":"2024-10-01T14:18:26.604Z","updated":"2024-10-01T14:18:26.604Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":9708,"end":9852},{"type":"TextQuoteSelector","exact":"Text provides (implicitly) supervised training data i.e. the appearance of the word wc near wt provides a ‘correct answer’ to the prediction tas","prefix":"re used as the word embeddings. ","suffix":"kDiscover the world at Leiden Un"}]}]}
>```
>%%
>*%%PREFIX%%re used as the word embeddings.%%HIGHLIGHT%% ==Text provides (implicitly) supervised training data i.e. the appearance of the word wc near wt provides a ‘correct answer’ to the prediction tas== %%POSTFIX%%kDiscover the world at Leiden Un*
>%%LINK%%[[#^tbiu8y14ndf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tbiu8y14ndf


>%%
>```annotation-json
>{"created":"2024-10-01T14:25:31.635Z","text":"What is skip-gram with negative sampling for Word2Vec?","updated":"2024-10-01T14:25:31.635Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":9892,"end":9934},{"type":"TextQuoteSelector","exact":"Word2Vec: Skip-Gram with Negative Sampling","prefix":"r the world at Leiden University","suffix":"Skip-Gram Algorithm  1. Treat th"}]}]}
>```
>%%
>*%%PREFIX%%r the world at Leiden University%%HIGHLIGHT%% ==Word2Vec: Skip-Gram with Negative Sampling== %%POSTFIX%%Skip-Gram Algorithm  1. Treat th*
>%%LINK%%[[#^ldaay2uxbt|show annotation]]
>%%COMMENT%%
>What is skip-gram with negative sampling for Word2Vec?
>%%TAGS%%
>#question
^ldaay2uxbt


>%%
>```annotation-json
>{"created":"2024-10-01T14:26:52.263Z","updated":"2024-10-01T14:26:52.263Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":9934,"end":10220},{"type":"TextQuoteSelector","exact":"Skip-Gram Algorithm  1. Treat the target word and a neighbouring context word as positive examples. 2. Randomly sample other words in the lexicon to get negative samples 3. Use logistic regression to train a classifier to distinguish those two cases 4. Use the weights as the embeddings","prefix":"Skip-Gram with Negative Sampling","suffix":" Example Training Sentence ... l"}]}]}
>```
>%%
>*%%PREFIX%%Skip-Gram with Negative Sampling%%HIGHLIGHT%% ==Skip-Gram Algorithm  1. Treat the target word and a neighbouring context word as positive examples. 2. Randomly sample other words in the lexicon to get negative samples 3. Use logistic regression to train a classifier to distinguish those two cases 4. Use the weights as the embeddings== %%POSTFIX%%Example Training Sentence ... l*
>%%LINK%%[[#^a6v4e8x7bgl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^a6v4e8x7bgl


>%%
>```annotation-json
>{"created":"2024-10-01T14:28:33.556Z","updated":"2024-10-01T14:28:33.556Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":10441,"end":10582},{"type":"TextQuoteSelector","exact":"Skip-Gram Goal Given a tuple (t, c) = target, context Return probability that c is a context word: P(+ | t, c) P(- | t, c) = 1 - P(+ | t, c) ","prefix":"Skip-Gram with Negative Sampling","suffix":"Intuition: Words are likely to a"}]}]}
>```
>%%
>*%%PREFIX%%Skip-Gram with Negative Sampling%%HIGHLIGHT%% ==Skip-Gram Goal Given a tuple (t, c) = target, context Return probability that c is a context word: P(+ | t, c) P(- | t, c) = 1 - P(+ | t, c)== %%POSTFIX%%Intuition: Words are likely to a*
>%%LINK%%[[#^h778dc2gjh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^h778dc2gjh


>%%
>```annotation-json
>{"created":"2024-10-01T14:28:47.521Z","updated":"2024-10-01T14:28:47.521Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":10582,"end":10690},{"type":"TextQuoteSelector","exact":"Intuition: Words are likely to appear near similar words Similarity computed using the dot product of vector","prefix":") P(- | t, c) = 1 - P(+ | t, c) ","suffix":"sDiscover the world at Leiden Un"}]}]}
>```
>%%
>*%%PREFIX%%) P(- | t, c) = 1 - P(+ | t, c)%%HIGHLIGHT%% ==Intuition: Words are likely to appear near similar words Similarity computed using the dot product of vector== %%POSTFIX%%sDiscover the world at Leiden Un*
>%%LINK%%[[#^54d2iebsq7y|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^54d2iebsq7y


>%%
>```annotation-json
>{"created":"2024-10-01T14:30:25.857Z","updated":"2024-10-01T14:30:25.857Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":11092,"end":11752},{"type":"TextQuoteSelector","exact":"To produce vectors of length 300 for a vocabulary V from text T using a context size C: Create an initial embedding of V random word vectors, each 300 long Iterate over all T to train a classifier using logistic regression: Positive examples = pairs of words (t, c) that co-occur within C Negative examples = pairs of words (t, c) that don’t co-occur within C Improve classifier by adjusting each word vector (t, c) such that: Maximise similarity of target and context word vectors from positive samples Minimise similarity of target and context word vectors from negative samples Once trained, throw away the classifier and keep the word vectors as embeddings","prefix":"tyWord2Vec: Outline of Algorithm","suffix":"Discover the world at Leiden Uni"}]}]}
>```
>%%
>*%%PREFIX%%tyWord2Vec: Outline of Algorithm%%HIGHLIGHT%% ==To produce vectors of length 300 for a vocabulary V from text T using a context size C: Create an initial embedding of V random word vectors, each 300 long Iterate over all T to train a classifier using logistic regression: Positive examples = pairs of words (t, c) that co-occur within C Negative examples = pairs of words (t, c) that don’t co-occur within C Improve classifier by adjusting each word vector (t, c) such that: Maximise similarity of target and context word vectors from positive samples Minimise similarity of target and context word vectors from negative samples Once trained, throw away the classifier and keep the word vectors as embeddings== %%POSTFIX%%Discover the world at Leiden Uni*
>%%LINK%%[[#^r3f78tc95j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r3f78tc95j



>%%
>```annotation-json
>{"created":"2024-10-01T14:33:59.058Z","updated":"2024-10-01T14:33:59.058Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":12181,"end":12385},{"type":"TextQuoteSelector","exact":"Relational Meanings Relations between words are captured differences between pairs of word embeddings ...and groups of words Constructing Analogies king - man + woman ≈ queen Paris - France + Italy ≈ Rome","prefix":"ityWord2Vec: Relational Meanings","suffix":"Discover the world at Leiden Uni"}]}]}
>```
>%%
>*%%PREFIX%%ityWord2Vec: Relational Meanings%%HIGHLIGHT%% ==Relational Meanings Relations between words are captured differences between pairs of word embeddings ...and groups of words Constructing Analogies king - man + woman ≈ queen Paris - France + Italy ≈ Rome== %%POSTFIX%%Discover the world at Leiden Uni*
>%%LINK%%[[#^mo6z710p25b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mo6z710p25b


>%%
>```annotation-json
>{"created":"2024-10-01T14:36:14.705Z","updated":"2024-10-01T14:36:14.705Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":13071,"end":13107},{"type":"TextQuoteSelector","exact":"Similarity depends on context size C","prefix":"rd2Vec: Properties of Embeddings","suffix":": For example, given a corpus of"}]}]}
>```
>%%
>*%%PREFIX%%rd2Vec: Properties of Embeddings%%HIGHLIGHT%% ==Similarity depends on context size C== %%POSTFIX%%: For example, given a corpus of*
>%%LINK%%[[#^ua434c53p5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ua434c53p5


>%%
>```annotation-json
>{"created":"2024-10-01T14:36:19.708Z","updated":"2024-10-01T14:36:19.708Z","document":{"title":"03b Natural Language Generation Statistical Methods","link":[{"href":"urn:x-pdf:e63cac061a3112220f85baaef46b5aa2"},{"href":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf"}],"documentFingerprint":"e63cac061a3112220f85baaef46b5aa2"},"uri":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","target":[{"source":"vault:/500 - attachments/computational_creativity_03b_natural_language_generation_statistical_methods.pdf","selector":[{"type":"TextPositionSelector","start":13254,"end":13295},{"type":"TextQuoteSelector","exact":"Warning, embeddings reflect cultural bias","prefix":": Dumbledore, Malfoy, halfblood ","suffix":": Paris : France ∷ Tokyo : Japan"}]}]}
>```
>%%
>*%%PREFIX%%: Dumbledore, Malfoy, halfblood%%HIGHLIGHT%% ==Warning, embeddings reflect cultural bias== %%POSTFIX%%: Paris : France ∷ Tokyo : Japan*
>%%LINK%%[[#^230amqesy7z|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^230amqesy7z
