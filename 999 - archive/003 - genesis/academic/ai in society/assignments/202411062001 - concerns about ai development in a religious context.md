---
tags:
  - academic
  - ais
aliases:
  - concerns about ai development in a religious context
title: concerns about ai development in a religious context
description: concerns/critiques about AI development in the context of religion as a domain
parent nodes:
  - "[[ai in society]]"
child nodes: 
annotation-target:
---


## Cues

1. Give me an outline for the essay.
   In the rapidly evolving field of artificial intelligence, the promise of objectivity and impartiality is often highlighted as a hallmark. However, a growing body of critique reveals a different narrative: AI systems frequently inherit and amplify the biases in their training data, leading to discriminatory practices. This issue is especially pronounced in the context of religious beliefs, where biased algorithms can perpetuate stereotypes and deepen societal divisions.
   One of the most pressing problems addressed by this critique is the reinforcement of negative stereotypes and the systemic marginalisation of religious minorities. For instance, facial recognition technology has been shown to have higher error rates for individuals from certain demographic groups, including those identifiable by specific religious attire. Such technological inaccuracies can lead to unjust surveillance and targeting, exacerbating the challenges faced by these communities.
   This critique is profoundly relevant to religion. In a world increasingly reliant on digital interfaces and automated decision-making, the risk of alienating religious minorities or misrepresenting their beliefs grows. This concern resonates with me deeply, as it underscores the potential of AI to shape cultural and social narratives in ways that could harden sectarian divides rather than bridge them.
   Champions of this critique often come from interdisciplinary fields, combining experts in ethics, technology, sociology, and religious studies. Significant advocacy groups include the Algorithmic Justice League and Faith in AI, which work to highlight and mitigate AI biases. Their efforts have gained prominence through high-profile cases such as the biased performance of Google's photo-tagging AI, which infamously mislabeled darker-skinned people, and research demonstrating the misidentification rates of facial recognition software across different ethnic groups, including those identifiable by religious garments.
   The goal of this critique is multi-faceted: to foster the development of AI technologies that are truly inclusive, to ensure fairness and accuracy in algorithmic decision-making, and to promote an understanding of AI's impact on diverse religious communities. By addressing these biases, advocates aim to create a technological landscape where AI supports equity and mutual respect among varied religious groups.
   Understanding why this problem is identified hinges on broader societal values, including the commitment to equality and human dignity. In a context devoid of concern for these principles, the discrepancies in AI performance might be dismissed as mere technical glitches rather than manifestations of deeper social issues. However, given the increasing integration of AI into daily life, the stakes are high. The norms and values at risk include the principle of nondiscrimination and the right of religious minorities to participate fully and fairly in society.
   As AI continues to shape our world, addressing these biases is not just a technical challenge but a moral imperative. Ensuring that AI systems do not perpetuate harmful stereotypes but instead promote a respectful and inclusive society reflects the core values that many believe technology should uphold. This essay and the research it prompts lay the groundwork for reimagining an AI that respects and reflects the diverse tapestry of human beliefs, including those shaped by religion.

## Notes

References: 
1. https://www.researchgate.net/publication/378375652_Impact_of_AI-Powered_Technology_on_Religious_Practices_and_Ethics_The_Road_Ahead
2. https://www.icrs.or.id/news/religion-in-the-age-of-generative-ai
3. https://www.forbes.com/sites/lanceeliot/2023/05/10/the-crucial-ways-that-religion-and-generative-ai-chatgpt-are-crossing-fateful-faithful-paths/
4. https://www.johnsnowlabs.com/unmasking-the-biases-within-ai-how-gender-ethnicity-religion-and-economics-shape-nlp-and-beyond/

## Summary


## Q and A

#### Total Words = 150 + 300 + 300 + 150 + 100 = 1000

Q: Explain what the critique is and what problem it addresses. (150 words)
A: Today, we live in a world that revolves around technology. Artificial Intelligence's sudden and rapid evolution instils both wonder and fear in our world; we must create systems that ensure objectivity and impartiality, as these pillars will ensure the new world is equitable and just. With this essay, I wish to address the biases these systems may inherit from their training data, especially in the context of religion. We are aware of implicit biases in humans and how these can trickle down in the form of data, data labels, model design, etc. I would like to bring attention to how these practices unless given due consideration, can perpetuate stereotypes and deepen societal division. In other words, unless training data and the models are regulated with an intersectional view that identifies possible biases beforehand, we will end up with AI systems that can fundamentally damage the fabric of our society.

Q: Explain the relevance of the problem and the critique in your domain and why you find it important/why it resonates with you. (300 words)
A: The boundaries of the physical, the biological, and the digital are slowly but surely blurring, and soon, we will find ourselves on a path to trans-humanism where AI and humans evolve hand in hand[^1]. It is important at such a time that we understand how AI can impact our approach to morality; as religion is the most prominent actor in defining morality, we must dig deeper and solidify our understanding of how AI can affect religious practices.
The market is now filled with chatbots, such as AI God Chat, Ask Jesus, Hadit GPT, etc[^1]. First and foremost, most of these provide boilerplate advice, which can feel very generic and make the user feel alienated and dehumanised[^1]. This presents quite an ethical conundrum. Second, the developers who train these models use metadata from the internet. This means the models could possibly acquire distorted views about theology and holy scriptures. What this entails is the potential for cyberbullying, the spread of misinformation, and the maligning of religions. In more technical terms, the systems are susceptible to stochastic parroting, jailbreaks, and adversarial attacks.
I came from a place where I grew up in a secular community where people who practise many religions coexist in harmony. I noticed that as I got older and the proliferation of news and media became more prominent in the community, there was a gradual invasion of foreign ideologies and theories that began to pave the way for the reinforcement of negative stereotypes and systemic marginalisation of religious sects. I've observed that the shift from print media dominance to television prominence, spurred by the internet, led to a once close-knit community fracturing into competing factions that turned against each other. 
Witnessing this transformation and recognising AI's significant impact, I find the issue we've discussed crucial for my well-being and a harmonious future.

Q: Describe who champions this critique – where it is coming from, are there particular groups leading it, have some significant moments/examples are used to illustrate the problem, is there a specific moment in time around when this critique became more visible or maybe it is still rather unknown? (300 words)
A: Academics and intellectuals have started to see the importance of such technologies and their impact on society. Many have taken an interest in this and are bringing it to a greater audience so that people can be educated on the new wave of change AI will bring. One example I would like to cite is the *Web3 Fusion: AI and Beyond conference* held in Bangkok in April 2024[^2]. Keynote speakers hailed from various countries, including the United States, Brazil, Greece, the United Kingdom, New Zealand, Japan, Korea, Thailand, Malaysia, and the Philippines. One of the key events they tried to describe is using "Keywords in Context" in Facebook algorithms. The discussion was about how some symbols, like the Swastika, could be used as a way of proliferating hate in a Nazi or Neo-Nazi context but at the same time is a symbol of wellbeing in many cultures like Hinduism, Buddhism and many more[^2]. 
Organisations like the Indonesian Consortium of Religious Studies are helping build community standard guidelines to help understand and control events where the same symbol can be used for good and evil. In the age of Generative AI, such organisations have already identified the power of words and how a picture is worth a thousand words. However, the data used for training, which is based on a corpus and big data, will leave these systems prone to synthetic biases[^2]. People must realise that two plus two is not always four. People are always prone to dynamic interpretations, as we can see from the law of montage[^2].  
Religious scholars are pondering the effects of Generative AI on trans-humanism, raising concerns about this shift. The impact of such algorithms on platforms like Facebook has prompted academics to discuss how data should be collected, annotated, or labelled, making these discussions crucial since the advent of Generative AI.

Q: What is the goal of the critique – what does it want to achieve? (150 words)
A: These discussions aim to ensure that AI does not cause more religious tension and divide people more. It hopes to take examples from the past and educate the masses so that we know what such technologies of the future can do. There is implicit bias in the training data we collect, especially if it's scraped from the internet. We need to be aware of such biases so that we can formulate plans to mitigate the side effects such training can cause in the models.
As we can see, one can create a religion-tuned generative AI[^3], which could use a base model the developer chooses and fine-tunes; what would happen if the base model was inherently biased? This critique aims to show that we must proactively check for such problems and create frameworks to evaluate these models before releasing them to the public. It aims to achieve responsibility and accountability for those developing such systems.

Q: What is the reason for the problem and its context? Why is the problem identified as a problem? What contexts and values/norms are at stake? Without concerns about climate change, energy consumption wouldn’t seem such an issue, and without the belief in equality and fairness, we wouldn’t worry about biased systems. (100 words)
A: The reason for the problem and its context is very simple. Data processing, even with RLHF, can be biased if it ignores the intersectional nature of the data. Insufficient context may further divide and marginalise communities. We need a system that mitigates religious bias by carefully moderating content and including religious diversity in the training data[^4]. Language models can produce biased content about religions, leading to discrimination and conflict. Experiments conducted in studies by John Snow Labs[^4] prove this point. Unless we take careful action to see why inequality is prevalent in society and address it when we create advanced LLMs, we cannot hope for a better future.


[^1]: https://www.researchgate.net/publication/378375652_Impact_of_AI-Powered_Technology_on_Religious_Practices_and_Ethics_The_Road_Ahead
[^2]: https://www.icrs.or.id/news/religion-in-the-age-of-generative-ai
[^3]: https://www.forbes.com/sites/lanceeliot/2023/05/10/the-crucial-ways-that-religion-and-generative-ai-chatgpt-are-crossing-fateful-faithful-paths/
[^4]: https://www.johnsnowlabs.com/unmasking-the-biases-within-ai-how-gender-ethnicity-religion-and-economics-shape-nlp-and-beyond/