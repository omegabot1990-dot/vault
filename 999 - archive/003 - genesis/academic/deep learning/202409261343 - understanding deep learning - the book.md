---
tags:
  - academic
  - idl
aliases:
  - understanding deep learning
title: understanding deep learning - the book
description: understanding deep learning - annotated and highlighted
parent nodes:
  - "[[introduction to deep learning]]"
child nodes:
annotation-target: understanding_deep_learning.pdf
---



>%%
>```annotation-json
>{"created":"2024-09-26T11:50:39.069Z","text":"What is a multi-layer perceptron?","updated":"2024-09-26T11:50:39.069Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":94889,"end":95020},{"type":"TextQuoteSelector","exact":"For historical reasons, any neural network with at least one hidden layer is also calleda multi-layer perceptron, or MLP for short.","prefix":"nctions) are termed activations.","suffix":" Networks with one hidden layer "}]}]}
>```
>%%
>*%%PREFIX%%nctions) are termed activations.%%HIGHLIGHT%% ==For historical reasons, any neural network with at least one hidden layer is also calleda multi-layer perceptron, or MLP for short.== %%POSTFIX%%Networks with one hidden layer*
>%%LINK%%[[#^ghz5nhjs1d5|show annotation]]
>%%COMMENT%%
>What is a multi-layer perceptron?
>%%TAGS%%
>#question
^ghz5nhjs1d5


>%%
>```annotation-json
>{"created":"2024-09-28T10:37:37.882Z","text":"What is *machine learning*?","updated":"2024-09-28T10:37:37.882Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":23676,"end":23787},{"type":"TextQuoteSelector","exact":"Machine learning is a subset of AI that learns tomake decisions by fitting mathematical models to observed data","prefix":"h, and probabilistic reasoning. ","suffix":". This area has seenexplosive gr"}]}]}
>```
>%%
>*%%PREFIX%%h, and probabilistic reasoning.%%HIGHLIGHT%% ==Machine learning is a subset of AI that learns tomake decisions by fitting mathematical models to observed data== %%POSTFIX%%. This area has seenexplosive gr*
>%%LINK%%[[#^ts5sehfoj7|show annotation]]
>%%COMMENT%%
>What is *machine learning*?
>%%TAGS%%
>#question
^ts5sehfoj7


>%%
>```annotation-json
>{"created":"2024-09-28T10:38:08.936Z","text":"What is *deep learning*?","updated":"2024-09-28T10:38:08.936Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":23884,"end":24010},{"type":"TextQuoteSelector","exact":"A deep neural network is a type of machine learning model, and when it is fittedto data, this is referred to as deep learning.","prefix":"ost synonymous with the term AI.","suffix":" At the time of writing, deep ne"}]}]}
>```
>%%
>*%%PREFIX%%ost synonymous with the term AI.%%HIGHLIGHT%% ==A deep neural network is a type of machine learning model, and when it is fittedto data, this is referred to as deep learning.== %%POSTFIX%%At the time of writing, deep ne*
>%%LINK%%[[#^j7arp17spg|show annotation]]
>%%COMMENT%%
>What is *deep learning*?
>%%TAGS%%
>#question
^j7arp17spg


>%%
>```annotation-json
>{"created":"2024-09-28T10:40:32.340Z","text":"What is *supervised learning*?","updated":"2024-09-28T10:40:32.340Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":25516,"end":25600},{"type":"TextQuoteSelector","exact":"Supervised learning models define a mapping from input data to an output prediction.","prefix":"his book.1.1 Supervised learning","suffix":"In the following sections, we di"}]}]}
>```
>%%
>*%%PREFIX%%his book.1.1 Supervised learning%%HIGHLIGHT%% ==Supervised learning models define a mapping from input data to an output prediction.== %%POSTFIX%%In the following sections, we di*
>%%LINK%%[[#^270gp542qdw|show annotation]]
>%%COMMENT%%
>What is *supervised learning*?
>%%TAGS%%
>#question
^270gp542qdw


>%%
>```annotation-json
>{"created":"2024-09-28T10:41:34.840Z","updated":"2024-09-28T10:41:34.840Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":25901,"end":26002},{"type":"TextQuoteSelector","exact":"Itcan coarsely be divided into supervisedlearning, unsupervised learning, and re-inforcement learning","prefix":"atical models to observed data. ","suffix":". Deep neural net-works contribu"}]}]}
>```
>%%
>*%%PREFIX%%atical models to observed data.%%HIGHLIGHT%% ==Itcan coarsely be divided into supervisedlearning, unsupervised learning, and re-inforcement learning== %%POSTFIX%%. Deep neural net-works contribu*
>%%LINK%%[[#^o3mmerm1e0j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^o3mmerm1e0j


>%%
>```annotation-json
>{"created":"2024-09-28T10:43:53.446Z","text":"What is *regression*?","updated":"2024-09-28T10:43:53.446Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":26748,"end":26857},{"type":"TextQuoteSelector","exact":"This is a regression problembecause the model returns a continuous number (rather than a category assignment)","prefix":"age and the number of bedrooms. ","suffix":". Incontrast, the model in 1.2b "}]}]}
>```
>%%
>*%%PREFIX%%age and the number of bedrooms.%%HIGHLIGHT%% ==This is a regression problembecause the model returns a continuous number (rather than a category assignment)== %%POSTFIX%%. Incontrast, the model in 1.2b*
>%%LINK%%[[#^i0r677aylqi|show annotation]]
>%%COMMENT%%
>What is *regression*?
>%%TAGS%%
>#question
^i0r677aylqi


>%%
>```annotation-json
>{"created":"2024-09-28T10:44:11.065Z","text":"What is *multivariate regression*?","updated":"2024-09-28T10:44:11.065Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":26993,"end":27073},{"type":"TextQuoteSelector","exact":"This is a multivariate regression problemsince it predicts more than one number.","prefix":"the melting and boiling points. ","suffix":"The model in figure 1.2c receive"}]}]}
>```
>%%
>*%%PREFIX%%the melting and boiling points.%%HIGHLIGHT%% ==This is a multivariate regression problemsince it predicts more than one number.== %%POSTFIX%%The model in figure 1.2c receive*
>%%LINK%%[[#^4vyuopmpn5e|show annotation]]
>%%COMMENT%%
>What is *multivariate regression*?
>%%TAGS%%
>#question
^4vyuopmpn5e


>%%
>```annotation-json
>{"created":"2024-09-28T10:44:44.069Z","text":"What is *binary classification*?","updated":"2024-09-28T10:44:44.069Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":27217,"end":27328},{"type":"TextQuoteSelector","exact":"This is a binary classificationproblem because the model attempts to assign the input to one of two categories.","prefix":"review is positive or negative. ","suffix":" Theoutput vector contains the p"}]}]}
>```
>%%
>*%%PREFIX%%review is positive or negative.%%HIGHLIGHT%% ==This is a binary classificationproblem because the model attempts to assign the input to one of two categories.== %%POSTFIX%%Theoutput vector contains the p*
>%%LINK%%[[#^fatv5nnk80h|show annotation]]
>%%COMMENT%%
>What is *binary classification*?
>%%TAGS%%
>#question
^fatv5nnk80h


>%%
>```annotation-json
>{"created":"2024-09-28T10:45:10.460Z","updated":"2024-09-28T10:45:10.460Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":27329,"end":27412},{"type":"TextQuoteSelector","exact":"Theoutput vector contains the probabilities that the input belongs to each category","prefix":"input to one of two categories. ","suffix":". Fig-ures 1.2d and 1.2e depict "}]}]}
>```
>%%
>*%%PREFIX%%input to one of two categories.%%HIGHLIGHT%% ==Theoutput vector contains the probabilities that the input belongs to each category== %%POSTFIX%%. Fig-ures 1.2d and 1.2e depict*
>%%LINK%%[[#^l3vkr5inuzk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^l3vkr5inuzk


>%%
>```annotation-json
>{"created":"2024-09-28T10:45:21.182Z","text":"What is *multi-class classification*?","updated":"2024-09-28T10:45:21.182Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":27444,"end":27539},{"type":"TextQuoteSelector","exact":"multiclass classification problems. Here, the model assigns theinput to one of N > 2 categories","prefix":". Fig-ures 1.2d and 1.2e depict ","suffix":". In the first case, the input i"}]}]}
>```
>%%
>*%%PREFIX%%. Fig-ures 1.2d and 1.2e depict%%HIGHLIGHT%% ==multiclass classification problems. Here, the model assigns theinput to one of N > 2 categories== %%POSTFIX%%. In the first case, the input i*
>%%LINK%%[[#^twpvj46o3ur|show annotation]]
>%%COMMENT%%
>What is *multi-class classification*?
>%%TAGS%%
>#question
^twpvj46o3ur


>%%
>```annotation-json
>{"created":"2024-09-28T10:50:23.881Z","updated":"2024-09-28T10:50:23.881Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":27735,"end":27837},{"type":"TextQuoteSelector","exact":"In each case, the model returnsa vector of size N that contains the probabilities of the N categories.","prefix":"dicts which object it contains. ","suffix":"1.1.2 InputsThe input data in fi"}]}]}
>```
>%%
>*%%PREFIX%%dicts which object it contains.%%HIGHLIGHT%% ==In each case, the model returnsa vector of size N that contains the probabilities of the N categories.== %%POSTFIX%%1.1.2 InputsThe input data in fi*
>%%LINK%%[[#^73wfv423pbv|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^73wfv423pbv


>%%
>```annotation-json
>{"created":"2024-09-28T10:57:12.640Z","text":"What is *training* or *fitting*?","updated":"2024-09-28T10:57:12.640Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":31839,"end":32061},{"type":"TextQuoteSelector","exact":"When we talk about training or fitting a model, we mean that wesearch through the family of possible equations (possible cyan curves) relating input tooutput to find the one that describes the training data most accurately","prefix":"describesthese data reasonably. ","suffix":".It follows that the models in f"}]}]}
>```
>%%
>*%%PREFIX%%describesthese data reasonably.%%HIGHLIGHT%% ==When we talk about training or fitting a model, we mean that wesearch through the family of possible equations (possible cyan curves) relating input tooutput to find the one that describes the training data most accurately== %%POSTFIX%%.It follows that the models in f*
>%%LINK%%[[#^lyst7rkh7f|show annotation]]
>%%COMMENT%%
>What is *training* or *fitting*?
>%%TAGS%%
>#question
^lyst7rkh7f


>%%
>```annotation-json
>{"created":"2024-09-28T10:57:53.363Z","updated":"2024-09-28T10:57:53.363Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":32292,"end":32435},{"type":"TextQuoteSelector","exact":" These input/output pairs takethe role of a teacher or supervisor for the training process, and this gives rise to the termsupervised learning.","prefix":"ad identified the genre of each.","suffix":"1.1.4 Deep neural networksThis b"}]}]}
>```
>%%
>*%%PREFIX%%ad identified the genre of each.%%HIGHLIGHT%% ==These input/output pairs takethe role of a teacher or supervisor for the training process, and this gives rise to the termsupervised learning.== %%POSTFIX%%1.1.4 Deep neural networksThis b*
>%%LINK%%[[#^w77v1t9k3oo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w77v1t9k3oo


>%%
>```annotation-json
>{"created":"2024-09-28T11:02:09.984Z","text":"What is *unsupervised learning*?","updated":"2024-09-28T11:02:09.984Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":36366,"end":36655},{"type":"TextQuoteSelector","exact":"Constructing a model from input data without corresponding output labels is termedunsupervised learning; the absence of output labels means there can be no “supervision.”Rather than learning a mapping from input to output, the goal is to describe or under-stand the structure of the data. ","prefix":"models.1.2 Unsupervised learning","suffix":"As was the case for supervised l"}]}]}
>```
>%%
>*%%PREFIX%%models.1.2 Unsupervised learning%%HIGHLIGHT%% ==Constructing a model from input data without corresponding output labels is termedunsupervised learning; the absence of output labels means there can be no “supervision.”Rather than learning a mapping from input to output, the goal is to describe or under-stand the structure of the data.== %%POSTFIX%%As was the case for supervised l*
>%%LINK%%[[#^mk6jdptge5|show annotation]]
>%%COMMENT%%
>What is *unsupervised learning*?
>%%TAGS%%
>#question
^mk6jdptge5


>%%
>```annotation-json
>{"created":"2024-09-28T11:03:20.949Z","updated":"2024-09-28T11:03:20.949Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":36873,"end":37301},{"type":"TextQuoteSelector","exact":"This book focuses on generative unsupervised models, which learn to synthesize newdata examples that are statistically indistinguishable from the training data. Somegenerative models explicitly describe the probability distribution over the input data andhere new examples are generated by sampling from this distribution. Others merely learna mechanism to generate new examples without explicitly describing their distribution.","prefix":"e length.1.2.1 Generative models","suffix":"State-of-the-art generative mode"}]}]}
>```
>%%
>*%%PREFIX%%e length.1.2.1 Generative models%%HIGHLIGHT%% ==This book focuses on generative unsupervised models, which learn to synthesize newdata examples that are statistically indistinguishable from the training data. Somegenerative models explicitly describe the probability distribution over the input data andhere new examples are generated by sampling from this distribution. Others merely learna mechanism to generate new examples without explicitly describing their distribution.== %%POSTFIX%%State-of-the-art generative mode*
>%%LINK%%[[#^mumhkv7r0e8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mumhkv7r0e8


>%%
>```annotation-json
>{"created":"2024-09-28T11:03:35.573Z","updated":"2024-09-28T11:03:35.573Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":37526,"end":37645},{"type":"TextQuoteSelector","exact":"They can also synthesize dataunder the constraint that some outputs are predetermined (termed conditional genera-tion).","prefix":"ure 1.5) and text (figure 1.6). ","suffix":" Examples include image inpainti"}]}]}
>```
>%%
>*%%PREFIX%%ure 1.5) and text (figure 1.6).%%HIGHLIGHT%% ==They can also synthesize dataunder the constraint that some outputs are predetermined (termed conditional genera-tion).== %%POSTFIX%%Examples include image inpainti*
>%%LINK%%[[#^ysu1d7d4k8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ysu1d7d4k8


>%%
>```annotation-json
>{"created":"2024-09-28T11:18:25.100Z","text":"What are *latent variables*?","updated":"2024-09-28T11:18:25.100Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":42043,"end":42158},{"type":"TextQuoteSelector","exact":"This leads to the idea that we can describe each data example using a smaller numberof underlying latent variables.","prefix":"ical processes (see figure 1.9).","suffix":" Here, the role of deep learning"}]}]}
>```
>%%
>*%%PREFIX%%ical processes (see figure 1.9).%%HIGHLIGHT%% ==This leads to the idea that we can describe each data example using a smaller numberof underlying latent variables.== %%POSTFIX%%Here, the role of deep learning*
>%%LINK%%[[#^v8vkao0nh4h|show annotation]]
>%%COMMENT%%
>What are *latent variables*?
>%%TAGS%%
>#question
^v8vkao0nh4h


>%%
>```annotation-json
>{"created":"2024-09-28T11:19:07.058Z","updated":"2024-09-28T11:19:07.058Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":42262,"end":42306},{"type":"TextQuoteSelector","exact":"The latent variables typically have a simple","prefix":" latent variables and the data. ","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%latent variables and the data.%%HIGHLIGHT%% ==The latent variables typically have a simple== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^cebdsz4tn3d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cebdsz4tn3d


>%%
>```annotation-json
>{"created":"2024-09-28T11:19:12.529Z","updated":"2024-09-28T11:19:12.529Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":43748,"end":43782},{"type":"TextQuoteSelector","exact":"probability distribution by design","prefix":" DALL·E-2 (Ramesh et al., 2022).","suffix":". By sampling from this distribu"}]}]}
>```
>%%
>*%%PREFIX%%DALL·E-2 (Ramesh et al., 2022).%%HIGHLIGHT%% ==probability distribution by design== %%POSTFIX%%. By sampling from this distribu*
>%%LINK%%[[#^hw9ju3rq9i6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hw9ju3rq9i6


>%%
>```annotation-json
>{"created":"2024-09-28T11:19:32.826Z","updated":"2024-09-28T11:19:32.826Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":43975,"end":44216},{"type":"TextQuoteSelector","exact":"For example, considerfinding the latent variables that underpin two real examples. We can interpolate betweenthese examples by interpolating between their latent representations and mapping theintermediate positions back into the data space ","prefix":"ods for manipulating real data. ","suffix":"(figure 1.11).1.2.3 Connecting s"}]}]}
>```
>%%
>*%%PREFIX%%ods for manipulating real data.%%HIGHLIGHT%% ==For example, considerfinding the latent variables that underpin two real examples. We can interpolate betweenthese examples by interpolating between their latent representations and mapping theintermediate positions back into the data space== %%POSTFIX%%(figure 1.11).1.2.3 Connecting s*
>%%LINK%%[[#^0r7bf55m71w|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0r7bf55m71w


>%%
>```annotation-json
>{"created":"2024-09-28T11:20:46.684Z","text":"Advantages of *latent variables*?","updated":"2024-09-28T11:20:46.684Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":44690,"end":45206},{"type":"TextQuoteSelector","exact":"First, we may need fewer text/image pairs to learn thismapping now that the inputs and outputs are lower dimensional. Second, we are morelikely to generate a plausible-looking image; any sensible values of the latent variablesshould produce something that looks like a plausible example. Third, if we introducerandomness to either the mapping between the two sets of latent variables or the mappingfrom the latent variables to the image, then we can generate multiple images that are alldescribed well by the caption","prefix":"mage.This has three advantages. ","suffix":" (figure 1.12).1.3 Reinforcement"}]}]}
>```
>%%
>*%%PREFIX%%mage.This has three advantages.%%HIGHLIGHT%% ==First, we may need fewer text/image pairs to learn thismapping now that the inputs and outputs are lower dimensional. Second, we are morelikely to generate a plausible-looking image; any sensible values of the latent variablesshould produce something that looks like a plausible example. Third, if we introducerandomness to either the mapping between the two sets of latent variables or the mappingfrom the latent variables to the image, then we can generate multiple images that are alldescribed well by the caption== %%POSTFIX%%(figure 1.12).1.3 Reinforcement*
>%%LINK%%[[#^p3nxx7k59jb|show annotation]]
>%%COMMENT%%
>Advantages of *latent variables*?
>%%TAGS%%
>#question
^p3nxx7k59jb


>%%
>```annotation-json
>{"created":"2024-09-28T11:22:03.465Z","text":"What is *reinforcement learning*?\nWhat is *inference*?\nWhat are *parameters*?","updated":"2024-09-28T11:22:03.465Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":45247,"end":45594},{"type":"TextQuoteSelector","exact":"The final area of machine learning is reinforcement learning. This paradigm introducesthe idea of an agent which lives in a world and can perform certain actions at each timestep. The actions change the state of the system but not necessarily in a deterministicway. Taking an action can also produce rewards, and the goal of reinforcement learning","prefix":"1.12).1.3 Reinforcement learning","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%1.12).1.3 Reinforcement learning%%HIGHLIGHT%% ==The final area of machine learning is reinforcement learning. This paradigm introducesthe idea of an agent which lives in a world and can perform certain actions at each timestep. The actions change the state of the system but not necessarily in a deterministicway. Taking an action can also produce rewards, and the goal of reinforcement learning== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^iubuahtl6wa|show annotation]]
>%%COMMENT%%
>What is *reinforcement learning*?
>What is *inference*?
>What are *parameters*?
>%%TAGS%%
>#question
^iubuahtl6wa


>%%
>```annotation-json
>{"created":"2024-09-28T11:22:25.142Z","updated":"2024-09-28T11:22:25.142Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":45662,"end":45743},{"type":"TextQuoteSelector","exact":"is for the agent to learn to choose actions that lead to high rewards on average.","prefix":"mail@gmail.com.12 1 Introduction","suffix":"One complication is that the rew"}]}]}
>```
>%%
>*%%PREFIX%%mail@gmail.com.12 1 Introduction%%HIGHLIGHT%% ==is for the agent to learn to choose actions that lead to high rewards on average.== %%POSTFIX%%One complication is that the rew*
>%%LINK%%[[#^7h6z59qw98p|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7h6z59qw98p


>%%
>```annotation-json
>{"created":"2024-09-28T11:23:04.560Z","updated":"2024-09-28T11:23:04.560Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":45743,"end":46250},{"type":"TextQuoteSelector","exact":"One complication is that the reward may occur some time after the action is taken,so associating a reward with an action is not straightforward. This is known as thetemporal credit assignment problem. As the agent learns, it must trade off explorationand exploitation of what it already knows; perhaps the agent has already learned how toreceive modest rewards; should it follow this strategy (exploit what it knows), or shouldit try different actions to see if it can improve (explore other opportunities)?","prefix":"lead to high rewards on average.","suffix":"1.3.1 Two examplesConsider teach"}]}]}
>```
>%%
>*%%PREFIX%%lead to high rewards on average.%%HIGHLIGHT%% ==One complication is that the reward may occur some time after the action is taken,so associating a reward with an action is not straightforward. This is known as thetemporal credit assignment problem. As the agent learns, it must trade off explorationand exploitation of what it already knows; perhaps the agent has already learned how toreceive modest rewards; should it follow this strategy (exploit what it knows), or shouldit try different actions to see if it can improve (explore other opportunities)?== %%POSTFIX%%1.3.1 Two examplesConsider teach*
>%%LINK%%[[#^pspj2lc5ri|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^pspj2lc5ri


>%%
>```annotation-json
>{"created":"2024-09-28T11:26:45.718Z","text":"What is a *policy network*?","updated":"2024-09-28T11:26:45.718Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":48082,"end":48258},{"type":"TextQuoteSelector","exact":"There are several possible approaches, but one technique is to use deep networksto build a mapping from the observed world state to an action. This is known as apolicy network.","prefix":"nforcement learning frame-work. ","suffix":" In the robot example, the polic"}]}]}
>```
>%%
>*%%PREFIX%%nforcement learning frame-work.%%HIGHLIGHT%% ==There are several possible approaches, but one technique is to use deep networksto build a mapping from the observed world state to an action. This is known as apolicy network.== %%POSTFIX%%In the robot example, the polic*
>%%LINK%%[[#^j50xlhhwxb|show annotation]]
>%%COMMENT%%
>What is a *policy network*?
>%%TAGS%%
>#question
^j50xlhhwxb


>%%
>```annotation-json
>{"created":"2024-09-28T11:28:23.691Z","updated":"2024-09-28T11:28:23.691Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":49467,"end":49485},{"type":"TextQuoteSelector","exact":"Bias and fairness:","prefix":"agraphs highlight five concerns.","suffix":" If we train a system to predict"}]}]}
>```
>%%
>*%%PREFIX%%agraphs highlight five concerns.%%HIGHLIGHT%% ==Bias and fairness:== %%POSTFIX%%If we train a system to predict*
>%%LINK%%[[#^iediospq7p7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^iediospq7p7


>%%
>```annotation-json
>{"created":"2024-09-28T11:28:27.158Z","updated":"2024-09-28T11:28:27.158Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":50116,"end":50132},{"type":"TextQuoteSelector","exact":"Explainability: ","prefix":"s (2018) for further discussion.","suffix":"Deep learning systems make decis"}]}]}
>```
>%%
>*%%PREFIX%%s (2018) for further discussion.%%HIGHLIGHT%% ==Explainability:== %%POSTFIX%%Deep learning systems make decis*
>%%LINK%%[[#^kisja7cwks|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kisja7cwks


>%%
>```annotation-json
>{"created":"2024-09-28T11:29:41.592Z","updated":"2024-09-28T11:29:41.592Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":51204,"end":51223},{"type":"TextQuoteSelector","exact":"Concentrating power","prefix":"mail@gmail.com.14 1 Introduction","suffix":": It is not from a benevolent in"}]}]}
>```
>%%
>*%%PREFIX%%mail@gmail.com.14 1 Introduction%%HIGHLIGHT%% ==Concentrating power== %%POSTFIX%%: It is not from a benevolent in*
>%%LINK%%[[#^ucnkpddsaa|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ucnkpddsaa


>%%
>```annotation-json
>{"created":"2024-09-28T11:29:47.062Z","updated":"2024-09-28T11:29:47.062Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":52005,"end":52021},{"type":"TextQuoteSelector","exact":"Existential risk","prefix":"aveon society (see David, 2015).","suffix":": The major existential risks to"}]}]}
>```
>%%
>*%%PREFIX%%aveon society (see David, 2015).%%HIGHLIGHT%% ==Existential risk== %%POSTFIX%%: The major existential risks to*
>%%LINK%%[[#^9ifwnv01tk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9ifwnv01tk


>%%
>```annotation-json
>{"created":"2024-09-28T11:37:31.867Z","updated":"2024-09-28T11:37:31.867Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":61373,"end":61465},{"type":"TextQuoteSelector","exact":"A supervised learning model defines a mapping from one or more inputs to one or moreoutputs.","prefix":"ess.Chapter 2Supervised learning","suffix":" For example, the input might be"}]}]}
>```
>%%
>*%%PREFIX%%ess.Chapter 2Supervised learning%%HIGHLIGHT%% ==A supervised learning model defines a mapping from one or more inputs to one or moreoutputs.== %%POSTFIX%%For example, the input might be*
>%%LINK%%[[#^kwcoikfd6kd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kwcoikfd6kd


>%%
>```annotation-json
>{"created":"2024-09-28T11:38:23.680Z","text":"What is a *supervised learning model*?","updated":"2024-09-28T11:38:23.680Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":61613,"end":62016},{"type":"TextQuoteSelector","exact":"The model is just a mathematical equation; when the inputs are passed through thisequation, it computes the output, and this is termed inference. The model equation alsocontains parameters. Different parameter values change the outcome of the computa-tion; the model equation describes a family of possible relationships between inputs andoutputs, and the parameters specify the particular relationship.","prefix":"ted value of the car in dollars.","suffix":"When we train or learn a model, "}]}]}
>```
>%%
>*%%PREFIX%%ted value of the car in dollars.%%HIGHLIGHT%% ==The model is just a mathematical equation; when the inputs are passed through thisequation, it computes the output, and this is termed inference. The model equation alsocontains parameters. Different parameter values change the outcome of the computa-tion; the model equation describes a family of possible relationships between inputs andoutputs, and the parameters specify the particular relationship.== %%POSTFIX%%When we train or learn a model,*
>%%LINK%%[[#^9faelq6vou8|show annotation]]
>%%COMMENT%%
>What is a *supervised learning model*?
>%%TAGS%%
>#question
^9faelq6vou8


>%%
>```annotation-json
>{"created":"2024-09-28T11:40:39.947Z","text":"What is *training* or *learning*?","updated":"2024-09-28T11:40:39.947Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":62016,"end":62301},{"type":"TextQuoteSelector","exact":"When we train or learn a model, we find parameters that describe the true relationshipbetween inputs and outputs. A learning algorithm takes a training set of input/outputpairs and manipulates the parameters until the inputs predict their corresponding out-puts as closely as possible.","prefix":"ify the particular relationship.","suffix":" If the model works well for the"}]}]}
>```
>%%
>*%%PREFIX%%ify the particular relationship.%%HIGHLIGHT%% ==When we train or learn a model, we find parameters that describe the true relationshipbetween inputs and outputs. A learning algorithm takes a training set of input/outputpairs and manipulates the parameters until the inputs predict their corresponding out-puts as closely as possible.== %%POSTFIX%%If the model works well for the*
>%%LINK%%[[#^4fbrvlsz39h|show annotation]]
>%%COMMENT%%
>What is *training* or *learning*?
>%%TAGS%%
>#question
^4fbrvlsz39h


>%%
>```annotation-json
>{"created":"2024-09-28T11:42:15.868Z","updated":"2024-09-28T11:42:15.868Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":63246,"end":63288},{"type":"TextQuoteSelector","exact":"This is termed structured or tabular data.","prefix":"hen the mileage, in that order. ","suffix":"To make the prediction, we need "}]}]}
>```
>%%
>*%%PREFIX%%hen the mileage, in that order.%%HIGHLIGHT%% ==This is termed structured or tabular data.== %%POSTFIX%%To make the prediction, we need*
>%%LINK%%[[#^6e727o9g8lo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6e727o9g8lo


>%%
>```annotation-json
>{"created":"2024-09-28T14:47:38.616Z","updated":"2024-09-28T14:47:38.616Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":63288,"end":63379},{"type":"TextQuoteSelector","exact":"To make the prediction, we need a model f[•] that takes input x and returns y, so:y = f[x].","prefix":"rmed structured or tabular data.","suffix":" (2.1)Draft: please send errata "}]}]}
>```
>%%
>*%%PREFIX%%rmed structured or tabular data.%%HIGHLIGHT%% ==To make the prediction, we need a model f[•] that takes input x and returns y, so:y = f[x].== %%POSTFIX%%(2.1)Draft: please send errata*
>%%LINK%%[[#^k4njl9v1m5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^k4njl9v1m5


>%%
>```annotation-json
>{"created":"2024-09-28T14:47:44.071Z","updated":"2024-09-28T14:47:44.071Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":63460,"end":63534},{"type":"TextQuoteSelector","exact":"When we compute the prediction y from the input x, we call this inference.","prefix":"ail.com.18 2 Supervised learning","suffix":"The model is just a mathematical"}]}]}
>```
>%%
>*%%PREFIX%%ail.com.18 2 Supervised learning%%HIGHLIGHT%% ==When we compute the prediction y from the input x, we call this inference.== %%POSTFIX%%The model is just a mathematical*
>%%LINK%%[[#^03oxrb9ysx88|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^03oxrb9ysx88


>%%
>```annotation-json
>{"created":"2024-09-28T14:47:56.206Z","updated":"2024-09-28T14:47:56.206Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":63534,"end":63835},{"type":"TextQuoteSelector","exact":"The model is just a mathematical equation with a fixed form. It represents a familyof different relations between the input and the output. The model also contains param-eters φ. The choice of parameters determines the particular relation between input andoutput, so we should really write:y = f[x,φ].","prefix":"input x, we call this inference.","suffix":" (2.2)When we talk about learnin"}]}]}
>```
>%%
>*%%PREFIX%%input x, we call this inference.%%HIGHLIGHT%% ==The model is just a mathematical equation with a fixed form. It represents a familyof different relations between the input and the output. The model also contains param-eters φ. The choice of parameters determines the particular relation between input andoutput, so we should really write:y = f[x,φ].== %%POSTFIX%%(2.2)When we talk about learnin*
>%%LINK%%[[#^uavgr9f57lo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uavgr9f57lo


>%%
>```annotation-json
>{"created":"2024-09-28T14:48:24.040Z","updated":"2024-09-28T14:48:24.040Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":63841,"end":64190},{"type":"TextQuoteSelector","exact":"When we talk about learning or training a model, we mean that we attempt to findparameters φ that make sensible output predictions from the input. We learn theseparameters using a training dataset of I pairs of input and output examples {xi,yi}. Weaim to select parameters that map each training input to its associated output as closelyas possible.","prefix":"d really write:y = f[x,φ]. (2.2)","suffix":" We quantify the degree of misma"}]}]}
>```
>%%
>*%%PREFIX%%d really write:y = f[x,φ]. (2.2)%%HIGHLIGHT%% ==When we talk about learning or training a model, we mean that we attempt to findparameters φ that make sensible output predictions from the input. We learn theseparameters using a training dataset of I pairs of input and output examples {xi,yi}. Weaim to select parameters that map each training input to its associated output as closelyas possible.== %%POSTFIX%%We quantify the degree of misma*
>%%LINK%%[[#^r06yuy0y98g|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r06yuy0y98g


>%%
>```annotation-json
>{"created":"2024-09-28T14:48:41.722Z","updated":"2024-09-28T14:48:41.722Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":64191,"end":64395},{"type":"TextQuoteSelector","exact":"We quantify the degree of mismatch in this mapping with the loss L. Thisis a scalar value that summarizes how poorly the model predicts the training outputsfrom their corresponding inputs for parameters φ","prefix":"d output as closelyas possible. ","suffix":".We can treat the loss as a func"}]}]}
>```
>%%
>*%%PREFIX%%d output as closelyas possible.%%HIGHLIGHT%% ==We quantify the degree of mismatch in this mapping with the loss L. Thisis a scalar value that summarizes how poorly the model predicts the training outputsfrom their corresponding inputs for parameters φ== %%POSTFIX%%.We can treat the loss as a func*
>%%LINK%%[[#^74vvs8ddvx3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^74vvs8ddvx3


>%%
>```annotation-json
>{"created":"2024-09-28T14:48:52.798Z","updated":"2024-09-28T14:48:52.798Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":64396,"end":64563},{"type":"TextQuoteSelector","exact":"We can treat the loss as a function L[φ] of these parameters. When we train themodel, we are seeking parameters ˆφ that minimize this loss function:1ˆφ = argminφ[L[φ]]","prefix":"ponding inputs for parameters φ.","suffix":". (2.3)If the loss is small afte"}]}]}
>```
>%%
>*%%PREFIX%%ponding inputs for parameters φ.%%HIGHLIGHT%% ==We can treat the loss as a function L[φ] of these parameters. When we train themodel, we are seeking parameters ˆφ that minimize this loss function:1ˆφ = argminφ[L[φ]]== %%POSTFIX%%. (2.3)If the loss is small afte*
>%%LINK%%[[#^v92wnqrnuv|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^v92wnqrnuv


>%%
>```annotation-json
>{"created":"2024-09-28T14:49:06.787Z","updated":"2024-09-28T14:49:06.787Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":64570,"end":64724},{"type":"TextQuoteSelector","exact":"If the loss is small after this minimization, we have found model parameters that accu-rately predict the training outputs yi from the training inputs xi.","prefix":"ction:1ˆφ = argminφ[L[φ]]. (2.3)","suffix":"After training a model, we must "}]}]}
>```
>%%
>*%%PREFIX%%ction:1ˆφ = argminφ[L[φ]]. (2.3)%%HIGHLIGHT%% ==If the loss is small after this minimization, we have found model parameters that accu-rately predict the training outputs yi from the training inputs xi.== %%POSTFIX%%After training a model, we must*
>%%LINK%%[[#^4qr42wtszda|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4qr42wtszda


>%%
>```annotation-json
>{"created":"2024-09-28T14:49:13.616Z","updated":"2024-09-28T14:49:13.616Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":64724,"end":64974},{"type":"TextQuoteSelector","exact":"After training a model, we must now assess its performance; we run the model onseparate test data to see how well it generalizes to examples that it didn’t observe duringtraining. If the performance is adequate, then we are ready to deploy the model.","prefix":" yi from the training inputs xi.","suffix":"2.2 Linear regression exampleLet"}]}]}
>```
>%%
>*%%PREFIX%%yi from the training inputs xi.%%HIGHLIGHT%% ==After training a model, we must now assess its performance; we run the model onseparate test data to see how well it generalizes to examples that it didn’t observe duringtraining. If the performance is adequate, then we are ready to deploy the model.== %%POSTFIX%%2.2 Linear regression exampleLet*
>%%LINK%%[[#^yxz7k1zkpfm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yxz7k1zkpfm


>%%
>```annotation-json
>{"created":"2024-09-28T15:23:39.553Z","updated":"2024-09-28T15:23:39.553Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":65250,"end":65353},{"type":"TextQuoteSelector","exact":"A 1D linear regression model describes the relationship between input x and output yas a straight line:","prefix":"2.2.1 1D linear regression model","suffix":"y = f[x,φ]= φ0 + φ1x. (2.4)1More"}]}]}
>```
>%%
>*%%PREFIX%%2.2.1 1D linear regression model%%HIGHLIGHT%% ==A 1D linear regression model describes the relationship between input x and output yas a straight line:== %%POSTFIX%%y = f[x,φ]= φ0 + φ1x. (2.4)1More*
>%%LINK%%[[#^uuvfcly3pog|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uuvfcly3pog


>%%
>```annotation-json
>{"created":"2024-09-28T15:23:44.614Z","updated":"2024-09-28T15:23:44.614Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":65353,"end":65374},{"type":"TextQuoteSelector","exact":"y = f[x,φ]= φ0 + φ1x.","prefix":" and output yas a straight line:","suffix":" (2.4)1More properly, the loss f"}]}]}
>```
>%%
>*%%PREFIX%%and output yas a straight line:%%HIGHLIGHT%% ==y = f[x,φ]= φ0 + φ1x.== %%POSTFIX%%(2.4)1More properly, the loss f*
>%%LINK%%[[#^obvp1y5inig|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^obvp1y5inig


>%%
>```annotation-json
>{"created":"2024-09-28T15:44:35.534Z","updated":"2024-09-28T15:44:35.534Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":66071,"end":66175},{"type":"TextQuoteSelector","exact":"This model has two parameters φ = [φ0,φ1]T , where φ0 is the y-intercept of the lineand φ1 is the slope.","prefix":"thefamily (the particular line).","suffix":" Different choices for the y-int"}]}]}
>```
>%%
>*%%PREFIX%%thefamily (the particular line).%%HIGHLIGHT%% ==This model has two parameters φ = [φ0,φ1]T , where φ0 is the y-intercept of the lineand φ1 is the slope.== %%POSTFIX%%Different choices for the y-int*
>%%LINK%%[[#^xf5wgrmg2tf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xf5wgrmg2tf


>%%
>```annotation-json
>{"created":"2024-09-28T15:45:06.675Z","updated":"2024-09-28T15:45:06.675Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":67004,"end":67065},{"type":"TextQuoteSelector","exact":"We term this value the loss; a lower loss means a better fit.","prefix":" between the model and thedata. ","suffix":"The mismatch is captured by the "}]}]}
>```
>%%
>*%%PREFIX%%between the model and thedata.%%HIGHLIGHT%% ==We term this value the loss; a lower loss means a better fit.== %%POSTFIX%%The mismatch is captured by the*
>%%LINK%%[[#^9fwen13yaci|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9fwen13yaci


>%%
>```annotation-json
>{"created":"2024-09-28T15:45:38.373Z","updated":"2024-09-28T15:45:38.373Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":67065,"end":67202},{"type":"TextQuoteSelector","exact":"The mismatch is captured by the deviation between the model predictions f[xi,φ](height of the line at xi) and the ground truth outputs yi","prefix":"a lower loss means a better fit.","suffix":". These deviations are depicteda"}]}]}
>```
>%%
>*%%PREFIX%%a lower loss means a better fit.%%HIGHLIGHT%% ==The mismatch is captured by the deviation between the model predictions f[xi,φ](height of the line at xi) and the ground truth outputs yi== %%POSTFIX%%. These deviations are depicteda*
>%%LINK%%[[#^a8fl18od0zc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^a8fl18od0zc


>%%
>```annotation-json
>{"created":"2024-09-28T15:45:47.824Z","updated":"2024-09-28T15:45:47.824Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":67275,"end":67451},{"type":"TextQuoteSelector","exact":"We quantify the total mismatch, training error,or loss as the sum of the squares of these deviations for all I training pairs:L[φ] =I∑i=1(f[xi,φ] −yi)2=I∑i=1(φ0 + φ1xi −yi)2 . ","prefix":"dashed lines in figures 2.2b–d. ","suffix":"(2.5)Since the best parameters m"}]}]}
>```
>%%
>*%%PREFIX%%dashed lines in figures 2.2b–d.%%HIGHLIGHT%% ==We quantify the total mismatch, training error,or loss as the sum of the squares of these deviations for all I training pairs:L[φ] =I∑i=1(f[xi,φ] −yi)2=I∑i=1(φ0 + φ1xi −yi)2 .== %%POSTFIX%%(2.5)Since the best parameters m*
>%%LINK%%[[#^9fpqcih5t1b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9fpqcih5t1b


>%%
>```annotation-json
>{"created":"2024-09-28T15:46:04.144Z","updated":"2024-09-28T15:46:04.144Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":67456,"end":67633},{"type":"TextQuoteSelector","exact":"Since the best parameters minimize this expression, we call this a least-squares loss. Thesquaring operation means that the direction of the deviation (i.e., whether the line is","prefix":")2=I∑i=1(φ0 + φ1xi −yi)2 . (2.5)","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%)2=I∑i=1(φ0 + φ1xi −yi)2 . (2.5)%%HIGHLIGHT%% ==Since the best parameters minimize this expression, we call this a least-squares loss. Thesquaring operation means that the direction of the deviation (i.e., whether the line is== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^oj0knkdwd7p|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^oj0knkdwd7p


>%%
>```annotation-json
>{"created":"2024-09-28T15:46:12.079Z","updated":"2024-09-28T15:46:12.079Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":69109,"end":69148},{"type":"TextQuoteSelector","exact":"above or below the data) is unimportant","prefix":"he smallest loss (green circle).","suffix":". There are also theoretical rea"}]}]}
>```
>%%
>*%%PREFIX%%he smallest loss (green circle).%%HIGHLIGHT%% ==above or below the data) is unimportant== %%POSTFIX%%. There are also theoretical rea*
>%%LINK%%[[#^mr5ya3fvvt9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mr5ya3fvvt9


>%%
>```annotation-json
>{"created":"2024-09-28T15:46:36.330Z","text":"What is *underfitting*?\nWhat is *overfitting*?","updated":"2024-09-28T15:46:36.330Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":69232,"end":69410},{"type":"TextQuoteSelector","exact":"The loss L is a function of the parameters φ; it will be larger when the model fit is Notebook 2.1Supervisedlearningpoor (figure 2.2b,c) and smaller when it is good (figure 2.2d)","prefix":"which we return to in chapter 5.","suffix":". Considered in this light,we te"}]}]}
>```
>%%
>*%%PREFIX%%which we return to in chapter 5.%%HIGHLIGHT%% ==The loss L is a function of the parameters φ; it will be larger when the model fit is Notebook 2.1Supervisedlearningpoor (figure 2.2b,c) and smaller when it is good (figure 2.2d)== %%POSTFIX%%. Considered in this light,we te*
>%%LINK%%[[#^0yscldy7sc4|show annotation]]
>%%COMMENT%%
>What is *underfitting*?
>What is *overfitting*?
>%%TAGS%%
>#question
^0yscldy7sc4


>%%
>```annotation-json
>{"created":"2024-09-28T15:52:04.304Z","updated":"2024-09-28T15:52:04.304Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":69412,"end":69633},{"type":"TextQuoteSelector","exact":"Considered in this light,we term L[φ] the loss function or cost function. The goal is to find the parameters ˆφthat minimize this quantity:ˆφ = argminφ[L[φ]]= argminφ[ I∑i=1(f[xi,φ] −yi)2]= argminφ[ I∑i=1(φ0 + φ1xi −yi)2]","prefix":" when it is good (figure 2.2d). ","suffix":". (2.6)There are only two parame"}]}]}
>```
>%%
>*%%PREFIX%%when it is good (figure 2.2d).%%HIGHLIGHT%% ==Considered in this light,we term L[φ] the loss function or cost function. The goal is to find the parameters ˆφthat minimize this quantity:ˆφ = argminφ[L[φ]]= argminφ[ I∑i=1(f[xi,φ] −yi)2]= argminφ[ I∑i=1(φ0 + φ1xi −yi)2]== %%POSTFIX%%. (2.6)There are only two parame*
>%%LINK%%[[#^ntjrip28lg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ntjrip28lg


>%%
>```annotation-json
>{"created":"2024-09-28T15:52:44.273Z","updated":"2024-09-28T15:52:44.273Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":69986,"end":70089},{"type":"TextQuoteSelector","exact":"The process of finding parameters that minimize the loss is termed model fitting, training,or learning.","prefix":"upervised learning2.2.3 Training","suffix":" The basic method is to choose t"}]}]}
>```
>%%
>*%%PREFIX%%upervised learning2.2.3 Training%%HIGHLIGHT%% ==The process of finding parameters that minimize the loss is termed model fitting, training,or learning.== %%POSTFIX%%The basic method is to choose t*
>%%LINK%%[[#^1tfxfevvt3i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1tfxfevvt3i


>%%
>```annotation-json
>{"created":"2024-09-28T15:52:57.395Z","updated":"2024-09-28T15:52:57.395Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":70091,"end":70235},{"type":"TextQuoteSelector","exact":"he basic method is to choose the initial parameters randomly and thenimprove them by “walking down” the loss function until we reach the bottom ","prefix":"fitting, training,or learning. T","suffix":"(figure 2.4).One way to do this "}]}]}
>```
>%%
>*%%PREFIX%%fitting, training,or learning. T%%HIGHLIGHT%% ==he basic method is to choose the initial parameters randomly and thenimprove them by “walking down” the loss function until we reach the bottom== %%POSTFIX%%(figure 2.4).One way to do this*
>%%LINK%%[[#^uixzi2nmipi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uixzi2nmipi


>%%
>```annotation-json
>{"created":"2024-09-28T15:53:04.586Z","updated":"2024-09-28T15:53:04.586Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":70248,"end":70479},{"type":"TextQuoteSelector","exact":"One way to do this is to measure the gradient of the surface at the current position andtake a step in the direction that is most steeply downhill. Then we repeat this processuntil the gradient is flat and we can improve no further","prefix":"e reach the bottom (figure 2.4).","suffix":".22.2.4 TestingHaving trained th"}]}]}
>```
>%%
>*%%PREFIX%%e reach the bottom (figure 2.4).%%HIGHLIGHT%% ==One way to do this is to measure the gradient of the surface at the current position andtake a step in the direction that is most steeply downhill. Then we repeat this processuntil the gradient is flat and we can improve no further== %%POSTFIX%%.22.2.4 TestingHaving trained th*
>%%LINK%%[[#^3kf8x70g48|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3kf8x70g48


>%%
>```annotation-json
>{"created":"2024-09-28T15:53:21.551Z","updated":"2024-09-28T15:53:21.551Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":70494,"end":70782},{"type":"TextQuoteSelector","exact":"Having trained the model, we want to know how it will perform in the real world. Wedo this by computing the loss on a separate set of test data. The degree to which theprediction accuracy generalizes to the test data depends in part on how representativeand complete the training data is.","prefix":"mprove no further.22.2.4 Testing","suffix":" However, it also depends on how"}]}]}
>```
>%%
>*%%PREFIX%%mprove no further.22.2.4 Testing%%HIGHLIGHT%% ==Having trained the model, we want to know how it will perform in the real world. Wedo this by computing the loss on a separate set of test data. The degree to which theprediction accuracy generalizes to the test data depends in part on how representativeand complete the training data is.== %%POSTFIX%%However, it also depends on how*
>%%LINK%%[[#^als2t0jib89|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^als2t0jib89


>%%
>```annotation-json
>{"created":"2024-09-28T15:53:40.337Z","updated":"2024-09-28T15:53:40.337Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":70784,"end":71147},{"type":"TextQuoteSelector","exact":"owever, it also depends on how expressive the modelis. A simple model like a line might not be able to capture the true relationship betweeninput and output. This is known as underfitting. Conversely, a very expressive modelmay describe statistical peculiarities of the training data that are atypical and lead tounusual predictions. This is known as overfitting.","prefix":"complete the training data is. H","suffix":"2.3 SummaryA supervised learning"}]}]}
>```
>%%
>*%%PREFIX%%complete the training data is. H%%HIGHLIGHT%% ==owever, it also depends on how expressive the modelis. A simple model like a line might not be able to capture the true relationship betweeninput and output. This is known as underfitting. Conversely, a very expressive modelmay describe statistical peculiarities of the training data that are atypical and lead tounusual predictions. This is known as overfitting.== %%POSTFIX%%2.3 SummaryA supervised learning*
>%%LINK%%[[#^nw9wl40w7hb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nw9wl40w7hb


>%%
>```annotation-json
>{"created":"2024-09-28T15:56:48.150Z","text":"Compare loss function vs cost function?","updated":"2024-09-28T15:56:48.150Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":73778,"end":74055},{"type":"TextQuoteSelector","exact":"However, more properly, a loss functionis the individual term associated with a data point (i.e., each of the squared terms on the right-hand side of equation 2.5), and the cost function is the overall quantity that is minimized (i.e.,the entire right-hand side of equation 2.5","prefix":"ction are used interchangeably. ","suffix":"). A cost function can contain a"}]}]}
>```
>%%
>*%%PREFIX%%ction are used interchangeably.%%HIGHLIGHT%% ==However, more properly, a loss functionis the individual term associated with a data point (i.e., each of the squared terms on the right-hand side of equation 2.5), and the cost function is the overall quantity that is minimized (i.e.,the entire right-hand side of equation 2.5== %%POSTFIX%%). A cost function can contain a*
>%%LINK%%[[#^dia0fmo6vi|show annotation]]
>%%COMMENT%%
>Compare loss function vs cost function?
>%%TAGS%%
>#question
^dia0fmo6vi


>%%
>```annotation-json
>{"created":"2024-09-28T15:57:35.143Z","updated":"2024-09-28T15:57:35.143Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":74174,"end":74262},{"type":"TextQuoteSelector","exact":"ore generally, an objectivefunction is any function that is to be maximized or minimized","prefix":"data points (see section 9.1). M","suffix":".Generative vs. discriminative m"}]}]}
>```
>%%
>*%%PREFIX%%data points (see section 9.1). M%%HIGHLIGHT%% ==ore generally, an objectivefunction is any function that is to be maximized or minimized== %%POSTFIX%%.Generative vs. discriminative m*
>%%LINK%%[[#^wrv04vom4i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wrv04vom4i


>%%
>```annotation-json
>{"created":"2024-09-28T15:57:45.541Z","updated":"2024-09-28T15:57:45.541Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":74058,"end":74171},{"type":"TextQuoteSelector","exact":"A cost function can contain additional terms thatare not associated with individual data points (see section 9.1)","prefix":"ght-hand side of equation 2.5). ","suffix":". More generally, an objectivefu"}]}]}
>```
>%%
>*%%PREFIX%%ght-hand side of equation 2.5).%%HIGHLIGHT%% ==A cost function can contain additional terms thatare not associated with individual data points (see section 9.1)== %%POSTFIX%%. More generally, an objectivefu*
>%%LINK%%[[#^9g067tjpu9f|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9g067tjpu9f


>%%
>```annotation-json
>{"created":"2024-09-28T15:58:23.667Z","text":"Compare *generative* vs *discriminative* models?","updated":"2024-09-28T15:58:23.667Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":74301,"end":74584},{"type":"TextQuoteSelector","exact":"The models y = f[x,φ] in this chapter are discrim-inative models. These make an output prediction y from real-world measurements x. Another Problem 2.3approach is to build a generative model x = g[y,φ], in which the real-world measurements xare computed as a function of the output y","prefix":"tive vs. discriminative models: ","suffix":".The generative approach has the"}]}]}
>```
>%%
>*%%PREFIX%%tive vs. discriminative models:%%HIGHLIGHT%% ==The models y = f[x,φ] in this chapter are discrim-inative models. These make an output prediction y from real-world measurements x. Another Problem 2.3approach is to build a generative model x = g[y,φ], in which the real-world measurements xare computed as a function of the output y== %%POSTFIX%%.The generative approach has the*
>%%LINK%%[[#^murixayfk6h|show annotation]]
>%%COMMENT%%
>Compare *generative* vs *discriminative* models?
>%%TAGS%%
>#question
^murixayfk6h


>%%
>```annotation-json
>{"created":"2024-09-28T15:58:49.368Z","updated":"2024-09-28T15:58:49.368Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":74585,"end":74882},{"type":"TextQuoteSelector","exact":"The generative approach has the disadvantage that it doesn’t directly predict y. To performinference, we must invert the generative equation as y = g−1[x,φ], and this may be diﬀicult.However, generative models have the advantage that we can build in prior knowledge about howthe data were created.","prefix":"d as a function of the output y.","suffix":" For example, if we wanted to pr"}]}]}
>```
>%%
>*%%PREFIX%%d as a function of the output y.%%HIGHLIGHT%% ==The generative approach has the disadvantage that it doesn’t directly predict y. To performinference, we must invert the generative equation as y = g−1[x,φ], and this may be diﬀicult.However, generative models have the advantage that we can build in prior knowledge about howthe data were created.== %%POSTFIX%%For example, if we wanted to pr*
>%%LINK%%[[#^86ag2uqsmtk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^86ag2uqsmtk


>%%
>```annotation-json
>{"created":"2024-09-28T16:04:36.834Z","text":"What is a shallow neural network?","updated":"2024-09-28T16:04:36.834Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":76941,"end":77066},{"type":"TextQuoteSelector","exact":"Shallow neural networks are functions y = f[x,φ] with parameters φ that map multivari-ate inputs x to multivariate outputs y.","prefix":"tputs.3.1 Neural network example","suffix":" We defer a full definition unti"}]}]}
>```
>%%
>*%%PREFIX%%tputs.3.1 Neural network example%%HIGHLIGHT%% ==Shallow neural networks are functions y = f[x,φ] with parameters φ that map multivari-ate inputs x to multivariate outputs y.== %%POSTFIX%%We defer a full definition unti*
>%%LINK%%[[#^7d4rpftr4gm|show annotation]]
>%%COMMENT%%
>What is a shallow neural network?
>%%TAGS%%
>#question
^7d4rpftr4gm


>%%
>```annotation-json
>{"created":"2024-09-28T16:08:35.820Z","updated":"2024-09-28T16:08:35.820Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":77284,"end":77353},{"type":"TextQuoteSelector","exact":"y = f[x,φ]= φ0 + φ1a[θ10 + θ11x] + φ2a[θ20 + θ21x] + φ3a[θ30 + θ31x].","prefix":",φ2,φ3,θ10,θ11,θ20,θ21,θ30,θ31}:","suffix":" (3.1)We can break down this cal"}]}]}
>```
>%%
>*%%PREFIX%%,φ2,φ3,θ10,θ11,θ20,θ21,θ30,θ31}:%%HIGHLIGHT%% ==y = f[x,φ]= φ0 + φ1a[θ10 + θ11x] + φ2a[θ20 + θ21x] + φ3a[θ30 + θ31x].== %%POSTFIX%%(3.1)We can break down this cal*
>%%LINK%%[[#^4ct3jvdgmev|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4ct3jvdgmev


>%%
>```annotation-json
>{"created":"2024-09-28T16:09:09.946Z","updated":"2024-09-28T16:09:09.946Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":77359,"end":77683},{"type":"TextQuoteSelector","exact":"We can break down this calculation into three parts: first, we compute three linearfunctions of the input data (θ10 + θ11x, θ20 + θ21x, and θ30 + θ31x). Second, we pass thethree results through an activation function a[•]. Finally, we weight the three resultingactivations with φ1,φ2, and φ3, sum them, and add an offset φ0.","prefix":"+ θ21x] + φ3a[θ30 + θ31x]. (3.1)","suffix":"To complete the description, we "}]}]}
>```
>%%
>*%%PREFIX%%+ θ21x] + φ3a[θ30 + θ31x]. (3.1)%%HIGHLIGHT%% ==We can break down this calculation into three parts: first, we compute three linearfunctions of the input data (θ10 + θ11x, θ20 + θ21x, and θ30 + θ31x). Second, we pass thethree results through an activation function a[•]. Finally, we weight the three resultingactivations with φ1,φ2, and φ3, sum them, and add an offset φ0.== %%POSTFIX%%To complete the description, we*
>%%LINK%%[[#^33kfv1rnx8w|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^33kfv1rnx8w


>%%
>```annotation-json
>{"created":"2024-09-28T16:09:28.224Z","updated":"2024-09-28T16:09:28.224Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":77820,"end":77849},{"type":"TextQuoteSelector","exact":"rectified linear unit or ReLU","prefix":"t the most common choice is the ","suffix":":a[z] = ReLU[z] ={0 z < 0z z ≥0 "}]}]}
>```
>%%
>*%%PREFIX%%t the most common choice is the%%HIGHLIGHT%% ==rectified linear unit or ReLU== %%POSTFIX%%:a[z] = ReLU[z] ={0 z < 0z z ≥0*
>%%LINK%%[[#^xfle5pezn3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xfle5pezn3


>%%
>```annotation-json
>{"created":"2024-09-28T16:09:34.708Z","text":"What is a ReLU function?","updated":"2024-09-28T16:09:34.708Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":77850,"end":77881},{"type":"TextQuoteSelector","exact":"a[z] = ReLU[z] ={0 z < 0z z ≥0 ","prefix":"e rectified linear unit or ReLU:","suffix":". (3.2)This returns the input wh"}]}]}
>```
>%%
>*%%PREFIX%%e rectified linear unit or ReLU:%%HIGHLIGHT%% ==a[z] = ReLU[z] ={0 z < 0z z ≥0== %%POSTFIX%%. (3.2)This returns the input wh*
>%%LINK%%[[#^8eg3iy6sja4|show annotation]]
>%%COMMENT%%
>What is a ReLU function?
>%%TAGS%%
>#question
^8eg3iy6sja4


>%%
>```annotation-json
>{"created":"2024-09-28T16:10:07.167Z","updated":"2024-09-28T16:10:07.167Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":77888,"end":77949},{"type":"TextQuoteSelector","exact":"This returns the input when it is positive and zero otherwise","prefix":" ReLU[z] ={0 z < 0z z ≥0 . (3.2)","suffix":" (figure 3.1).It is probably not"}]}]}
>```
>%%
>*%%PREFIX%%ReLU[z] ={0 z < 0z z ≥0 . (3.2)%%HIGHLIGHT%% ==This returns the input when it is positive and zero otherwise== %%POSTFIX%%(figure 3.1).It is probably not*
>%%LINK%%[[#^6xdogfsj4uo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6xdogfsj4uo


>%%
>```annotation-json
>{"created":"2024-09-28T16:21:05.658Z","updated":"2024-09-28T16:21:05.658Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":77731,"end":77755},{"type":"TextQuoteSelector","exact":"activation function a[•]","prefix":"description, we must define the ","suffix":". There aremany possibilities, b"}]}]}
>```
>%%
>*%%PREFIX%%description, we must define the%%HIGHLIGHT%% ==activation function a[•]== %%POSTFIX%%. There aremany possibilities, b*
>%%LINK%%[[#^e8rkind5k76|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^e8rkind5k76


>%%
>```annotation-json
>{"created":"2024-09-28T16:28:10.445Z","updated":"2024-09-28T16:28:10.445Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":79820,"end":79874},{"type":"TextQuoteSelector","exact":"h1 = a[θ10 + θ11x]h2 = a[θ20 + θ21x]h3 = a[θ30 + θ31x]","prefix":"ss.3.1 Neural network example 27","suffix":", (3.3)where we refer to h1, h2,"}]}]}
>```
>%%
>*%%PREFIX%%ss.3.1 Neural network example 27%%HIGHLIGHT%% ==h1 = a[θ10 + θ11x]h2 = a[θ20 + θ21x]h3 = a[θ30 + θ31x]== %%POSTFIX%%, (3.3)where we refer to h1, h2,*
>%%LINK%%[[#^qlta6df485q|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qlta6df485q


>%%
>```annotation-json
>{"created":"2024-09-28T16:28:16.437Z","updated":"2024-09-28T16:28:16.437Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":79896,"end":79929},{"type":"TextQuoteSelector","exact":"to h1, h2, and h3 as hidden units","prefix":"30 + θ31x], (3.3)where we refer ","suffix":". Second, we compute the output "}]}]}
>```
>%%
>*%%PREFIX%%30 + θ31x], (3.3)where we refer%%HIGHLIGHT%% ==to h1, h2, and h3 as hidden units== %%POSTFIX%%. Second, we compute the output*
>%%LINK%%[[#^k1cn9uk2ish|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^k1cn9uk2ish


>%%
>```annotation-json
>{"created":"2024-09-28T16:28:22.442Z","updated":"2024-09-28T16:28:22.442Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":80016,"end":80043},{"type":"TextQuoteSelector","exact":"y = φ0 + φ1h1 + φ2h2 + φ3h3","prefix":"n units with a linear function:1","suffix":". (3.4)Figure 3.3 shows the flow"}]}]}
>```
>%%
>*%%PREFIX%%n units with a linear function:1%%HIGHLIGHT%% ==y = φ0 + φ1h1 + φ2h2 + φ3h3== %%POSTFIX%%. (3.4)Figure 3.3 shows the flow*
>%%LINK%%[[#^h23ao3ww00l|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^h23ao3ww00l


>%%
>```annotation-json
>{"created":"2024-09-28T16:28:48.815Z","updated":"2024-09-28T16:28:48.815Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":80132,"end":80262},{"type":"TextQuoteSelector","exact":"Each hidden unit contains a linear function θ•0 + θ•1x of the input, and that line isclipped by the ReLU function a[•] below zero.","prefix":"tes the function in figure 3.2a.","suffix":" The positions where the three l"}]}]}
>```
>%%
>*%%PREFIX%%tes the function in figure 3.2a.%%HIGHLIGHT%% ==Each hidden unit contains a linear function θ•0 + θ•1x of the input, and that line isclipped by the ReLU function a[•] below zero.== %%POSTFIX%%The positions where the three l*
>%%LINK%%[[#^zk01szp1ylo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zk01szp1ylo


>%%
>```annotation-json
>{"created":"2024-09-28T16:29:41.884Z","updated":"2024-09-28T16:29:41.884Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":80263,"end":80517},{"type":"TextQuoteSelector","exact":"The positions where the three lines crosszero become the three “joints” in the final output. The three clipped lines are thenweighted by φ1, φ2, and φ3, respectively. Finally, the offset φ0 is added, which controlsthe overall height of the final function","prefix":" ReLU function a[•] below zero. ","suffix":". Problems 3.1–3.8Each linear re"}]}]}
>```
>%%
>*%%PREFIX%%ReLU function a[•] below zero.%%HIGHLIGHT%% ==The positions where the three lines crosszero become the three “joints” in the final output. The three clipped lines are thenweighted by φ1, φ2, and φ3, respectively. Finally, the offset φ0 is added, which controlsthe overall height of the final function== %%POSTFIX%%. Problems 3.1–3.8Each linear re*
>%%LINK%%[[#^7g5hj63msic|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7g5hj63msic


>%%
>```annotation-json
>{"created":"2024-09-28T16:30:06.451Z","updated":"2024-09-28T16:30:06.451Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":80635,"end":80740},{"type":"TextQuoteSelector","exact":"When a unit is clipped, we refer to it as inactive, and when it is notclipped, we refer to it as active. ","prefix":"ion pattern in thehidden units. ","suffix":"For example, the shaded region r"}]}]}
>```
>%%
>*%%PREFIX%%ion pattern in thehidden units.%%HIGHLIGHT%% ==When a unit is clipped, we refer to it as inactive, and when it is notclipped, we refer to it as active.== %%POSTFIX%%For example, the shaded region r*
>%%LINK%%[[#^759y02cvud6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^759y02cvud6


>%%
>```annotation-json
>{"created":"2024-09-28T16:30:31.502Z","updated":"2024-09-28T16:30:31.502Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":80864,"end":81031},{"type":"TextQuoteSelector","exact":"The slope ofeach linear region is determined by (i) the original slopes θ•1 of the active inputs for thisregion and (ii) the weights φ• that were subsequently applied.","prefix":"ot from h2 (which is inactive). ","suffix":" For example, the slope inthe sh"}]}]}
>```
>%%
>*%%PREFIX%%ot from h2 (which is inactive).%%HIGHLIGHT%% ==The slope ofeach linear region is determined by (i) the original slopes θ•1 of the active inputs for thisregion and (ii) the weights φ• that were subsequently applied.== %%POSTFIX%%For example, the slope inthe sh*
>%%LINK%%[[#^u9r9bm433t|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^u9r9bm433t


>%%
>```annotation-json
>{"created":"2024-09-28T16:31:04.366Z","updated":"2024-09-28T16:31:04.366Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":81203,"end":81353},{"type":"TextQuoteSelector","exact":"Each hidden unit contributes one “joint” to the function, so with three hidden units, Notebook 3.1Shallow networks Ithere can be four linear regions. ","prefix":" term is the slope in panel (i).","suffix":"However, only three of the slope"}]}]}
>```
>%%
>*%%PREFIX%%term is the slope in panel (i).%%HIGHLIGHT%% ==Each hidden unit contributes one “joint” to the function, so with three hidden units, Notebook 3.1Shallow networks Ithere can be four linear regions.== %%POSTFIX%%However, only three of the slope*
>%%LINK%%[[#^qd0adlswkh9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qd0adlswkh9


>%%
>```annotation-json
>{"created":"2024-09-28T16:31:26.321Z","updated":"2024-09-28T16:31:26.321Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":81353,"end":81554},{"type":"TextQuoteSelector","exact":"However, only three of the slopes of these regions areindependent; the fourth is either zero (if all the hidden units are inactive in this region)Problem 3.9or is a sum of slopes from the other regions","prefix":"ere can be four linear regions. ","suffix":".3.1.2 Depicting neural networks"}]}]}
>```
>%%
>*%%PREFIX%%ere can be four linear regions.%%HIGHLIGHT%% ==However, only three of the slopes of these regions areindependent; the fourth is either zero (if all the hidden units are inactive in this region)Problem 3.9or is a sum of slopes from the other regions== %%POSTFIX%%.3.1.2 Depicting neural networks*
>%%LINK%%[[#^czhof8m7zir|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^czhof8m7zir


>%%
>```annotation-json
>{"created":"2024-09-28T16:33:50.951Z","text":"How to depict a neural network?","updated":"2024-09-28T16:33:50.951Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":83149,"end":83173},{"type":"TextQuoteSelector","exact":"Depicting neural network","prefix":"roximation theorem 29Figure 3.4 ","suffix":"s. a) The input x is on the left"}]}]}
>```
>%%
>*%%PREFIX%%roximation theorem 29Figure 3.4%%HIGHLIGHT%% ==Depicting neural network== %%POSTFIX%%s. a) The input x is on the left*
>%%LINK%%[[#^vtnm1jayzrk|show annotation]]
>%%COMMENT%%
>How to depict a neural network?
>%%TAGS%%
>#question
^vtnm1jayzrk


>%%
>```annotation-json
>{"created":"2024-09-28T16:36:40.202Z","updated":"2024-09-28T16:36:40.202Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":84369,"end":84454},{"type":"TextQuoteSelector","exact":"The number of hidden units in a shallow network is a measure of the network capacity.","prefix":" output:y = φ0 +D∑d=1φdhd. (3.6)","suffix":"With ReLU activation functions, "}]}]}
>```
>%%
>*%%PREFIX%%output:y = φ0 +D∑d=1φdhd. (3.6)%%HIGHLIGHT%% ==The number of hidden units in a shallow network is a measure of the network capacity.== %%POSTFIX%%With ReLU activation functions,*
>%%LINK%%[[#^5df6dw6q288|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5df6dw6q288


>%%
>```annotation-json
>{"created":"2024-09-28T16:37:01.276Z","updated":"2024-09-28T16:37:01.276Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":84454,"end":84712},{"type":"TextQuoteSelector","exact":"With ReLU activation functions, the output of a network with D hidden units has at Problem 3.10most D joints and so is a piecewise linear function with at most D+ 1 linear regions. Aswe add more hidden units, the model can approximate more complex functions.","prefix":"measure of the network capacity.","suffix":"Indeed, with enough capacity (hi"}]}]}
>```
>%%
>*%%PREFIX%%measure of the network capacity.%%HIGHLIGHT%% ==With ReLU activation functions, the output of a network with D hidden units has at Problem 3.10most D joints and so is a piecewise linear function with at most D+ 1 linear regions. Aswe add more hidden units, the model can approximate more complex functions.== %%POSTFIX%%Indeed, with enough capacity (hi*
>%%LINK%%[[#^5ph0gajyww5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5ph0gajyww5


>%%
>```annotation-json
>{"created":"2024-09-28T16:42:52.944Z","updated":"2024-09-28T16:42:52.944Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":84712,"end":84882},{"type":"TextQuoteSelector","exact":"Indeed, with enough capacity (hidden units), a shallow network can describe anycontinuous 1D function defined on a compact subset of the real line to arbitrary precision.","prefix":"roximate more complex functions.","suffix":"To see this, consider that every"}]}]}
>```
>%%
>*%%PREFIX%%roximate more complex functions.%%HIGHLIGHT%% ==Indeed, with enough capacity (hidden units), a shallow network can describe anycontinuous 1D function defined on a compact subset of the real line to arbitrary precision.== %%POSTFIX%%To see this, consider that every*
>%%LINK%%[[#^tpriaeusxrr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tpriaeusxrr


>%%
>```annotation-json
>{"created":"2024-09-28T16:43:17.021Z","text":"What is the *universal approximation theorem*?","updated":"2024-09-28T16:43:17.021Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":85139,"end":85306},{"type":"TextQuoteSelector","exact":"Theuniversal approximation theorem proves that for any continuous function, there exists ashallow network that can approximate this function to any specified precision","prefix":"ximated by a line (figure 3.5). ","suffix":".Draft: please send errata to ud"}]}]}
>```
>%%
>*%%PREFIX%%ximated by a line (figure 3.5).%%HIGHLIGHT%% ==Theuniversal approximation theorem proves that for any continuous function, there exists ashallow network that can approximate this function to any specified precision== %%POSTFIX%%.Draft: please send errata to ud*
>%%LINK%%[[#^e39jxmxq4fc|show annotation]]
>%%COMMENT%%
>What is the *universal approximation theorem*?
>%%TAGS%%
>#question
^e39jxmxq4fc


>%%
>```annotation-json
>{"created":"2024-09-28T16:44:40.518Z","updated":"2024-09-28T16:44:40.518Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":85660,"end":85875},{"type":"TextQuoteSelector","exact":"he universal approximation theoremproves that, with enough hidden units, there exists a shallow neural network thatcan describe any given continuous function defined on a compact subset of RDito arbitrary precision.","prefix":"linear region per hidden unit. T","suffix":"3.3 Multivariate inputs and outp"}]}]}
>```
>%%
>*%%PREFIX%%linear region per hidden unit. T%%HIGHLIGHT%% ==he universal approximation theoremproves that, with enough hidden units, there exists a shallow neural network thatcan describe any given continuous function defined on a compact subset of RDito arbitrary precision.== %%POSTFIX%%3.3 Multivariate inputs and outp*
>%%LINK%%[[#^7029ml87a29|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7029ml87a29


>%%
>```annotation-json
>{"created":"2024-09-28T16:59:31.943Z","updated":"2024-09-28T16:59:31.943Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":86009,"end":86202},{"type":"TextQuoteSelector","exact":" the universal approximation theorem also holds for the more general casewhere the network maps multivariate inputs x = [x1,x2,...,xDi ]T to multivariate outputpredictions y = [y1,y2,...,yDo ]T","prefix":" single scalar output y.However,","suffix":" . We first explore how to exten"}]}]}
>```
>%%
>*%%PREFIX%%single scalar output y.However,%%HIGHLIGHT%% ==the universal approximation theorem also holds for the more general casewhere the network maps multivariate inputs x = [x1,x2,...,xDi ]T to multivariate outputpredictions y = [y1,y2,...,yDo ]T== %%POSTFIX%%. We first explore how to exten*
>%%LINK%%[[#^nccta0qx7x|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nccta0qx7x


>%%
>```annotation-json
>{"created":"2024-09-28T17:00:04.212Z","updated":"2024-09-28T17:00:04.212Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":86565,"end":86699},{"type":"TextQuoteSelector","exact":"So, a network with a scalar input x, four hiddenunits h1,h2,h3, and h4, and a 2D multivariate output y = [y1,y2]T would be defined as:","prefix":"e hidden units for each output. ","suffix":"h1 = a[θ10 + θ11x]h2 = a[θ20 + θ"}]}]}
>```
>%%
>*%%PREFIX%%e hidden units for each output.%%HIGHLIGHT%% ==So, a network with a scalar input x, four hiddenunits h1,h2,h3, and h4, and a 2D multivariate output y = [y1,y2]T would be defined as:== %%POSTFIX%%h1 = a[θ10 + θ11x]h2 = a[θ20 + θ*
>%%LINK%%[[#^ut54h0sgaam|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ut54h0sgaam


>%%
>```annotation-json
>{"created":"2024-09-28T17:00:08.127Z","updated":"2024-09-28T17:00:08.127Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":86699,"end":86773},{"type":"TextQuoteSelector","exact":"h1 = a[θ10 + θ11x]h2 = a[θ20 + θ21x]h3 = a[θ30 + θ31x]h4 = a[θ40 + θ41x], ","prefix":" = [y1,y2]T would be defined as:","suffix":"(3.7)andThis work is subject to "}]}]}
>```
>%%
>*%%PREFIX%%= [y1,y2]T would be defined as:%%HIGHLIGHT%% ==h1 = a[θ10 + θ11x]h2 = a[θ20 + θ21x]h3 = a[θ30 + θ31x]h4 = a[θ40 + θ41x],== %%POSTFIX%%(3.7)andThis work is subject to*
>%%LINK%%[[#^3dadcot1t26|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3dadcot1t26


>%%
>```annotation-json
>{"created":"2024-09-28T17:00:13.886Z","updated":"2024-09-28T17:00:13.886Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":87370,"end":87452},{"type":"TextQuoteSelector","exact":"y1 = φ10 + φ11h1 + φ12h2 + φ13h3 + φ14h4y2 = φ20 + φ21h1 + φ22h2 + φ23h3 + φ24h4. ","prefix":"x =[x1,x2]T and scalar output y.","suffix":"(3.8)The two outputs are two dif"}]}]}
>```
>%%
>*%%PREFIX%%x =[x1,x2]T and scalar output y.%%HIGHLIGHT%% ==y1 = φ10 + φ11h1 + φ12h2 + φ13h3 + φ14h4y2 = φ20 + φ21h1 + φ22h2 + φ23h3 + φ24h4.== %%POSTFIX%%(3.8)The two outputs are two dif*
>%%LINK%%[[#^m37x3lmk0j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^m37x3lmk0j


>%%
>```annotation-json
>{"created":"2024-09-28T17:05:24.029Z","updated":"2024-09-28T17:05:24.029Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":90947,"end":90991},{"type":"TextQuoteSelector","exact":"Di dimensions, this wouldcreate 2Di orthants","prefix":"d create eight octants, and for ","suffix":". Shallow neural networks usuall"}]}]}
>```
>%%
>*%%PREFIX%%d create eight octants, and for%%HIGHLIGHT%% ==Di dimensions, this wouldcreate 2Di orthants== %%POSTFIX%%. Shallow neural networks usuall*
>%%LINK%%[[#^g4s5i32a10h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^g4s5i32a10h


>%%
>```annotation-json
>{"created":"2024-09-28T17:05:49.657Z","text":"How many linear regions do a shallow neural network have?","updated":"2024-09-28T17:05:49.657Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":90994,"end":91123},{"type":"TextQuoteSelector","exact":"hallow neural networks usually have more hidden units than inputdimensions, so they typically create more than 2Di linear regions","prefix":"this wouldcreate 2Di orthants. S","suffix":".3.4 Shallow neural networks: ge"}]}]}
>```
>%%
>*%%PREFIX%%this wouldcreate 2Di orthants. S%%HIGHLIGHT%% ==hallow neural networks usually have more hidden units than inputdimensions, so they typically create more than 2Di linear regions== %%POSTFIX%%.3.4 Shallow neural networks: ge*
>%%LINK%%[[#^xfyfkbr0ymq|show annotation]]
>%%COMMENT%%
>How many linear regions do a shallow neural network have?
>%%TAGS%%
>#question
^xfyfkbr0ymq


>%%
>```annotation-json
>{"created":"2024-09-28T17:15:38.672Z","updated":"2024-09-28T17:15:38.672Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":92750,"end":92877},{"type":"TextQuoteSelector","exact":"a model with Di inputdimensions and Di hidden units can divide the input space with Di hyperplanesto create 2Di linear regions.","prefix":" this argument, it follows that ","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%this argument, it follows that%%HIGHLIGHT%% ==a model with Di inputdimensions and Di hidden units can divide the input space with Di hyperplanesto create 2Di linear regions.== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^1712vhjasy7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1712vhjasy7


>%%
>```annotation-json
>{"created":"2024-09-28T17:24:04.411Z","updated":"2024-09-28T17:24:04.411Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":91263,"end":91473},{"type":"TextQuoteSelector","exact":"e now define a general equation for a shallow neural network y = f[x,φ]that maps a multi-dimensional input x ∈ RDi to a multi-dimensional output y ∈ RDousing h ∈RD hidden units. Each hidden unit is computed as:","prefix":" intuition about howthey work. W","suffix":"hd = a[θd0 +Di∑i=1θdixi], (3.11)"}]}]}
>```
>%%
>*%%PREFIX%%intuition about howthey work. W%%HIGHLIGHT%% ==e now define a general equation for a shallow neural network y = f[x,φ]that maps a multi-dimensional input x ∈ RDi to a multi-dimensional output y ∈ RDousing h ∈RD hidden units. Each hidden unit is computed as:== %%POSTFIX%%hd = a[θd0 +Di∑i=1θdixi], (3.11)*
>%%LINK%%[[#^nsd3v9koso|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nsd3v9koso


>%%
>```annotation-json
>{"created":"2024-09-28T17:24:08.510Z","updated":"2024-09-28T17:24:08.510Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":91474,"end":91497},{"type":"TextQuoteSelector","exact":"d = a[θd0 +Di∑i=1θdixi]","prefix":"ach hidden unit is computed as:h","suffix":", (3.11)and these are combined l"}]}]}
>```
>%%
>*%%PREFIX%%ach hidden unit is computed as:h%%HIGHLIGHT%% ==d = a[θd0 +Di∑i=1θdixi]== %%POSTFIX%%, (3.11)and these are combined l*
>%%LINK%%[[#^bihmrtonvmr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bihmrtonvmr


>%%
>```annotation-json
>{"created":"2024-09-28T17:24:15.299Z","updated":"2024-09-28T17:24:15.299Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":93167,"end":93186},{"type":"TextQuoteSelector","exact":"j = φj0 +D∑d=1φjdhd","prefix":") and five offsets (not shown).y","suffix":", (3.12)where a[•] is a nonlinea"}]}]}
>```
>%%
>*%%PREFIX%%) and five offsets (not shown).y%%HIGHLIGHT%% ==j = φj0 +D∑d=1φjdhd== %%POSTFIX%%, (3.12)where a[•] is a nonlinea*
>%%LINK%%[[#^dabwa5pit1u|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dabwa5pit1u


>%%
>```annotation-json
>{"created":"2024-09-28T17:24:21.736Z","updated":"2024-09-28T17:24:21.736Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":93194,"end":93280},{"type":"TextQuoteSelector","exact":"where a[•] is a nonlinear activation function. The model has parameters φ = {θ••,φ••}.","prefix":"wn).yj = φj0 +D∑d=1φjdhd, (3.12)","suffix":"Figure 3.11 shows an example wit"}]}]}
>```
>%%
>*%%PREFIX%%wn).yj = φj0 +D∑d=1φjdhd, (3.12)%%HIGHLIGHT%% ==where a[•] is a nonlinear activation function. The model has parameters φ = {θ••,φ••}.== %%POSTFIX%%Figure 3.11 shows an example wit*
>%%LINK%%[[#^vvh5x7tlaj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vvh5x7tlaj


>%%
>```annotation-json
>{"created":"2024-09-28T17:24:42.157Z","text":"How does an activation function describe the mapping between input and output?","updated":"2024-09-28T17:24:42.157Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":93383,"end":93665},{"type":"TextQuoteSelector","exact":"The activation function permits the model to describe nonlinear relations betweeninput and the output, and as such, it must be nonlinear itself; with no activation func-tion, or a linear activation function, the overall mapping from input to output wouldbe restricted to be linear. ","prefix":" two outputs. Problems 3.14–3.17","suffix":"Many different activation functi"}]}]}
>```
>%%
>*%%PREFIX%%two outputs. Problems 3.14–3.17%%HIGHLIGHT%% ==The activation function permits the model to describe nonlinear relations betweeninput and the output, and as such, it must be nonlinear itself; with no activation func-tion, or a linear activation function, the overall mapping from input to output wouldbe restricted to be linear.== %%POSTFIX%%Many different activation functi*
>%%LINK%%[[#^dzntklo9jl5|show annotation]]
>%%COMMENT%%
>How does an activation function describe the mapping between input and output?
>%%TAGS%%
>#question
^dzntklo9jl5


>%%
>```annotation-json
>{"created":"2024-09-28T17:26:48.830Z","updated":"2024-09-28T17:26:48.830Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":94327,"end":94486},{"type":"TextQuoteSelector","exact":"They are often referred to in terms of layers. The left offigure 3.12 is the input layer, the center is the hidden layer, and to the right is the outputlayer. ","prefix":"ave a lot of associated jargon. ","suffix":"We would say that the network in"}]}]}
>```
>%%
>*%%PREFIX%%ave a lot of associated jargon.%%HIGHLIGHT%% ==They are often referred to in terms of layers. The left offigure 3.12 is the input layer, the center is the hidden layer, and to the right is the outputlayer.== %%POSTFIX%%We would say that the network in*
>%%LINK%%[[#^tlvvyv1kdr9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tlvvyv1kdr9


>%%
>```annotation-json
>{"created":"2024-09-28T17:26:58.866Z","text":"What are neurons?","updated":"2024-09-28T17:26:58.866Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":94581,"end":94646},{"type":"TextQuoteSelector","exact":"The hidden units themselves are sometimes referred to as neurons.","prefix":"er containingfour hidden units. ","suffix":"When we pass data through the ne"}]}]}
>```
>%%
>*%%PREFIX%%er containingfour hidden units.%%HIGHLIGHT%% ==The hidden units themselves are sometimes referred to as neurons.== %%POSTFIX%%When we pass data through the ne*
>%%LINK%%[[#^01lwx7nixal5|show annotation]]
>%%COMMENT%%
>What are neurons?
>%%TAGS%%
>#question
^01lwx7nixal5


>%%
>```annotation-json
>{"created":"2024-09-28T17:27:35.576Z","text":"What are *activations* and *pre-activations*?","updated":"2024-09-28T17:27:35.576Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":94646,"end":94889},{"type":"TextQuoteSelector","exact":"When we pass data through the network, the values of the inputs to the hidden layer(i.e., before the ReLU functions are applied) are termed pre-activations. The values atthe hidden layer (i.e., after the ReLU functions) are termed activations.","prefix":"ometimes referred to as neurons.","suffix":"For historical reasons, any neur"}]}]}
>```
>%%
>*%%PREFIX%%ometimes referred to as neurons.%%HIGHLIGHT%% ==When we pass data through the network, the values of the inputs to the hidden layer(i.e., before the ReLU functions are applied) are termed pre-activations. The values atthe hidden layer (i.e., after the ReLU functions) are termed activations.== %%POSTFIX%%For historical reasons, any neur*
>%%LINK%%[[#^e2ixlnc3f2l|show annotation]]
>%%COMMENT%%
>What are *activations* and *pre-activations*?
>%%TAGS%%
>#question
^e2ixlnc3f2l


>%%
>```annotation-json
>{"created":"2024-09-28T17:28:16.891Z","updated":"2024-09-28T17:28:16.891Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":95021,"end":95135},{"type":"TextQuoteSelector","exact":"Networks with one hidden layer (as describedin this chapter) are sometimes referred to as shallow neural networks.","prefix":"r perceptron, or MLP for short. ","suffix":" Networks withmultiple hidden la"}]}]}
>```
>%%
>*%%PREFIX%%r perceptron, or MLP for short.%%HIGHLIGHT%% ==Networks with one hidden layer (as describedin this chapter) are sometimes referred to as shallow neural networks.== %%POSTFIX%%Networks withmultiple hidden la*
>%%LINK%%[[#^yzrb7mmj1dd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yzrb7mmj1dd


>%%
>```annotation-json
>{"created":"2024-09-28T17:28:45.117Z","text":"What is a feed-forward network?\nWhat is a fully connected neural network?","updated":"2024-09-28T17:28:45.117Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":95136,"end":95561},{"type":"TextQuoteSelector","exact":"Networks withmultiple hidden layers (as described in the next chapter) are referred to as deep neuralnetworks. Neural networks in which the connections form an acyclic graph (i.e., a graphwith no loops, as in all the examples in this chapter) are referred to as feed-forwardnetworks. If every element in one layer connects to every element in the next (as inall the examples in this chapter), the network is fully connected. ","prefix":" to as shallow neural networks. ","suffix":"These connectionsDraft: please s"}]}]}
>```
>%%
>*%%PREFIX%%to as shallow neural networks.%%HIGHLIGHT%% ==Networks withmultiple hidden layers (as described in the next chapter) are referred to as deep neuralnetworks. Neural networks in which the connections form an acyclic graph (i.e., a graphwith no loops, as in all the examples in this chapter) are referred to as feed-forwardnetworks. If every element in one layer connects to every element in the next (as inall the examples in this chapter), the network is fully connected.== %%POSTFIX%%These connectionsDraft: please s*
>%%LINK%%[[#^nijc6ufnr6s|show annotation]]
>%%COMMENT%%
>What is a feed-forward network?
>What is a fully connected neural network?
>%%TAGS%%
>#question
^nijc6ufnr6s


>%%
>```annotation-json
>{"created":"2024-09-28T17:30:00.900Z","updated":"2024-09-28T17:30:00.900Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":95561,"end":95578},{"type":"TextQuoteSelector","exact":"These connections","prefix":"the network is fully connected. ","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%the network is fully connected.%%HIGHLIGHT%% ==These connections== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^r6xhkmw70t|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r6xhkmw70t


>%%
>```annotation-json
>{"created":"2024-09-28T17:30:16.913Z","text":"What are *network weights*?\nWhat are *biases*?","updated":"2024-09-28T17:30:16.913Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":96367,"end":96528},{"type":"TextQuoteSelector","exact":"represent slope parameters in the underlying equations and are referred to as networkweights. The offset parameters (not shown in figure 3.12) are called biases.","prefix":"applied) are termed activations.","suffix":"3.6 SummaryShallow neural networ"}]}]}
>```
>%%
>*%%PREFIX%%applied) are termed activations.%%HIGHLIGHT%% ==represent slope parameters in the underlying equations and are referred to as networkweights. The offset parameters (not shown in figure 3.12) are called biases.== %%POSTFIX%%3.6 SummaryShallow neural networ*
>%%LINK%%[[#^k2xlcww68f|show annotation]]
>%%COMMENT%%
>What are *network weights*?
>What are *biases*?
>%%TAGS%%
>#question
^k2xlcww68f


>%%
>```annotation-json
>{"created":"2024-09-28T17:31:32.411Z","updated":"2024-09-28T17:31:32.411Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":97588,"end":97742},{"type":"TextQuoteSelector","exact":"However, there is scant evidence that brain computation works in the same wayas neural networks, and it is unhelpful to think about biology going forward.","prefix":"ich also have denseconnections. ","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%ich also have denseconnections.%%HIGHLIGHT%% ==However, there is scant evidence that brain computation works in the same wayas neural networks, and it is unhelpful to think about biology going forward.== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^t88hv79mit|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^t88hv79mit


>%%
>```annotation-json
>{"created":"2024-09-28T17:33:33.061Z","updated":"2024-09-28T17:33:33.061Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":100357,"end":100395},{"type":"TextQuoteSelector","exact":"This is known as the dyingReLU problem","prefix":", so we cannot “walk downhill.” ","suffix":". Many variations on the ReLU ha"}]}]}
>```
>%%
>*%%PREFIX%%, so we cannot “walk downhill.”%%HIGHLIGHT%% ==This is known as the dyingReLU problem== %%POSTFIX%%. Many variations on the ReLU ha*
>%%LINK%%[[#^zj7ezd5ng5p|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zj7ezd5ng5p


>%%
>```annotation-json
>{"created":"2024-09-28T17:35:00.271Z","updated":"2024-09-28T17:35:00.271Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":100009,"end":100355},{"type":"TextQuoteSelector","exact":"However, the ReLU function has the disadvantage that its derivative is zero for negative inputs.If all the training examples produce negative inputs to a given ReLU function, then we cannotimprove the parameters feeding into this ReLU during training. The gradient with respect tothe incoming weights is locally flat, so we cannot “walk downhill.","prefix":"itive and large negative inputs.","suffix":"” This is known as the dyingReLU"}]}]}
>```
>%%
>*%%PREFIX%%itive and large negative inputs.%%HIGHLIGHT%% ==However, the ReLU function has the disadvantage that its derivative is zero for negative inputs.If all the training examples produce negative inputs to a given ReLU function, then we cannotimprove the parameters feeding into this ReLU during training. The gradient with respect tothe incoming weights is locally flat, so we cannot “walk downhill.== %%POSTFIX%%” This is known as the dyingReLU*
>%%LINK%%[[#^t1v7n6odx5t|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^t1v7n6odx5t


>%%
>```annotation-json
>{"created":"2024-09-28T17:36:27.794Z","updated":"2024-09-28T17:36:27.794Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":102666,"end":102934},{"type":"TextQuoteSelector","exact":"Universal approximation theorem: The width version of this theorem states that thereexists a network with one hidden layer containing a finite number of hidden units that canapproximate any specified continuous function on a compact subset of Rn to arbitrary accuracy.","prefix":"of the number of linear regions.","suffix":"This was proved by Cybenko (1989"}]}]}
>```
>%%
>*%%PREFIX%%of the number of linear regions.%%HIGHLIGHT%% ==Universal approximation theorem: The width version of this theorem states that thereexists a network with one hidden layer containing a finite number of hidden units that canapproximate any specified continuous function on a compact subset of Rn to arbitrary accuracy.== %%POSTFIX%%This was proved by Cybenko (1989*
>%%LINK%%[[#^jg564cskn3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jg564cskn3


>%%
>```annotation-json
>{"created":"2024-09-28T17:38:45.064Z","updated":"2024-09-28T17:38:45.064Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":103935,"end":104682},{"type":"TextQuoteSelector","exact":"Linear, aﬀine, and nonlinear functions: Technically, a linear transformation f[•] is anyfunction that obeys the principle of superposition, so f[a+b] = f[a]+f[b]. This definition impliesthat f[2a] = 2f[a].The weighted sum f[h1,h2,h3] = φ1h1 + φ2h2 + φ3h3 is linear, but once theoffset (bias) is added so f[h1,h2,h3] = φ0 + φ1h1 + φ2h2 + φ3h3, this is no longer true. To seethis, consider that the output is doubled when we double the arguments of the former function.This is not the case for the latter function, which is more properly termed an aﬀine function.However, it is common in machine learning to conflate these terms. We follow this conventionin this book and refer to both as linear. All other functions we will encounter are nonlinear.","prefix":" license. (C) MIT Press.Notes 39","suffix":"ProblemsProblem 3.1 What kind of"}]}]}
>```
>%%
>*%%PREFIX%%license. (C) MIT Press.Notes 39%%HIGHLIGHT%% ==Linear, aﬀine, and nonlinear functions: Technically, a linear transformation f[•] is anyfunction that obeys the principle of superposition, so f[a+b] = f[a]+f[b]. This definition impliesthat f[2a] = 2f[a].The weighted sum f[h1,h2,h3] = φ1h1 + φ2h2 + φ3h3 is linear, but once theoffset (bias) is added so f[h1,h2,h3] = φ0 + φ1h1 + φ2h2 + φ3h3, this is no longer true. To seethis, consider that the output is doubled when we double the arguments of the former function.This is not the case for the latter function, which is more properly termed an aﬀine function.However, it is common in machine learning to conflate these terms. We follow this conventionin this book and refer to both as linear. All other functions we will encounter are nonlinear.== %%POSTFIX%%ProblemsProblem 3.1 What kind of*
>%%LINK%%[[#^22u04bsh8ov|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^22u04bsh8ov


>%%
>```annotation-json
>{"created":"2024-09-28T18:01:41.454Z","updated":"2024-09-28T18:01:41.454Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":109355,"end":109777},{"type":"TextQuoteSelector","exact":"As the number of hidden units increases, shallow neural networks improve theirdescriptive power. Indeed, with enough hidden units, shallow networks can describearbitrarily complex functions in high dimensions. However, it turns out that for somefunctions, the required number of hidden units is impractically large. Deep networks canproduce many more linear regions than shallow networks for a given number of parame-ters.","prefix":"r mappings from input to output.","suffix":" Hence, from a practical standpo"}]}]}
>```
>%%
>*%%PREFIX%%r mappings from input to output.%%HIGHLIGHT%% ==As the number of hidden units increases, shallow neural networks improve theirdescriptive power. Indeed, with enough hidden units, shallow networks can describearbitrarily complex functions in high dimensions. However, it turns out that for somefunctions, the required number of hidden units is impractically large. Deep networks canproduce many more linear regions than shallow networks for a given number of parame-ters.== %%POSTFIX%%Hence, from a practical standpo*
>%%LINK%%[[#^vuis2or06wp|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vuis2or06wp


>%%
>```annotation-json
>{"created":"2024-09-28T18:05:00.879Z","updated":"2024-09-28T18:05:00.879Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":109960,"end":110214},{"type":"TextQuoteSelector","exact":"we first consider composingtwo shallow networks so the output of the first becomes the input of the second. Considertwo shallow networks with three hidden units each (figure 4.1a). The first network takesan input x and returns output y and is defined by:","prefix":"havior of deep neural networks, ","suffix":"h1 = a[θ10 + θ11x]h2 = a[θ20 + θ"}]}]}
>```
>%%
>*%%PREFIX%%havior of deep neural networks,%%HIGHLIGHT%% ==we first consider composingtwo shallow networks so the output of the first becomes the input of the second. Considertwo shallow networks with three hidden units each (figure 4.1a). The first network takesan input x and returns output y and is defined by:== %%POSTFIX%%h1 = a[θ10 + θ11x]h2 = a[θ20 + θ*
>%%LINK%%[[#^fgxjlkeqdf7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fgxjlkeqdf7


>%%
>```annotation-json
>{"created":"2024-09-28T18:05:04.490Z","updated":"2024-09-28T18:05:04.490Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":110214,"end":110269},{"type":"TextQuoteSelector","exact":"h1 = a[θ10 + θ11x]h2 = a[θ20 + θ21x]h3 = a[θ30 + θ31x],","prefix":"urns output y and is defined by:","suffix":" (4.1)andy = φ0 + φ1h1 + φ2h2 + "}]}]}
>```
>%%
>*%%PREFIX%%urns output y and is defined by:%%HIGHLIGHT%% ==h1 = a[θ10 + θ11x]h2 = a[θ20 + θ21x]h3 = a[θ30 + θ31x],== %%POSTFIX%%(4.1)andy = φ0 + φ1h1 + φ2h2 +*
>%%LINK%%[[#^qgluqpzfp9g|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qgluqpzfp9g


>%%
>```annotation-json
>{"created":"2024-09-28T18:05:09.432Z","updated":"2024-09-28T18:05:09.432Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":110278,"end":110305},{"type":"TextQuoteSelector","exact":"y = φ0 + φ1h1 + φ2h2 + φ3h3","prefix":"21x]h3 = a[θ30 + θ31x], (4.1)and","suffix":". (4.2)The second network takes "}]}]}
>```
>%%
>*%%PREFIX%%21x]h3 = a[θ30 + θ31x], (4.1)and%%HIGHLIGHT%% ==y = φ0 + φ1h1 + φ2h2 + φ3h3== %%POSTFIX%%. (4.2)The second network takes*
>%%LINK%%[[#^nlp9jca06b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nlp9jca06b


>%%
>```annotation-json
>{"created":"2024-09-28T18:05:18.724Z","updated":"2024-09-28T18:05:18.724Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":110312,"end":110381},{"type":"TextQuoteSelector","exact":"The second network takes y as input and returns y′ and is defined by:","prefix":"= φ0 + φ1h1 + φ2h2 + φ3h3. (4.2)","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%= φ0 + φ1h1 + φ2h2 + φ3h3. (4.2)%%HIGHLIGHT%% ==The second network takes y as input and returns y′ and is defined by:== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^7srazap54ar|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7srazap54ar


>%%
>```annotation-json
>{"created":"2024-09-28T18:08:09.784Z","updated":"2024-09-28T18:08:09.784Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":111587,"end":111652},{"type":"TextQuoteSelector","exact":"h′1 = a[θ′10 + θ′11y]h′2 = a[θ′20 + θ′21y]h′3 = a[θ′30 + θ′31y], ","prefix":"ing networks to deep networks 43","suffix":"(4.3)andy′ = φ′0 + φ′1h′1 + φ′2h"}]}]}
>```
>%%
>*%%PREFIX%%ing networks to deep networks 43%%HIGHLIGHT%% ==h′1 = a[θ′10 + θ′11y]h′2 = a[θ′20 + θ′21y]h′3 = a[θ′30 + θ′31y],== %%POSTFIX%%(4.3)andy′ = φ′0 + φ′1h′1 + φ′2h*
>%%LINK%%[[#^uvfm7s85ur|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uvfm7s85ur


>%%
>```annotation-json
>{"created":"2024-09-28T18:08:13.490Z","updated":"2024-09-28T18:08:13.490Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":111660,"end":111696},{"type":"TextQuoteSelector","exact":"y′ = φ′0 + φ′1h′1 + φ′2h′2 + φ′3h′3.","prefix":"]h′3 = a[θ′30 + θ′31y], (4.3)and","suffix":" (4.4)With ReLU activations, thi"}]}]}
>```
>%%
>*%%PREFIX%%]h′3 = a[θ′30 + θ′31y], (4.3)and%%HIGHLIGHT%% ==y′ = φ′0 + φ′1h′1 + φ′2h′2 + φ′3h′3.== %%POSTFIX%%(4.4)With ReLU activations, thi*
>%%LINK%%[[#^cxauozlu4nm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cxauozlu4nm


>%%
>```annotation-json
>{"created":"2024-09-28T18:09:09.324Z","updated":"2024-09-28T18:09:09.324Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":111702,"end":112426},{"type":"TextQuoteSelector","exact":"With ReLU activations, this model also describes a family of piecewise linear functions.However, the number of linear regions is potentially greater than for a shallow networkwith six hidden units. To see this, consider choosing the first network to produce three Problem 4.1alternating regions of positive and negative slope (figure 4.1b). This means that threedifferent ranges of x are mapped to the same output range y ∈[−1,1], and the subsequentmapping from this range of y to y′ is applied three times. The overall effect is that the Notebook 4.1Composingnetworksfunction defined by the second network is duplicated three times to create nine linearregions. The same principle applies in higher dimensions (figure 4.2).","prefix":" φ′1h′1 + φ′2h′2 + φ′3h′3. (4.4)","suffix":"A different way to think about c"}]}]}
>```
>%%
>*%%PREFIX%%φ′1h′1 + φ′2h′2 + φ′3h′3. (4.4)%%HIGHLIGHT%% ==With ReLU activations, this model also describes a family of piecewise linear functions.However, the number of linear regions is potentially greater than for a shallow networkwith six hidden units. To see this, consider choosing the first network to produce three Problem 4.1alternating regions of positive and negative slope (figure 4.1b). This means that threedifferent ranges of x are mapped to the same output range y ∈[−1,1], and the subsequentmapping from this range of y to y′ is applied three times. The overall effect is that the Notebook 4.1Composingnetworksfunction defined by the second network is duplicated three times to create nine linearregions. The same principle applies in higher dimensions (figure 4.2).== %%POSTFIX%%A different way to think about c*
>%%LINK%%[[#^gj7ukyfpr4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gj7ukyfpr4


>%%
>```annotation-json
>{"created":"2024-09-28T18:09:33.836Z","updated":"2024-09-28T18:09:33.836Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":112426,"end":112722},{"type":"TextQuoteSelector","exact":"A different way to think about composing networks is that the first network “folds”the input space x back onto itself so that multiple inputs generate the same output.Then the second network applies a function, which is replicated at all points that werefolded on top of one another (figure 4.3).","prefix":" higher dimensions (figure 4.2).","suffix":"4.2 From composing networks to d"}]}]}
>```
>%%
>*%%PREFIX%%higher dimensions (figure 4.2).%%HIGHLIGHT%% ==A different way to think about composing networks is that the first network “folds”the input space x back onto itself so that multiple inputs generate the same output.Then the second network applies a function, which is replicated at all points that werefolded on top of one another (figure 4.3).== %%POSTFIX%%4.2 From composing networks to d*
>%%LINK%%[[#^bktllo8k66w|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bktllo8k66w


>%%
>```annotation-json
>{"created":"2024-09-28T18:12:01.835Z","updated":"2024-09-28T18:12:01.835Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":112987,"end":113413},{"type":"TextQuoteSelector","exact":"The output of the first network (y = φ0 + φ1h1 + φ2h2 + φ3h3) is a linear combina-tion of the activations at the hidden units. The first operations of the second network(equation 4.3 in which we calculate θ′10 + θ′11y, θ′20 + θ′21y, and θ′30 + θ′31y) are linear inthe output of the first network. Applying one linear function to another yields anotherlinear function. Substituting the expression for y into equation 4.3 gives:","prefix":" network with two hidden layers.","suffix":"h′1 = a[θ′10 + θ′11y] = a[θ′10 +"}]}]}
>```
>%%
>*%%PREFIX%%network with two hidden layers.%%HIGHLIGHT%% ==The output of the first network (y = φ0 + φ1h1 + φ2h2 + φ3h3) is a linear combina-tion of the activations at the hidden units. The first operations of the second network(equation 4.3 in which we calculate θ′10 + θ′11y, θ′20 + θ′21y, and θ′30 + θ′31y) are linear inthe output of the first network. Applying one linear function to another yields anotherlinear function. Substituting the expression for y into equation 4.3 gives:== %%POSTFIX%%h′1 = a[θ′10 + θ′11y] = a[θ′10 +*
>%%LINK%%[[#^o4w973k5nf8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^o4w973k5nf8


>%%
>```annotation-json
>{"created":"2024-09-28T18:12:14.324Z","updated":"2024-09-28T18:12:14.324Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":113413,"end":113772},{"type":"TextQuoteSelector","exact":"h′1 = a[θ′10 + θ′11y] = a[θ′10 + θ′11φ0 + θ′11φ1h1 + θ′11φ2h2 + θ′11φ3h3]h′2 = a[θ′20 + θ′21y] = a[θ′20 + θ′21φ0 + θ′21φ1h1 + θ′21φ2h2 + θ′21φ3h3]h′3 = a[θ′30 + θ′31y] = a[θ′30 + θ′31φ0 + θ′31φ1h1 + θ′31φ2h2 + θ′31φ3h3], (4.5)which we can rewrite as:h′1 = a[ψ10 + ψ11h1 + ψ12h2 + ψ13h3]h′2 = a[ψ20 + ψ21h1 + ψ22h2 + ψ23h3]h′3 = a[ψ30 + ψ31h1 + ψ32h2 + ψ33h3],","prefix":"n for y into equation 4.3 gives:","suffix":" (4.6)Draft: please send errata "}]}]}
>```
>%%
>*%%PREFIX%%n for y into equation 4.3 gives:%%HIGHLIGHT%% ==h′1 = a[θ′10 + θ′11y] = a[θ′10 + θ′11φ0 + θ′11φ1h1 + θ′11φ2h2 + θ′11φ3h3]h′2 = a[θ′20 + θ′21y] = a[θ′20 + θ′21φ0 + θ′21φ1h1 + θ′21φ2h2 + θ′21φ3h3]h′3 = a[θ′30 + θ′31y] = a[θ′30 + θ′31φ0 + θ′31φ1h1 + θ′31φ2h2 + θ′31φ3h3], (4.5)which we can rewrite as:h′1 = a[ψ10 + ψ11h1 + ψ12h2 + ψ13h3]h′2 = a[ψ20 + ψ21h1 + ψ22h2 + ψ23h3]h′3 = a[ψ30 + ψ31h1 + ψ32h2 + ψ33h3],== %%POSTFIX%%(4.6)Draft: please send errata*
>%%LINK%%[[#^gkfpiko1t6s|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gkfpiko1t6s


>%%
>```annotation-json
>{"created":"2024-09-28T18:14:44.100Z","updated":"2024-09-28T18:14:44.100Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":114966,"end":115075},{"type":"TextQuoteSelector","exact":"where ψ10 = θ′10 + θ′11φ0,ψ11 = θ′11φ1,ψ12 = θ′11φ2 and so on. The result is a networkwith two hidden layers ","prefix":"h containing three hidden units.","suffix":"(figure 4.4).It follows that a n"}]}]}
>```
>%%
>*%%PREFIX%%h containing three hidden units.%%HIGHLIGHT%% ==where ψ10 = θ′10 + θ′11φ0,ψ11 = θ′11φ1,ψ12 = θ′11φ2 and so on. The result is a networkwith two hidden layers== %%POSTFIX%%(figure 4.4).It follows that a n*
>%%LINK%%[[#^d7ijqljuq9r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^d7ijqljuq9r


>%%
>```annotation-json
>{"created":"2024-09-28T18:17:11.664Z","updated":"2024-09-28T18:17:11.664Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":115762,"end":116042},{"type":"TextQuoteSelector","exact":"The first layer is defined by:h1 = a[θ10 + θ11x]h2 = a[θ20 + θ21x]h3 = a[θ30 + θ31x], (4.7)the second layer by:h′1 = a[ψ10 + ψ11h1 + ψ12h2 + ψ13h3]h′2 = a[ψ20 + ψ21h1 + ψ22h2 + ψ23h3]h′3 = a[ψ30 + ψ31h1 + ψ32h2 + ψ33h3], (4.8)and the output by:y′ = φ′0 + φ′1h′1 + φ′2h′2 + φ′3h′3.","prefix":"three hidden units (figure 4.4).","suffix":" (4.9)Draft: please send errata "}]}]}
>```
>%%
>*%%PREFIX%%three hidden units (figure 4.4).%%HIGHLIGHT%% ==The first layer is defined by:h1 = a[θ10 + θ11x]h2 = a[θ20 + θ21x]h3 = a[θ30 + θ31x], (4.7)the second layer by:h′1 = a[ψ10 + ψ11h1 + ψ12h2 + ψ13h3]h′2 = a[ψ20 + ψ21h1 + ψ22h2 + ψ23h3]h′3 = a[ψ30 + ψ31h1 + ψ32h2 + ψ33h3], (4.8)and the output by:y′ = φ′0 + φ′1h′1 + φ′2h′2 + φ′3h′3.== %%POSTFIX%%(4.9)Draft: please send errata*
>%%LINK%%[[#^0qcom1hz7w9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0qcom1hz7w9


>%%
>```annotation-json
>{"created":"2024-09-28T18:18:05.117Z","updated":"2024-09-28T18:18:05.117Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":116295,"end":116481},{"type":"TextQuoteSelector","exact":"1. The three hidden units h1,h2, and h3 in the first layer are computed as usual byforming linear functions of the input and passing these through ReLU activationfunctions (equation 4.7)","prefix":"mplicated function (figure 4.5):","suffix":".2. The pre-activations at the s"}]}]}
>```
>%%
>*%%PREFIX%%mplicated function (figure 4.5):%%HIGHLIGHT%% ==1. The three hidden units h1,h2, and h3 in the first layer are computed as usual byforming linear functions of the input and passing these through ReLU activationfunctions (equation 4.7)== %%POSTFIX%%.2. The pre-activations at the s*
>%%LINK%%[[#^nlmsu2v3tz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nlmsu2v3tz


>%%
>```annotation-json
>{"created":"2024-09-28T18:18:24.315Z","updated":"2024-09-28T18:18:24.315Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":116482,"end":116852},{"type":"TextQuoteSelector","exact":"2. The pre-activations at the second layer are computed by taking three new linearfunctions of these hidden units (arguments of the activation functions in equa-tion 4.8). At this point, we effectively have a shallow network with three outputs;we have computed three piecewise linear functions with the “joints” between linearregions in the same places (see figure 3.6).","prefix":"ivationfunctions (equation 4.7).","suffix":"3. At the second hidden layer, a"}]}]}
>```
>%%
>*%%PREFIX%%ivationfunctions (equation 4.7).%%HIGHLIGHT%% ==2. The pre-activations at the second layer are computed by taking three new linearfunctions of these hidden units (arguments of the activation functions in equa-tion 4.8). At this point, we effectively have a shallow network with three outputs;we have computed three piecewise linear functions with the “joints” between linearregions in the same places (see figure 3.6).== %%POSTFIX%%3. At the second hidden layer, a*
>%%LINK%%[[#^xx1215ug6ni|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xx1215ug6ni


>%%
>```annotation-json
>{"created":"2024-09-28T18:19:14.681Z","updated":"2024-09-28T18:19:14.681Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":116852,"end":117000},{"type":"TextQuoteSelector","exact":"3. At the second hidden layer, another ReLU function a[•] is applied to each function(equation 4.8), which clips them and adds new “joints” to each.","prefix":"he same places (see figure 3.6).","suffix":"4. The final output is a linear "}]}]}
>```
>%%
>*%%PREFIX%%he same places (see figure 3.6).%%HIGHLIGHT%% ==3. At the second hidden layer, another ReLU function a[•] is applied to each function(equation 4.8), which clips them and adds new “joints” to each.== %%POSTFIX%%4. The final output is a linear*
>%%LINK%%[[#^3l4oqv3ts5z|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3l4oqv3ts5z


>%%
>```annotation-json
>{"created":"2024-09-28T18:19:46.216Z","updated":"2024-09-28T18:19:46.216Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":117000,"end":117081},{"type":"TextQuoteSelector","exact":"4. The final output is a linear combination of these hidden units (equation 4.9).","prefix":"m and adds new “joints” to each.","suffix":"In conclusion, we can either thi"}]}]}
>```
>%%
>*%%PREFIX%%m and adds new “joints” to each.%%HIGHLIGHT%% ==4. The final output is a linear combination of these hidden units (equation 4.9).== %%POSTFIX%%In conclusion, we can either thi*
>%%LINK%%[[#^nqao3ukje1|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nqao3ukje1


>%%
>```annotation-json
>{"created":"2024-09-28T18:20:58.552Z","updated":"2024-09-28T18:20:58.552Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":117686,"end":117898},{"type":"TextQuoteSelector","exact":"y′ = φ′0 + φ′1a[ψ10 + ψ11a[θ10 + θ11x] + ψ12a[θ20 + θ21x] + ψ13a[θ30 + θ31x]]+φ′2a[ψ20 + ψ21a[θ10 + θ11x] + ψ22a[θ20 + θ21x] + ψ23a[θ30 + θ31x]]+φ′3a[ψ30 + ψ31a[θ10 + θ11x] + ψ32a[θ20 + θ21x] + ψ33a[θ30 + θ31x]],","prefix":"s 4.7–4.9 to get one expression:","suffix":"(4.10)although this is admittedl"}]}]}
>```
>%%
>*%%PREFIX%%s 4.7–4.9 to get one expression:%%HIGHLIGHT%% ==y′ = φ′0 + φ′1a[ψ10 + ψ11a[θ10 + θ11x] + ψ12a[θ20 + θ21x] + ψ13a[θ30 + θ31x]]+φ′2a[ψ20 + ψ21a[θ10 + θ11x] + ψ22a[θ20 + θ21x] + ψ23a[θ30 + θ31x]]+φ′3a[ψ30 + ψ31a[θ10 + θ11x] + ψ32a[θ20 + θ21x] + ψ33a[θ30 + θ31x]],== %%POSTFIX%%(4.10)although this is admittedl*
>%%LINK%%[[#^1hko1vkjkd5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1hko1vkjkd5


>%%
>```annotation-json
>{"created":"2024-09-28T18:21:30.095Z","text":"What is a deep neural network's *width*, *depth* and *capacity*?","updated":"2024-09-28T18:21:30.095Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":118157,"end":118358},{"type":"TextQuoteSelector","exact":"The number of hidden units in each layer is referred to as the width of the network,and the number of hidden layers as the depth. The total number of hidden units is ameasure of the network’s capacity.","prefix":"s of hidden units at eachlayer. ","suffix":"We denote the number of layers a"}]}]}
>```
>%%
>*%%PREFIX%%s of hidden units at eachlayer.%%HIGHLIGHT%% ==The number of hidden units in each layer is referred to as the width of the network,and the number of hidden layers as the depth. The total number of hidden units is ameasure of the network’s capacity.== %%POSTFIX%%We denote the number of layers a*
>%%LINK%%[[#^kkornez4iqb|show annotation]]
>%%COMMENT%%
>What is a deep neural network's *width*, *depth* and *capacity*?
>%%TAGS%%
>#question
^kkornez4iqb


>%%
>```annotation-json
>{"created":"2024-09-28T18:22:58.319Z","text":"What are *hyperparameters*?","updated":"2024-09-28T18:22:58.319Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":118358,"end":118494},{"type":"TextQuoteSelector","exact":"We denote the number of layers as K and the number of hidden units in each layeras D1,D2,...,DK . These are examples of hyperparameters.","prefix":"asure of the network’s capacity.","suffix":" They are quantities chosenProbl"}]}]}
>```
>%%
>*%%PREFIX%%asure of the network’s capacity.%%HIGHLIGHT%% ==We denote the number of layers as K and the number of hidden units in each layeras D1,D2,...,DK . These are examples of hyperparameters.== %%POSTFIX%%They are quantities chosenProbl*
>%%LINK%%[[#^s7l43rlhv4|show annotation]]
>%%COMMENT%%
>What are *hyperparameters*?
>%%TAGS%%
>#question
^s7l43rlhv4


>%%
>```annotation-json
>{"created":"2024-09-28T18:43:13.526Z","updated":"2024-09-28T18:43:13.526Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":121267,"end":121593},{"type":"TextQuoteSelector","exact":"ence, from nowon, we will describe the vector of hidden units at layer k as hk, the vector of biases(intercepts) that contribute to hidden layer k+1 as βk, and the weights (slopes) thatare applied to the kth layer and contribute to the (k+1)th layer as Ωk. A general deepnetwork y = f[x,φ] with K layers can now be written as:","prefix":"for networks with many layers. H","suffix":"h1 = a[β0 + Ω0x]h2 = a[β1 + Ω1h1"}]}]}
>```
>%%
>*%%PREFIX%%for networks with many layers. H%%HIGHLIGHT%% ==ence, from nowon, we will describe the vector of hidden units at layer k as hk, the vector of biases(intercepts) that contribute to hidden layer k+1 as βk, and the weights (slopes) thatare applied to the kth layer and contribute to the (k+1)th layer as Ωk. A general deepnetwork y = f[x,φ] with K layers can now be written as:== %%POSTFIX%%h1 = a[β0 + Ω0x]h2 = a[β1 + Ω1h1*
>%%LINK%%[[#^wb920i6prx|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wb920i6prx


>%%
>```annotation-json
>{"created":"2024-09-28T18:43:18.383Z","updated":"2024-09-28T18:43:18.383Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":121593,"end":121685},{"type":"TextQuoteSelector","exact":"h1 = a[β0 + Ω0x]h2 = a[β1 + Ω1h1]h3 = a[β2 + Ω2h2]...hK = a[βK−1 + ΩK−1hK−1]y = βK + ΩK hK .","prefix":" K layers can now be written as:","suffix":" (4.15)The parameters φ of this "}]}]}
>```
>%%
>*%%PREFIX%%K layers can now be written as:%%HIGHLIGHT%% ==h1 = a[β0 + Ω0x]h2 = a[β1 + Ω1h1]h3 = a[β2 + Ω2h2]...hK = a[βK−1 + ΩK−1hK−1]y = βK + ΩK hK .== %%POSTFIX%%(4.15)The parameters φ of this*
>%%LINK%%[[#^77q2fonnvdm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^77q2fonnvdm


>%%
>```annotation-json
>{"created":"2024-09-28T18:44:33.836Z","updated":"2024-09-28T18:44:33.836Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":121692,"end":121793},{"type":"TextQuoteSelector","exact":"The parameters φ of this model comprise all of these weight matrices and bias vectorsφ = {βk,Ωk}Kk=0.","prefix":"ΩK−1hK−1]y = βK + ΩK hK . (4.15)","suffix":"If the kth layer has Dk hidden u"}]}]}
>```
>%%
>*%%PREFIX%%ΩK−1hK−1]y = βK + ΩK hK . (4.15)%%HIGHLIGHT%% ==The parameters φ of this model comprise all of these weight matrices and bias vectorsφ = {βk,Ωk}Kk=0.== %%POSTFIX%%If the kth layer has Dk hidden u*
>%%LINK%%[[#^ag8zivn3p6v|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ag8zivn3p6v


>%%
>```annotation-json
>{"created":"2024-09-28T18:45:01.781Z","updated":"2024-09-28T18:45:01.781Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":121793,"end":122127},{"type":"TextQuoteSelector","exact":"If the kth layer has Dk hidden units, then the bias vector βk−1 will be of size Dk.The last bias vector βK has the size Do of the output. The first weight matrix Ω0 has Notebook 4.3Deep networkssize D1 ×Di where Di is the size of the input. The last weight matrix ΩK is Do ×DK ,and the remaining matrices Ωk are Dk+1 ×Dk (figure 4.6).","prefix":"and bias vectorsφ = {βk,Ωk}Kk=0.","suffix":"We can equivalently write the ne"}]}]}
>```
>%%
>*%%PREFIX%%and bias vectorsφ = {βk,Ωk}Kk=0.%%HIGHLIGHT%% ==If the kth layer has Dk hidden units, then the bias vector βk−1 will be of size Dk.The last bias vector βK has the size Do of the output. The first weight matrix Ω0 has Notebook 4.3Deep networkssize D1 ×Di where Di is the size of the input. The last weight matrix ΩK is Do ×DK ,and the remaining matrices Ωk are Dk+1 ×Dk (figure 4.6).== %%POSTFIX%%We can equivalently write the ne*
>%%LINK%%[[#^hq3cqwqsr79|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hq3cqwqsr79


>%%
>```annotation-json
>{"created":"2024-09-28T18:45:10.664Z","updated":"2024-09-28T18:45:10.664Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":122127,"end":122267},{"type":"TextQuoteSelector","exact":"We can equivalently write the network as a single function: Problems 4.3–4.6y = βK + ΩK a[βK−1 + ΩK−1a[...β2 + Ω2a[β1 + Ω1a[β0 + Ω0x]] ...]]","prefix":"es Ωk are Dk+1 ×Dk (figure 4.6).","suffix":".(4.16)4.5 Shallow vs. deep neur"}]}]}
>```
>%%
>*%%PREFIX%%es Ωk are Dk+1 ×Dk (figure 4.6).%%HIGHLIGHT%% ==We can equivalently write the network as a single function: Problems 4.3–4.6y = βK + ΩK a[βK−1 + ΩK−1a[...β2 + Ω2a[β1 + Ω1a[β0 + Ω0x]] ...]]== %%POSTFIX%%.(4.16)4.5 Shallow vs. deep neur*
>%%LINK%%[[#^e8aechm4fh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^e8aechm4fh


>%%
>```annotation-json
>{"created":"2024-09-28T19:25:23.757Z","updated":"2024-09-28T19:25:23.757Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":122869,"end":122990},{"type":"TextQuoteSelector","exact":"If the second of these networks computes the identity function, thenthis deep network replicates a single shallow network","prefix":"osition of twoshallow networks. ","suffix":". Hence, it can also approximate"}]}]}
>```
>%%
>*%%PREFIX%%osition of twoshallow networks.%%HIGHLIGHT%% ==If the second of these networks computes the identity function, thenthis deep network replicates a single shallow network== %%POSTFIX%%. Hence, it can also approximate*
>%%LINK%%[[#^d76bbn7j5i5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^d76bbn7j5i5


>%%
>```annotation-json
>{"created":"2024-09-28T19:26:01.111Z","text":"How many linear regions can a deep neural network create?","updated":"2024-09-28T19:26:01.111Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":123146,"end":123480},{"type":"TextQuoteSelector","exact":"A shallow network with one input, one output, and D > 2 hidden units can create upto D + 1 linear regions and is defined by 3D + 1 parameters. A deep network with oneProblems 4.8–4.11 input, one output, and K layers of D > 2 hidden units can create a function with up to(D + 1)K linear regions using 3D + 1 + (K −1)D(D + 1) parameters","prefix":" of linear regions per parameter","suffix":".Figure 4.7a shows how the maxim"}]}]}
>```
>%%
>*%%PREFIX%%of linear regions per parameter%%HIGHLIGHT%% ==A shallow network with one input, one output, and D > 2 hidden units can create upto D + 1 linear regions and is defined by 3D + 1 parameters. A deep network with oneProblems 4.8–4.11 input, one output, and K layers of D > 2 hidden units can create a function with up to(D + 1)K linear regions using 3D + 1 + (K −1)D(D + 1) parameters== %%POSTFIX%%.Figure 4.7a shows how the maxim*
>%%LINK%%[[#^zx4epeb27jk|show annotation]]
>%%COMMENT%%
>How many linear regions can a deep neural network create?
>%%TAGS%%
>#question
^zx4epeb27jk


>%%
>```annotation-json
>{"created":"2024-09-28T19:28:41.253Z","updated":"2024-09-28T19:28:41.253Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":123995,"end":124115},{"type":"TextQuoteSelector","exact":"Deep networks can create extremely large numbers of linear regions, butthese contain complex dependencies and symmetries","prefix":"ted by the numberof parameters. ","suffix":". We saw some of these when weco"}]}]}
>```
>%%
>*%%PREFIX%%ted by the numberof parameters.%%HIGHLIGHT%% ==Deep networks can create extremely large numbers of linear regions, butthese contain complex dependencies and symmetries== %%POSTFIX%%. We saw some of these when weco*
>%%LINK%%[[#^rwafqh4qimc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rwafqh4qimc


>%%
>```annotation-json
>{"created":"2024-09-28T19:28:52.651Z","updated":"2024-09-28T19:28:52.651Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":124212,"end":124502},{"type":"TextQuoteSelector","exact":" So, it’s not clear thatthe greater number of regions is an advantage unless (i) there are similar symmetries inthe real-world functions that we wish to approximate or (ii) we have reason to believethat the mapping from input to output really does involve a composition of simplerfunctions.","prefix":"g” the input space (figure 4.3).","suffix":"4.5.3 Depth eﬀiciencyBoth deep a"}]}]}
>```
>%%
>*%%PREFIX%%g” the input space (figure 4.3).%%HIGHLIGHT%% ==So, it’s not clear thatthe greater number of regions is an advantage unless (i) there are similar symmetries inthe real-world functions that we wish to approximate or (ii) we have reason to believethat the mapping from input to output really does involve a composition of simplerfunctions.== %%POSTFIX%%4.5.3 Depth eﬀiciencyBoth deep a*
>%%LINK%%[[#^ihugfiqic8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ihugfiqic8


>%%
>```annotation-json
>{"created":"2024-09-28T19:29:27.786Z","text":"What is depth efficiency?","updated":"2024-09-28T19:29:27.786Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":124664,"end":124899},{"type":"TextQuoteSelector","exact":"Functions have beenidentified that require a shallow network with exponentially more hidden units to achievean equivalent approximation to that of a deep network. This phenomenon is referred toas the depth eﬀiciency of neural networks.","prefix":" eﬀiciently with deep networks. ","suffix":" This property is also attractiv"}]}]}
>```
>%%
>*%%PREFIX%%eﬀiciently with deep networks.%%HIGHLIGHT%% ==Functions have beenidentified that require a shallow network with exponentially more hidden units to achievean equivalent approximation to that of a deep network. This phenomenon is referred toas the depth eﬀiciency of neural networks.== %%POSTFIX%%This property is also attractiv*
>%%LINK%%[[#^vmmtdorrh4n|show annotation]]
>%%COMMENT%%
>What is depth efficiency?
>%%TAGS%%
>#question
^vmmtdorrh4n


>%%
>```annotation-json
>{"created":"2024-09-28T19:32:41.395Z","updated":"2024-09-28T19:32:41.395Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":128279,"end":128686},{"type":"TextQuoteSelector","exact":"We saw that (i) both networkscan approximate any function given enough capacity, (ii) deep networks produce manymore linear regions per parameter, (iii) some functions can be approximated much moreeﬀiciently by deep networks, (iv) large, structured inputs like images are best processedin multiple stages, and (v) in practice, the best results for most tasks are achieved usingdeep networks with many layers","prefix":"ared shallow and deep networks. ","suffix":".Now that we understand deep and"}]}]}
>```
>%%
>*%%PREFIX%%ared shallow and deep networks.%%HIGHLIGHT%% ==We saw that (i) both networkscan approximate any function given enough capacity, (ii) deep networks produce manymore linear regions per parameter, (iii) some functions can be approximated much moreeﬀiciently by deep networks, (iv) large, structured inputs like images are best processedin multiple stages, and (v) in practice, the best results for most tasks are achieved usingdeep networks with many layers== %%POSTFIX%%.Now that we understand deep and*
>%%LINK%%[[#^x3wwfcj2zxi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^x3wwfcj2zxi


>%%
>```annotation-json
>{"created":"2024-09-28T19:33:53.886Z","updated":"2024-09-28T19:33:53.886Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":130137,"end":130295},{"type":"TextQuoteSelector","exact":"hesame authors show that a deep ReLU network with Di-dimensional input and K layers, eachcontaining D ≥Di hidden units, has O((D/Di)(K−1)Di DDi)linear regions","prefix":"is 2D (Montúfar et al., 2014). T","suffix":". Montúfar (2017),Arora et al. ("}]}]}
>```
>%%
>*%%PREFIX%%is 2D (Montúfar et al., 2014). T%%HIGHLIGHT%% ==hesame authors show that a deep ReLU network with Di-dimensional input and K layers, eachcontaining D ≥Di hidden units, has O((D/Di)(K−1)Di DDi)linear regions== %%POSTFIX%%. Montúfar (2017),Arora et al. (*
>%%LINK%%[[#^dhx5bl63xfd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dhx5bl63xfd


>%%
>```annotation-json
>{"created":"2024-09-28T19:34:11.128Z","updated":"2024-09-28T19:34:11.128Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":130629,"end":130809},{"type":"TextQuoteSelector","exact":"If the number of hidden units D in each of the K layers is the same, and D is an integermultiple of the input dimensionality Di, then the maximum number of linear regions Nr can be","prefix":"actical for very small networks.","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%actical for very small networks.%%HIGHLIGHT%% ==If the number of hidden units D in each of the K layers is the same, and D is an integermultiple of the input dimensionality Di, then the maximum number of linear regions Nr can be== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^mvqm8j3rfms|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mvqm8j3rfms


>%%
>```annotation-json
>{"created":"2024-09-28T19:34:19.744Z","updated":"2024-09-28T19:34:19.744Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":130895,"end":130950},{"type":"TextQuoteSelector","exact":"computed exactly and is:Nr =( DDi+ 1)Di(K−1)·Di∑j=0(Dj)","prefix":" license. (C) MIT Press.Notes 53","suffix":". (4.17)The first term in this e"}]}]}
>```
>%%
>*%%PREFIX%%license. (C) MIT Press.Notes 53%%HIGHLIGHT%% ==computed exactly and is:Nr =( DDi+ 1)Di(K−1)·Di∑j=0(Dj)== %%POSTFIX%%. (4.17)The first term in this e*
>%%LINK%%[[#^dk5ba30hw8o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dk5ba30hw8o


>%%
>```annotation-json
>{"created":"2024-09-28T19:35:24.429Z","text":"What is the *depth version* of the universal approximation theorem?","updated":"2024-09-28T19:35:24.429Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":131844,"end":132127},{"type":"TextQuoteSelector","exact":"exists a networkwith ReLU activation functions and at least Di + 4 hidden units in each layer can approximateany specified Di-dimensional Lebesgue integrable function to arbitrary accuracy given enoughlayers. This is known as the depth version of the universal approximation theorem.","prefix":"et al. (2017) proved that there ","suffix":"Depth eﬀiciency: Several results"}]}]}
>```
>%%
>*%%PREFIX%%et al. (2017) proved that there%%HIGHLIGHT%% ==exists a networkwith ReLU activation functions and at least Di + 4 hidden units in each layer can approximateany specified Di-dimensional Lebesgue integrable function to arbitrary accuracy given enoughlayers. This is known as the depth version of the universal approximation theorem.== %%POSTFIX%%Depth eﬀiciency: Several results*
>%%LINK%%[[#^ccwkoas6724|show annotation]]
>%%COMMENT%%
>What is the *depth version* of the universal approximation theorem?
>%%TAGS%%
>#question
^ccwkoas6724


>%%
>```annotation-json
>{"created":"2024-09-28T19:37:33.408Z","text":"What is *width efficiency*? ","updated":"2024-09-28T19:37:33.408Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":133540,"end":133862},{"type":"TextQuoteSelector","exact":"hey show that there exist classes of wide, shallow networksthat can only be expressed by narrow networks with polynomial depth. This is known as thewidth eﬀiciency of neural networks. This polynomial lower bound on width is less restrictivethan the exponential lower bound on depth, suggesting that depth is more important","prefix":"h is not substantially larger. T","suffix":". Vardiet al. (2022) subsequentl"}]}]}
>```
>%%
>*%%PREFIX%%h is not substantially larger. T%%HIGHLIGHT%% ==hey show that there exist classes of wide, shallow networksthat can only be expressed by narrow networks with polynomial depth. This is known as thewidth eﬀiciency of neural networks. This polynomial lower bound on width is less restrictivethan the exponential lower bound on depth, suggesting that depth is more important== %%POSTFIX%%. Vardiet al. (2022) subsequentl*
>%%LINK%%[[#^5766pty72wu|show annotation]]
>%%COMMENT%%
>What is *width efficiency*? 
>%%TAGS%%
>#question
^5766pty72wu


>%%
>```annotation-json
>{"created":"2024-10-07T17:06:42.326Z","updated":"2024-10-07T17:06:42.326Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":50792,"end":50806},{"type":"TextQuoteSelector","exact":"Weaponizing AI","prefix":" (2022) for further information.","suffix":": All significant technologies h"}]}]}
>```
>%%
>*%%PREFIX%%(2022) for further information.%%HIGHLIGHT%% ==Weaponizing AI== %%POSTFIX%%: All significant technologies h*
>%%LINK%%[[#^nlyr0j26zrd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nlyr0j26zrd


>%%
>```annotation-json
>{"created":"2024-10-07T19:40:19.117Z","updated":"2024-10-07T19:40:19.117Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":138946,"end":139202},{"type":"TextQuoteSelector","exact":"the least squares loss function is suitable for univariate regressionproblems for which the target is a real number y ∈R. It computes the sum of the squaresAppendix ANumber sets of the deviations between the model predictions f[xi,φ] and the true values yi","prefix":"of a lossfunction in chapter 2; ","suffix":".This chapter provides a framewo"}]}]}
>```
>%%
>*%%PREFIX%%of a lossfunction in chapter 2;%%HIGHLIGHT%% ==the least squares loss function is suitable for univariate regressionproblems for which the target is a real number y ∈R. It computes the sum of the squaresAppendix ANumber sets of the deviations between the model predictions f[xi,φ] and the true values yi== %%POSTFIX%%.This chapter provides a framewo*
>%%LINK%%[[#^s8m01958f3i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^s8m01958f3i


>%%
>```annotation-json
>{"created":"2024-10-07T19:42:01.753Z","updated":"2024-10-07T19:42:01.753Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":140060,"end":140153},{"type":"TextQuoteSelector","exact":"computing a conditional probability distribution Pr(y|x) overpossible outputs y given input x","prefix":"ective andconsider the model as ","suffix":". The loss encourages each train"}]}]}
>```
>%%
>*%%PREFIX%%ective andconsider the model as%%HIGHLIGHT%% ==computing a conditional probability distribution Pr(y|x) overpossible outputs y given input x== %%POSTFIX%%. The loss encourages each train*
>%%LINK%%[[#^me3witl2ke|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^me3witl2ke


>%%
>```annotation-json
>{"created":"2024-10-07T19:42:14.304Z","updated":"2024-10-07T19:42:14.304Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":140155,"end":140297},{"type":"TextQuoteSelector","exact":"The loss encourages each training output yi to havea high probability under the distribution Pr(yi|xi) computed from the correspondinginput xi","prefix":"ssible outputs y given input x. ","suffix":" (figure 5.1).This work is subje"}]}]}
>```
>%%
>*%%PREFIX%%ssible outputs y given input x.%%HIGHLIGHT%% ==The loss encourages each training output yi to havea high probability under the distribution Pr(yi|xi) computed from the correspondinginput xi== %%POSTFIX%%(figure 5.1).This work is subje*
>%%LINK%%[[#^yuz5dxkxpr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yuz5dxkxpr


>%%
>```annotation-json
>{"created":"2024-10-07T19:46:16.575Z","updated":"2024-10-07T19:46:16.575Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":141526,"end":141690},{"type":"TextQuoteSelector","exact":"we choose a parametric distribu-tion Pr(y|θ) defined on the output domain y. Then we use the network to compute oneor more of the parameters θ of this distribution.","prefix":" The solution is simple. First, ","suffix":"For example, suppose the predict"}]}]}
>```
>%%
>*%%PREFIX%%The solution is simple. First,%%HIGHLIGHT%% ==we choose a parametric distribu-tion Pr(y|θ) defined on the output domain y. Then we use the network to compute oneor more of the parameters θ of this distribution.== %%POSTFIX%%For example, suppose the predict*
>%%LINK%%[[#^izh9jzooe9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^izh9jzooe9


>%%
>```annotation-json
>{"created":"2024-10-07T19:46:35.084Z","updated":"2024-10-07T19:46:35.084Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":141851,"end":141923},{"type":"TextQuoteSelector","exact":"Thisdistribution is defined by the mean μ and variance σ2, so θ = {μ,σ2}","prefix":"ibution, which is defined on R. ","suffix":". The machinelearning model migh"}]}]}
>```
>%%
>*%%PREFIX%%ibution, which is defined on R.%%HIGHLIGHT%% ==Thisdistribution is defined by the mean μ and variance σ2, so θ = {μ,σ2}== %%POSTFIX%%. The machinelearning model migh*
>%%LINK%%[[#^z4w3gfhuzd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^z4w3gfhuzd


>%%
>```annotation-json
>{"created":"2024-10-07T19:47:37.406Z","updated":"2024-10-07T19:47:37.406Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":142070,"end":142392},{"type":"TextQuoteSelector","exact":"The model now computes different distribution parameters θi = f[xi,φ] for each traininginput xi. Each observed training output yi should have high probability under itscorresponding distribution Pr(yi|θi). Hence, we choose the model parameters φ so thatthey maximize the combined probability across all I training examples","prefix":"1.2 Maximum likelihood criterion","suffix":":ˆφ = argmaxφ[ I∏i=1Pr(yi|xi)]= "}]}]}
>```
>%%
>*%%PREFIX%%1.2 Maximum likelihood criterion%%HIGHLIGHT%% ==The model now computes different distribution parameters θi = f[xi,φ] for each traininginput xi. Each observed training output yi should have high probability under itscorresponding distribution Pr(yi|θi). Hence, we choose the model parameters φ so thatthey maximize the combined probability across all I training examples== %%POSTFIX%%:ˆφ = argmaxφ[ I∏i=1Pr(yi|xi)]=*
>%%LINK%%[[#^f2qzunxpcls|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f2qzunxpcls


>%%
>```annotation-json
>{"created":"2024-10-07T19:47:40.726Z","text":"What is maximum likelihood criterion?","updated":"2024-10-07T19:47:40.726Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":142042,"end":142070},{"type":"TextQuoteSelector","exact":"Maximum likelihood criterion","prefix":"ted as anunknown constant.5.1.2 ","suffix":"The model now computes different"}]}]}
>```
>%%
>*%%PREFIX%%ted as anunknown constant.5.1.2%%HIGHLIGHT%% ==Maximum likelihood criterion== %%POSTFIX%%The model now computes different*
>%%LINK%%[[#^4796bfkgn3l|show annotation]]
>%%COMMENT%%
>What is maximum likelihood criterion?
>%%TAGS%%
>#question
^4796bfkgn3l


>%%
>```annotation-json
>{"created":"2024-10-07T19:48:05.318Z","updated":"2024-10-07T19:48:05.318Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":142394,"end":142479},{"type":"TextQuoteSelector","exact":"φ = argmaxφ[ I∏i=1Pr(yi|xi)]= argmaxφ[ I∏i=1Pr(yi|θi)]= argmaxφ[ I∏i=1Pr(yi|f[xi,φ])]","prefix":"across all I training examples:ˆ","suffix":". (5.1)The combined probability "}]}]}
>```
>%%
>*%%PREFIX%%across all I training examples:ˆ%%HIGHLIGHT%% ==φ = argmaxφ[ I∏i=1Pr(yi|xi)]= argmaxφ[ I∏i=1Pr(yi|θi)]= argmaxφ[ I∏i=1Pr(yi|f[xi,φ])]== %%POSTFIX%%. (5.1)The combined probability*
>%%LINK%%[[#^xordp930cz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xordp930cz


>%%
>```annotation-json
>{"created":"2024-10-07T19:48:57.441Z","updated":"2024-10-07T19:48:57.441Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":142486,"end":142620},{"type":"TextQuoteSelector","exact":"The combined probability term is the likelihood of the parameters, and hence equation 5.1is known as the maximum likelihood criterion.","prefix":"axφ[ I∏i=1Pr(yi|f[xi,φ])]. (5.1)","suffix":"1Here we are implicitly making t"}]}]}
>```
>%%
>*%%PREFIX%%axφ[ I∏i=1Pr(yi|f[xi,φ])]. (5.1)%%HIGHLIGHT%% ==The combined probability term is the likelihood of the parameters, and hence equation 5.1is known as the maximum likelihood criterion.== %%POSTFIX%%1Here we are implicitly making t*
>%%LINK%%[[#^hw9mxwttder|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hw9mxwttder


>%%
>```annotation-json
>{"created":"2024-10-07T19:49:51.341Z","updated":"2024-10-07T19:49:51.341Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":142667,"end":143063},{"type":"TextQuoteSelector","exact":" First, we assume that the dataare identically distributed (the form of the probability distribution over the outputs yiis the same for each data point). Second, we assume that the conditional distribu-tions Pr(yi|xi) of the output given the input are independent, so the total likelihood ofAppendix C.1.5Independencethe training data decomposes as:Pr(y1,y2,...,yI |x1,x2,...,xI ) =I∏i=1Pr(yi|xi)","prefix":"plicitly making two assumptions.","suffix":". (5.2)In other words, we assume"}]}]}
>```
>%%
>*%%PREFIX%%plicitly making two assumptions.%%HIGHLIGHT%% ==First, we assume that the dataare identically distributed (the form of the probability distribution over the outputs yiis the same for each data point). Second, we assume that the conditional distribu-tions Pr(yi|xi) of the output given the input are independent, so the total likelihood ofAppendix C.1.5Independencethe training data decomposes as:Pr(y1,y2,...,yI |x1,x2,...,xI ) =I∏i=1Pr(yi|xi)== %%POSTFIX%%. (5.2)In other words, we assume*
>%%LINK%%[[#^r5whbyqlfmg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r5whbyqlfmg


>%%
>```annotation-json
>{"created":"2024-10-07T19:50:27.775Z","updated":"2024-10-07T19:50:27.775Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":143070,"end":143157},{"type":"TextQuoteSelector","exact":"In other words, we assume the data are independent and identically distributed (i.i.d.)","prefix":",...,xI ) =I∏i=1Pr(yi|xi). (5.2)","suffix":".1A conditional probability Pr(z"}]}]}
>```
>%%
>*%%PREFIX%%,...,xI ) =I∏i=1Pr(yi|xi). (5.2)%%HIGHLIGHT%% ==In other words, we assume the data are independent and identically distributed (i.i.d.)== %%POSTFIX%%.1A conditional probability Pr(z*
>%%LINK%%[[#^cwyhyzh3h84|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cwyhyzh3h84


>%%
>```annotation-json
>{"created":"2024-10-07T19:57:52.447Z","text":"What is maximising log-likelihood?","updated":"2024-10-07T19:57:52.447Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":143957,"end":143982},{"type":"TextQuoteSelector","exact":"Maximizing log-likelihood","prefix":" maximum remains the same.5.1.3 ","suffix":"The maximum likelihood criterion"}]}]}
>```
>%%
>*%%PREFIX%%maximum remains the same.5.1.3%%HIGHLIGHT%% ==Maximizing log-likelihood== %%POSTFIX%%The maximum likelihood criterion*
>%%LINK%%[[#^vv16rbn9xd|show annotation]]
>%%COMMENT%%
>What is maximising log-likelihood?
>%%TAGS%%
>#question
^vv16rbn9xd


>%%
>```annotation-json
>{"created":"2024-10-07T19:58:30.370Z","updated":"2024-10-07T19:58:30.370Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":143982,"end":144294},{"type":"TextQuoteSelector","exact":"The maximum likelihood criterion (equation 5.1) is not very practical. Each termPr(yi|f[xi,φ]) can be small, so the product of many of these terms can be tiny. Itmay be diﬀicult to represent this quantity with finite precision arithmetic. Fortunately,we can equivalently maximize the logarithm of the likelihood:","prefix":".5.1.3 Maximizing log-likelihood","suffix":"ˆφ = argmaxφ[ I∏i=1Pr(yi|f[xi,φ]"}]}]}
>```
>%%
>*%%PREFIX%%.5.1.3 Maximizing log-likelihood%%HIGHLIGHT%% ==The maximum likelihood criterion (equation 5.1) is not very practical. Each termPr(yi|f[xi,φ]) can be small, so the product of many of these terms can be tiny. Itmay be diﬀicult to represent this quantity with finite precision arithmetic. Fortunately,we can equivalently maximize the logarithm of the likelihood:== %%POSTFIX%%ˆφ = argmaxφ[ I∏i=1Pr(yi|f[xi,φ]*
>%%LINK%%[[#^f2eaxub7ltd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f2eaxub7ltd


>%%
>```annotation-json
>{"created":"2024-10-07T19:58:36.096Z","updated":"2024-10-07T19:58:36.096Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":144295,"end":144399},{"type":"TextQuoteSelector","exact":"φ = argmaxφ[ I∏i=1Pr(yi|f[xi,φ])]= argmaxφ[log[ I∏i=1Pr(yi|f[xi,φ])]]= argmaxφ[ I∑i=1log[Pr(yi|f[xi,φ])]","prefix":"he logarithm of the likelihood:ˆ","suffix":"]. (5.3)This log-likelihood crit"}]}]}
>```
>%%
>*%%PREFIX%%he logarithm of the likelihood:ˆ%%HIGHLIGHT%% ==φ = argmaxφ[ I∏i=1Pr(yi|f[xi,φ])]= argmaxφ[log[ I∏i=1Pr(yi|f[xi,φ])]]= argmaxφ[ I∑i=1log[Pr(yi|f[xi,φ])]== %%POSTFIX%%]. (5.3)This log-likelihood crit*
>%%LINK%%[[#^w4w4okiiov|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w4w4okiiov


>%%
>```annotation-json
>{"created":"2024-10-07T19:59:55.338Z","updated":"2024-10-07T19:59:55.338Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":144407,"end":144561},{"type":"TextQuoteSelector","exact":"This log-likelihood criterion is equivalent because the logarithm is a monotonically in-creasing function: if z > z′, then log[z] > log[z′] and vice versa","prefix":"I∑i=1log[Pr(yi|f[xi,φ])]]. (5.3)","suffix":" (figure 5.2). It followsthat wh"}]}]}
>```
>%%
>*%%PREFIX%%I∑i=1log[Pr(yi|f[xi,φ])]]. (5.3)%%HIGHLIGHT%% ==This log-likelihood criterion is equivalent because the logarithm is a monotonically in-creasing function: if z > z′, then log[z] > log[z′] and vice versa== %%POSTFIX%%(figure 5.2). It followsthat wh*
>%%LINK%%[[#^k0ygnmunoa|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^k0ygnmunoa


>%%
>```annotation-json
>{"created":"2024-10-07T20:00:30.104Z","updated":"2024-10-07T20:00:30.104Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":144577,"end":145038},{"type":"TextQuoteSelector","exact":"t followsthat when we change the model parameters φ to improve the log-likelihood criterion, wealso improve the original maximum likelihood criterion. It also follows that the overallmaxima of the two criteria must be in the same place, so the best model parameters ˆφare the same in both cases. However, the log-likelihood criterion has the practical ad-vantage of using a sum of terms, not a product, so representing it with finite precisionisn’t problematic.","prefix":"] and vice versa (figure 5.2). I","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%] and vice versa (figure 5.2). I%%HIGHLIGHT%% ==t followsthat when we change the model parameters φ to improve the log-likelihood criterion, wealso improve the original maximum likelihood criterion. It also follows that the overallmaxima of the two criteria must be in the same place, so the best model parameters ˆφare the same in both cases. However, the log-likelihood criterion has the practical ad-vantage of using a sum of terms, not a product, so representing it with finite precisionisn’t problematic.== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^g4wbr80fb4h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^g4wbr80fb4h


>%%
>```annotation-json
>{"created":"2024-10-07T20:02:18.678Z","text":"What is minimising negative log-likelihood?","updated":"2024-10-07T20:02:18.678Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":145114,"end":145148},{"type":"TextQuoteSelector","exact":"Minimizing negative log-likelihood","prefix":"il.com.60 5 Loss functions5.1.4 ","suffix":"Finally, we note that, by conven"}]}]}
>```
>%%
>*%%PREFIX%%il.com.60 5 Loss functions5.1.4%%HIGHLIGHT%% ==Minimizing negative log-likelihood== %%POSTFIX%%Finally, we note that, by conven*
>%%LINK%%[[#^mim0swnes7s|show annotation]]
>%%COMMENT%%
>What is minimising negative log-likelihood?
>%%TAGS%%
>#question
^mim0swnes7s


>%%
>```annotation-json
>{"created":"2024-10-07T20:25:17.166Z","updated":"2024-10-07T20:25:17.166Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":145148,"end":145512},{"type":"TextQuoteSelector","exact":"Finally, we note that, by convention, model fitting problems are framed in terms ofminimizing a loss. To convert the maximum log-likelihood criterion to a minimizationproblem, we multiply by minus one, which gives us the negative log-likelihood criterion:ˆφ = argminφ[−I∑i=1log[Pr(yi|f[xi,φ])]]= argminφ[L[φ]], (5.4)which is what forms the final loss function L[φ]","prefix":"nimizing negative log-likelihood","suffix":".5.1.5 InferenceThe network no l"}]}]}
>```
>%%
>*%%PREFIX%%nimizing negative log-likelihood%%HIGHLIGHT%% ==Finally, we note that, by convention, model fitting problems are framed in terms ofminimizing a loss. To convert the maximum log-likelihood criterion to a minimizationproblem, we multiply by minus one, which gives us the negative log-likelihood criterion:ˆφ = argminφ[−I∑i=1log[Pr(yi|f[xi,φ])]]= argminφ[L[φ]], (5.4)which is what forms the final loss function L[φ]== %%POSTFIX%%.5.1.5 InferenceThe network no l*
>%%LINK%%[[#^n47lmmxx69|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^n47lmmxx69


>%%
>```annotation-json
>{"created":"2024-10-07T20:32:19.831Z","text":"How do we do inference in this case?","updated":"2024-10-07T20:32:19.831Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":145519,"end":145528},{"type":"TextQuoteSelector","exact":"Inference","prefix":" final loss function L[φ].5.1.5 ","suffix":"The network no longer directly p"}]}]}
>```
>%%
>*%%PREFIX%%final loss function L[φ].5.1.5%%HIGHLIGHT%% ==Inference== %%POSTFIX%%The network no longer directly p*
>%%LINK%%[[#^mo5rfic2oqn|show annotation]]
>%%COMMENT%%
>How do we do inference in this case?
>%%TAGS%%
>#question
^mo5rfic2oqn


>%%
>```annotation-json
>{"created":"2024-10-07T20:34:34.464Z","updated":"2024-10-07T20:34:34.464Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":145528,"end":146010},{"type":"TextQuoteSelector","exact":"The network no longer directly predicts the outputs y but instead determines a proba-bility distribution over y. When we perform inference, we often want a point estimaterather than a distribution, so we return the maximum of the distribution:ˆy = argmaxy[Pr(y|f[x, ˆφ])]. (5.5)It is usually possible to find an expression for this in terms of the distribution parame-ters θ predicted by the model. For example, in the univariate normal distribution, themaximum occurs at the mean μ","prefix":"ss function L[φ].5.1.5 Inference","suffix":".5.2 Recipe for constructing los"}]}]}
>```
>%%
>*%%PREFIX%%ss function L[φ].5.1.5 Inference%%HIGHLIGHT%% ==The network no longer directly predicts the outputs y but instead determines a proba-bility distribution over y. When we perform inference, we often want a point estimaterather than a distribution, so we return the maximum of the distribution:ˆy = argmaxy[Pr(y|f[x, ˆφ])]. (5.5)It is usually possible to find an expression for this in terms of the distribution parame-ters θ predicted by the model. For example, in the univariate normal distribution, themaximum occurs at the mean μ== %%POSTFIX%%.5.2 Recipe for constructing los*
>%%LINK%%[[#^rwzb7qpm22|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rwzb7qpm22


>%%
>```annotation-json
>{"created":"2024-10-07T20:35:03.919Z","text":"How do we construct loss functions?","updated":"2024-10-07T20:35:03.919Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":146015,"end":146053},{"type":"TextQuoteSelector","exact":"Recipe for constructing loss functions","prefix":"aximum occurs at the mean μ.5.2 ","suffix":"The recipe for constructing loss"}]}]}
>```
>%%
>*%%PREFIX%%aximum occurs at the mean μ.5.2%%HIGHLIGHT%% ==Recipe for constructing loss functions== %%POSTFIX%%The recipe for constructing loss*
>%%LINK%%[[#^o93594r2j68|show annotation]]
>%%COMMENT%%
>How do we construct loss functions?
>%%TAGS%%
>#question
^o93594r2j68


>%%
>```annotation-json
>{"created":"2024-10-07T21:07:21.566Z","updated":"2024-10-07T21:07:21.566Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":146053,"end":146889},{"type":"TextQuoteSelector","exact":"The recipe for constructing loss functions for training data {xi,yi} using the maximumlikelihood approach is hence:1. Choose a suitable probability distribution Pr(y|θ) defined over the domain of thepredictions y with distribution parameters θ.2. Set the machine learning model f[x,φ] to predict one or more of these parameters,so θ = f[x,φ] and Pr(y|θ) = Pr(y|f[x,φ]).3. To train the model, find the network parameters ˆφ that minimize the negativelog-likelihood loss function over the training dataset pairs {xi,yi}:ˆφ = argminφ[L[φ]]= argminφ[−I∑i=1log[Pr(yi|f[xi,φ])]]. (5.6)4. To perform inference for a new test example x, return either the full distribu-tion Pr(y|f[x, ˆφ]) or the maximum of this distribution.We devote most of the rest of this chapter to constructing loss functions for commonprediction types using this recipe.","prefix":" for constructing loss functions","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%for constructing loss functions%%HIGHLIGHT%% ==The recipe for constructing loss functions for training data {xi,yi} using the maximumlikelihood approach is hence:1. Choose a suitable probability distribution Pr(y|θ) defined over the domain of thepredictions y with distribution parameters θ.2. Set the machine learning model f[x,φ] to predict one or more of these parameters,so θ = f[x,φ] and Pr(y|θ) = Pr(y|f[x,φ]).3. To train the model, find the network parameters ˆφ that minimize the negativelog-likelihood loss function over the training dataset pairs {xi,yi}:ˆφ = argminφ[L[φ]]= argminφ[−I∑i=1log[Pr(yi|f[xi,φ])]]. (5.6)4. To perform inference for a new test example x, return either the full distribu-tion Pr(y|f[x, ˆφ]) or the maximum of this distribution.We devote most of the rest of this chapter to constructing loss functions for commonprediction types using this recipe.== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^rw9uzd925rq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rw9uzd925rq


>%%
>```annotation-json
>{"created":"2024-10-07T21:09:01.718Z","updated":"2024-10-07T21:09:01.718Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":147017,"end":147308},{"type":"TextQuoteSelector","exact":"The univariate normal distri-bution (also known as the Gaussian dis-tribution) is defined on the real line z ∈R and has parameters μ and σ2. Themean μ determines the position of thepeak. The positive root of the vari-ance σ2 (the standard deviation) de-termines the width of the distribution","prefix":"variate regression 61Figure 5.3 ","suffix":".Since the total probability den"}]}]}
>```
>%%
>*%%PREFIX%%variate regression 61Figure 5.3%%HIGHLIGHT%% ==The univariate normal distri-bution (also known as the Gaussian dis-tribution) is defined on the real line z ∈R and has parameters μ and σ2. Themean μ determines the position of thepeak. The positive root of the vari-ance σ2 (the standard deviation) de-termines the width of the distribution== %%POSTFIX%%.Since the total probability den*
>%%LINK%%[[#^xlvgj2wbnu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xlvgj2wbnu


>%%
>```annotation-json
>{"created":"2024-10-07T21:22:10.058Z","text":"How to apply the recipe to univariate regression?","updated":"2024-10-07T21:22:10.058Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":147447,"end":147479},{"type":"TextQuoteSelector","exact":"Example 1: univariate regression","prefix":"istributionbecomes narrower.5.3 ","suffix":"We start by considering univaria"}]}]}
>```
>%%
>*%%PREFIX%%istributionbecomes narrower.5.3%%HIGHLIGHT%% ==Example 1: univariate regression== %%POSTFIX%%We start by considering univaria*
>%%LINK%%[[#^7dzis5fk6cr|show annotation]]
>%%COMMENT%%
>How to apply the recipe to univariate regression?
>%%TAGS%%
>#question
^7dzis5fk6cr


>%%
>```annotation-json
>{"created":"2024-10-07T21:22:57.056Z","updated":"2024-10-07T21:22:57.056Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":147479,"end":148518},{"type":"TextQuoteSelector","exact":"We start by considering univariate regression models. Here the goal is to predict a singlescalar output y ∈ R from input x using a model f[x,φ] with parameters φ. Followingthe recipe, we choose a probability distribution over the output domain y. We select theunivariate normal (figure 5.3), which is defined over y ∈ R. This distribution has twoparameters (mean μ and variance σ2) and has a probability density function:Pr(y|μ,σ2) = 1√2πσ2 exp[−(y −μ)22σ2]. (5.7)Second, we set the machine learning model f[x,φ] to compute one or more of the param-eters of this distribution. Here, we just compute the mean so μ = f[x,φ]:Pr(y|f[x,φ],σ2) = 1√2πσ2 exp[−(y −f[x,φ])22σ2]. (5.8)We aim to find the parameters φ that make the training data {xi,yi} most probableunder this distribution (figure 5.4). To accomplish this, we choose a loss function L[φ]based on the negative log-likelihood:L[φ] = −I∑i=1log [Pr(yi|f[xi,φ],σ2)]= −I∑i=1log[ 1√2πσ2 exp[−(yi −f[xi,φ])22σ2]]. (5.9)When we train the model, we seek parameters ˆφ that minimize this loss.","prefix":"Example 1: univariate regression","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%Example 1: univariate regression%%HIGHLIGHT%% ==We start by considering univariate regression models. Here the goal is to predict a singlescalar output y ∈ R from input x using a model f[x,φ] with parameters φ. Followingthe recipe, we choose a probability distribution over the output domain y. We select theunivariate normal (figure 5.3), which is defined over y ∈ R. This distribution has twoparameters (mean μ and variance σ2) and has a probability density function:Pr(y|μ,σ2) = 1√2πσ2 exp[−(y −μ)22σ2]. (5.7)Second, we set the machine learning model f[x,φ] to compute one or more of the param-eters of this distribution. Here, we just compute the mean so μ = f[x,φ]:Pr(y|f[x,φ],σ2) = 1√2πσ2 exp[−(y −f[x,φ])22σ2]. (5.8)We aim to find the parameters φ that make the training data {xi,yi} most probableunder this distribution (figure 5.4). To accomplish this, we choose a loss function L[φ]based on the negative log-likelihood:L[φ] = −I∑i=1log [Pr(yi|f[xi,φ],σ2)]= −I∑i=1log[ 1√2πσ2 exp[−(yi −f[xi,φ])22σ2]]. (5.9)When we train the model, we seek parameters ˆφ that minimize this loss.== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^ky6ud0fegs|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ky6ud0fegs


>%%
>```annotation-json
>{"created":"2024-10-07T21:24:51.663Z","updated":"2024-10-07T21:24:51.663Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":148594,"end":148621},{"type":"TextQuoteSelector","exact":"Least squares loss function","prefix":"il.com.62 5 Loss functions5.3.1 ","suffix":"Now let’s perform some algebraic"}]}]}
>```
>%%
>*%%PREFIX%%il.com.62 5 Loss functions5.3.1%%HIGHLIGHT%% ==Least squares loss function== %%POSTFIX%%Now let’s perform some algebraic*
>%%LINK%%[[#^7j9c3wjjv25|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7j9c3wjjv25


>%%
>```annotation-json
>{"created":"2024-10-07T21:24:57.818Z","updated":"2024-10-07T21:24:57.818Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":148621,"end":149541},{"type":"TextQuoteSelector","exact":"Now let’s perform some algebraic manipulations on the loss function. We seek:ˆφ = argminφ[−I∑i=1log[ 1√2πσ2 exp[−(yi −f[xi,φ])22σ2]]]= argminφ[−I∑i=1(log[ 1√2πσ2]− (yi −f[xi,φ])22σ2)]= argminφ[−I∑i=1−(yi −f[xi,φ])22σ2]= argminφ[ I∑i=1(yi −f[xi,φ])2], (5.10)where we have removed the first term between the second and third lines because it doesnot depend on φ. We have removed the denominator between the third and fourth lines,as this is just a constant scaling factor that does not affect the position of the minimum.The result of these manipulations is the least squares loss function that we originallyintroduced when we discussed linear regression in chapter 2:L[φ] =I∑i=1(yi −f[xi,φ])2. (5.11)We see that the least squares loss function follows naturally from the assumptions thatNotebook 5.1Least squareslossthe prediction errors are (i) independent and (ii) drawn from a normal distribution withmean μ = f[xi,φ] ","prefix":".3.1 Least squares loss function","suffix":"(figure 5.4).5.3.2 InferenceThe "}]}]}
>```
>%%
>*%%PREFIX%%.3.1 Least squares loss function%%HIGHLIGHT%% ==Now let’s perform some algebraic manipulations on the loss function. We seek:ˆφ = argminφ[−I∑i=1log[ 1√2πσ2 exp[−(yi −f[xi,φ])22σ2]]]= argminφ[−I∑i=1(log[ 1√2πσ2]− (yi −f[xi,φ])22σ2)]= argminφ[−I∑i=1−(yi −f[xi,φ])22σ2]= argminφ[ I∑i=1(yi −f[xi,φ])2], (5.10)where we have removed the first term between the second and third lines because it doesnot depend on φ. We have removed the denominator between the third and fourth lines,as this is just a constant scaling factor that does not affect the position of the minimum.The result of these manipulations is the least squares loss function that we originallyintroduced when we discussed linear regression in chapter 2:L[φ] =I∑i=1(yi −f[xi,φ])2. (5.11)We see that the least squares loss function follows naturally from the assumptions thatNotebook 5.1Least squareslossthe prediction errors are (i) independent and (ii) drawn from a normal distribution withmean μ = f[xi,φ]== %%POSTFIX%%(figure 5.4).5.3.2 InferenceThe*
>%%LINK%%[[#^wgew8lidoi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wgew8lidoi


>%%
>```annotation-json
>{"created":"2024-10-07T21:25:53.303Z","text":"How to do inference for a univariate regression?","updated":"2024-10-07T21:25:53.303Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":149560,"end":149569},{"type":"TextQuoteSelector","exact":"Inference","prefix":" μ = f[xi,φ] (figure 5.4).5.3.2 ","suffix":"The network no longer directly p"}]}]}
>```
>%%
>*%%PREFIX%%μ = f[xi,φ] (figure 5.4).5.3.2%%HIGHLIGHT%% ==Inference== %%POSTFIX%%The network no longer directly p*
>%%LINK%%[[#^610rfnoie96|show annotation]]
>%%COMMENT%%
>How to do inference for a univariate regression?
>%%TAGS%%
>#question
^610rfnoie96


>%%
>```annotation-json
>{"created":"2024-10-07T21:26:15.247Z","updated":"2024-10-07T21:26:15.247Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":149569,"end":150013},{"type":"TextQuoteSelector","exact":"The network no longer directly predicts y but instead predicts the mean μ = f[x,φ] ofthe normal distribution over y. When we perform inference, we usually want a single“best” point estimate ˆy, so we take the maximum of the predicted distribution:ˆy = argmaxy[Pr(y|f[x, ˆφ,σ2])]. (5.12)For the univariate normal, the maximum position is determined by the mean parameter μ(figure 5.3). This is precisely what the model computed, so ˆy = f[x, ˆφ]","prefix":",φ] (figure 5.4).5.3.2 Inference","suffix":".5.3.3 Estimating varianceTo for"}]}]}
>```
>%%
>*%%PREFIX%%,φ] (figure 5.4).5.3.2 Inference%%HIGHLIGHT%% ==The network no longer directly predicts y but instead predicts the mean μ = f[x,φ] ofthe normal distribution over y. When we perform inference, we usually want a single“best” point estimate ˆy, so we take the maximum of the predicted distribution:ˆy = argmaxy[Pr(y|f[x, ˆφ,σ2])]. (5.12)For the univariate normal, the maximum position is determined by the mean parameter μ(figure 5.3). This is precisely what the model computed, so ˆy = f[x, ˆφ]== %%POSTFIX%%.5.3.3 Estimating varianceTo for*
>%%LINK%%[[#^9z681lsb1u|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9z681lsb1u


>%%
>```annotation-json
>{"created":"2024-10-07T21:29:56.793Z","text":"How do we estimate variance? ","updated":"2024-10-07T21:29:56.793Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":150020,"end":150039},{"type":"TextQuoteSelector","exact":"Estimating variance","prefix":"omputed, so ˆy = f[x, ˆφ].5.3.3 ","suffix":"To formulate the least squares l"}]}]}
>```
>%%
>*%%PREFIX%%omputed, so ˆy = f[x, ˆφ].5.3.3%%HIGHLIGHT%% ==Estimating variance== %%POSTFIX%%To formulate the least squares l*
>%%LINK%%[[#^g640o4hl0zl|show annotation]]
>%%COMMENT%%
>How do we estimate variance? 
>%%TAGS%%
>#question
^g640o4hl0zl


>%%
>```annotation-json
>{"created":"2024-10-07T21:31:55.644Z","updated":"2024-10-07T21:31:55.644Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":150157,"end":150212},{"type":"TextQuoteSelector","exact":"The final expression in equation 5.11 (perhaps surpris-","prefix":"emean of a normal distribution. ","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%emean of a normal distribution.%%HIGHLIGHT%% ==The final expression in equation 5.11 (perhaps surpris-== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^duvphuq6clc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^duvphuq6clc


>%%
>```annotation-json
>{"created":"2024-10-07T21:32:02.342Z","updated":"2024-10-07T21:32:02.342Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":151350,"end":151391},{"type":"TextQuoteSelector","exact":"ingly) does not depend on the variance σ2","prefix":"il@gmail.com.64 5 Loss functions","suffix":". However, there is nothing to s"}]}]}
>```
>%%
>*%%PREFIX%%il@gmail.com.64 5 Loss functions%%HIGHLIGHT%% ==ingly) does not depend on the variance σ2== %%POSTFIX%%. However, there is nothing to s*
>%%LINK%%[[#^w6kq8zimlfo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w6kq8zimlfo


>%%
>```annotation-json
>{"created":"2024-10-07T21:32:28.457Z","updated":"2024-10-07T21:32:28.457Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":151394,"end":151874},{"type":"TextQuoteSelector","exact":"owever, there is nothing to stop us fromtreating σ2 as a parameter of the model and minimizing equation 5.9 with respect toboth the model parameters φ and the distribution variance σ2:ˆφ, ˆσ2 = argminφ,σ2[−I∑i=1log[ 1√2πσ2 exp[−(yi −f[xi,φ])22σ2]]]. (5.13)In inference, the model predicts the mean μ = f[x, ˆφ] from the input, and we learned thevariance ˆσ2 during the training process. The former is the best prediction. The lattertells us about the uncertainty of the prediction","prefix":"not depend on the variance σ2. H","suffix":".5.3.4 Heteroscedastic regressio"}]}]}
>```
>%%
>*%%PREFIX%%not depend on the variance σ2. H%%HIGHLIGHT%% ==owever, there is nothing to stop us fromtreating σ2 as a parameter of the model and minimizing equation 5.9 with respect toboth the model parameters φ and the distribution variance σ2:ˆφ, ˆσ2 = argminφ,σ2[−I∑i=1log[ 1√2πσ2 exp[−(yi −f[xi,φ])22σ2]]]. (5.13)In inference, the model predicts the mean μ = f[x, ˆφ] from the input, and we learned thevariance ˆσ2 during the training process. The former is the best prediction. The lattertells us about the uncertainty of the prediction== %%POSTFIX%%.5.3.4 Heteroscedastic regressio*
>%%LINK%%[[#^ihped8wiwwa|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ihped8wiwwa


>%%
>```annotation-json
>{"created":"2024-10-08T06:58:36.553Z","text":"What is heteroscedastic regression?","updated":"2024-10-08T06:58:36.553Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":151881,"end":151907},{"type":"TextQuoteSelector","exact":"Heteroscedastic regression","prefix":"rtainty of the prediction.5.3.4 ","suffix":"The model above assumes that the"}]}]}
>```
>%%
>*%%PREFIX%%rtainty of the prediction.5.3.4%%HIGHLIGHT%% ==Heteroscedastic regression== %%POSTFIX%%The model above assumes that the*
>%%LINK%%[[#^9o16yd4lojn|show annotation]]
>%%COMMENT%%
>What is heteroscedastic regression?
>%%TAGS%%
>#question
^9o16yd4lojn


>%%
>```annotation-json
>{"created":"2024-10-08T06:59:32.249Z","updated":"2024-10-08T06:59:32.249Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":151907,"end":152192},{"type":"TextQuoteSelector","exact":"The model above assumes that the variance of the data is constant everywhere. However,this might be unrealistic. When the uncertainty of the model varies as a function of theinput data, we refer to this as heteroscedastic (as opposed to homoscedastic, where theuncertainty is constant)","prefix":"5.3.4 Heteroscedastic regression","suffix":".A simple way to model this is t"}]}]}
>```
>%%
>*%%PREFIX%%5.3.4 Heteroscedastic regression%%HIGHLIGHT%% ==The model above assumes that the variance of the data is constant everywhere. However,this might be unrealistic. When the uncertainty of the model varies as a function of theinput data, we refer to this as heteroscedastic (as opposed to homoscedastic, where theuncertainty is constant)== %%POSTFIX%%.A simple way to model this is t*
>%%LINK%%[[#^cv8r1ri21va|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cv8r1ri21va


>%%
>```annotation-json
>{"created":"2024-10-08T07:01:48.358Z","updated":"2024-10-08T07:01:48.358Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":152193,"end":152506},{"type":"TextQuoteSelector","exact":"A simple way to model this is to train a neural network f[x,φ] that computes boththe mean and the variance. For example, consider a shallow network with two outputs.We denote the first output as f1[x,φ] and use this to predict the mean, and we denotethe second output as f2[x,φ] and use it to predict the variance","prefix":"ere theuncertainty is constant).","suffix":".There is one complication; the "}]}]}
>```
>%%
>*%%PREFIX%%ere theuncertainty is constant).%%HIGHLIGHT%% ==A simple way to model this is to train a neural network f[x,φ] that computes boththe mean and the variance. For example, consider a shallow network with two outputs.We denote the first output as f1[x,φ] and use this to predict the mean, and we denotethe second output as f2[x,φ] and use it to predict the variance== %%POSTFIX%%.There is one complication; the*
>%%LINK%%[[#^lp3lua50687|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lp3lua50687


>%%
>```annotation-json
>{"created":"2024-10-08T07:02:11.585Z","updated":"2024-10-08T07:02:11.585Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":152507,"end":153052},{"type":"TextQuoteSelector","exact":"There is one complication; the variance must be positive, but we can’t guaranteethat the network will always produce a positive output. To ensure that the computedvariance is positive, we pass the second network output through a function that mapsan arbitrary value to a positive one. A suitable choice is the squaring function, giving:μ = f1[x,φ]σ2 = f2[x,φ]2, (5.14)which results in the loss function:ˆφ = argminφ[−I∑i=1(log[1√2πf2[xi,φ]2]− (yi −f1[xi,φ])22f2[xi,φ]2)]. (5.15)Homoscedastic and heteroscedastic models are compared in figure 5.5","prefix":" use it to predict the variance.","suffix":".5.4 Example 2: binary classific"}]}]}
>```
>%%
>*%%PREFIX%%use it to predict the variance.%%HIGHLIGHT%% ==There is one complication; the variance must be positive, but we can’t guaranteethat the network will always produce a positive output. To ensure that the computedvariance is positive, we pass the second network output through a function that mapsan arbitrary value to a positive one. A suitable choice is the squaring function, giving:μ = f1[x,φ]σ2 = f2[x,φ]2, (5.14)which results in the loss function:ˆφ = argminφ[−I∑i=1(log[1√2πf2[xi,φ]2]− (yi −f1[xi,φ])22f2[xi,φ]2)]. (5.15)Homoscedastic and heteroscedastic models are compared in figure 5.5== %%POSTFIX%%.5.4 Example 2: binary classific*
>%%LINK%%[[#^vu77a8u495|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vu77a8u495


>%%
>```annotation-json
>{"created":"2024-10-08T07:06:32.708Z","text":"How to apply the recipe to binary classification?","updated":"2024-10-08T07:06:32.708Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":153057,"end":153089},{"type":"TextQuoteSelector","exact":"Example 2: binary classification","prefix":" are compared in figure 5.5.5.4 ","suffix":"In binary classification, the go"}]}]}
>```
>%%
>*%%PREFIX%%are compared in figure 5.5.5.4%%HIGHLIGHT%% ==Example 2: binary classification== %%POSTFIX%%In binary classification, the go*
>%%LINK%%[[#^lcbnlv49p0s|show annotation]]
>%%COMMENT%%
>How to apply the recipe to binary classification?
>%%TAGS%%
>#question
^lcbnlv49p0s


>%%
>```annotation-json
>{"created":"2024-10-08T07:07:27.530Z","updated":"2024-10-08T07:07:27.530Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":153089,"end":153187},{"type":"TextQuoteSelector","exact":"In binary classification, the goal is to assign the data x to one of two discrete classes y ∈{0,1}","prefix":"Example 2: binary classification","suffix":". In this context, we refer to y"}]}]}
>```
>%%
>*%%PREFIX%%Example 2: binary classification%%HIGHLIGHT%% ==In binary classification, the goal is to assign the data x to one of two discrete classes y ∈{0,1}== %%POSTFIX%%. In this context, we refer to y*
>%%LINK%%[[#^yo1j7acw6i|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yo1j7acw6i


>%%
>```annotation-json
>{"created":"2024-10-08T07:07:34.159Z","updated":"2024-10-08T07:07:34.159Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":153189,"end":153230},{"type":"TextQuoteSelector","exact":"In this context, we refer to y as a label","prefix":" two discrete classes y ∈{0,1}. ","suffix":". Examples of binary classificat"}]}]}
>```
>%%
>*%%PREFIX%%two discrete classes y ∈{0,1}.%%HIGHLIGHT%% ==In this context, we refer to y as a label== %%POSTFIX%%. Examples of binary classificat*
>%%LINK%%[[#^2x50d71oy4z|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2x50d71oy4z


>%%
>```annotation-json
>{"created":"2024-10-08T07:12:33.362Z","updated":"2024-10-08T07:12:33.362Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":154815,"end":155071},{"type":"TextQuoteSelector","exact":"First,we choose a probability distribution over the output space y ∈{0,1}. A suitable choiceis the Bernoulli distribution, which is defined on the domain {0,1}. This has a singleparameter λ ∈[0,1] that represents the probability that y takes the value one ","prefix":"to construct the loss function. ","suffix":"(figure 5.6):Pr(y|λ) ={1 −λ y = "}]}]}
>```
>%%
>*%%PREFIX%%to construct the loss function.%%HIGHLIGHT%% ==First,we choose a probability distribution over the output space y ∈{0,1}. A suitable choiceis the Bernoulli distribution, which is defined on the domain {0,1}. This has a singleparameter λ ∈[0,1] that represents the probability that y takes the value one== %%POSTFIX%%(figure 5.6):Pr(y|λ) ={1 −λ y =*
>%%LINK%%[[#^4rtw3bvxx4u|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4rtw3bvxx4u


>%%
>```annotation-json
>{"created":"2024-10-08T07:12:42.878Z","updated":"2024-10-08T07:12:42.878Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":155084,"end":155180},{"type":"TextQuoteSelector","exact":"Pr(y|λ) ={1 −λ y = 0λ y = 1 , (5.16)which can equivalently be written as:Pr(y|λ) = (1 −λ)1−y ·λy","prefix":"akes the value one (figure 5.6):","suffix":". (5.17)Second, we set the machi"}]}]}
>```
>%%
>*%%PREFIX%%akes the value one (figure 5.6):%%HIGHLIGHT%% ==Pr(y|λ) ={1 −λ y = 0λ y = 1 , (5.16)which can equivalently be written as:Pr(y|λ) = (1 −λ)1−y ·λy== %%POSTFIX%%. (5.17)Second, we set the machi*
>%%LINK%%[[#^nar6wckfp9s|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nar6wckfp9s


>%%
>```annotation-json
>{"created":"2024-10-08T07:12:53.882Z","updated":"2024-10-08T07:12:53.882Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":155188,"end":155547},{"type":"TextQuoteSelector","exact":"Second, we set the machine learning model f[x,φ] to predict the single distributionparameter λ. However, λ can only take values in the range [0,1], and we cannot guaranteethat the network output will lie in this range. Consequently, we pass the network outputthrough a function that maps the real numbers R to [0,1]. A suitable function is thelogistic sigmoid","prefix":":Pr(y|λ) = (1 −λ)1−y ·λy. (5.17)","suffix":" (figure 5.7):Problem 5.1sig[z] "}]}]}
>```
>%%
>*%%PREFIX%%:Pr(y|λ) = (1 −λ)1−y ·λy. (5.17)%%HIGHLIGHT%% ==Second, we set the machine learning model f[x,φ] to predict the single distributionparameter λ. However, λ can only take values in the range [0,1], and we cannot guaranteethat the network output will lie in this range. Consequently, we pass the network outputthrough a function that maps the real numbers R to [0,1]. A suitable function is thelogistic sigmoid== %%POSTFIX%%(figure 5.7):Problem 5.1sig[z]*
>%%LINK%%[[#^srktmhjw83o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^srktmhjw83o


>%%
>```annotation-json
>{"created":"2024-10-08T07:13:05.849Z","updated":"2024-10-08T07:13:05.849Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":155572,"end":155934},{"type":"TextQuoteSelector","exact":"sig[z] = 11 + exp[−z]. (5.18)Hence, we predict the distribution parameter as λ = sig[f[x,φ]]. The likelihood is now:Pr(y|x) = (1 −sig[f[x,φ]])1−y ·sig[f[x,φ]]y. (5.19)This is depicted in figure 5.8 for a shallow neural network model. The loss function isthe negative log-likelihood of the training set:L[φ] =I∑i=1−(1 −yi) log[1 −sig[f[xi,φ]]]−yi log[sig[f[xi,φ]]","prefix":"sigmoid (figure 5.7):Problem 5.1","suffix":"]. (5.20)For reasons to be expla"}]}]}
>```
>%%
>*%%PREFIX%%sigmoid (figure 5.7):Problem 5.1%%HIGHLIGHT%% ==sig[z] = 11 + exp[−z]. (5.18)Hence, we predict the distribution parameter as λ = sig[f[x,φ]]. The likelihood is now:Pr(y|x) = (1 −sig[f[x,φ]])1−y ·sig[f[x,φ]]y. (5.19)This is depicted in figure 5.8 for a shallow neural network model. The loss function isthe negative log-likelihood of the training set:L[φ] =I∑i=1−(1 −yi) log[1 −sig[f[xi,φ]]]−yi log[sig[f[xi,φ]]== %%POSTFIX%%]. (5.20)For reasons to be expla*
>%%LINK%%[[#^1kx1k6tnldu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1kx1k6tnldu


>%%
>```annotation-json
>{"created":"2024-10-08T07:14:54.143Z","updated":"2024-10-08T07:14:54.143Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":155943,"end":156394},{"type":"TextQuoteSelector","exact":"For reasons to be explained in section 5.7, this is known as the binary cross-entropy loss.The transformed model output sig[f[x,φ]] predicts the parameter λ of the BernoulliNotebook 5.2Binarycross-entropy loss distribution. This represents the probability that y = 1, and it follows that 1 − λrepresents the probability that y = 0. When we perform inference, we may want a pointProblem 5.2estimate of y, so we set y = 1 if λ > 0.5 and y = 0 otherwise.","prefix":"]]]−yi log[sig[f[xi,φ]]]. (5.20)","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%]]]−yi log[sig[f[xi,φ]]]. (5.20)%%HIGHLIGHT%% ==For reasons to be explained in section 5.7, this is known as the binary cross-entropy loss.The transformed model output sig[f[x,φ]] predicts the parameter λ of the BernoulliNotebook 5.2Binarycross-entropy loss distribution. This represents the probability that y = 1, and it follows that 1 − λrepresents the probability that y = 0. When we perform inference, we may want a pointProblem 5.2estimate of y, so we set y = 1 if λ > 0.5 and y = 0 otherwise.== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^zl0ihn3w11b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zl0ihn3w11b


>%%
>```annotation-json
>{"created":"2024-10-08T07:17:41.789Z","text":"How to apply the recipe to multi-class classification?","updated":"2024-10-08T07:17:41.789Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":157549,"end":157585},{"type":"TextQuoteSelector","exact":"Example 3: multiclass classification","prefix":"K parameters mustsum to one.5.5 ","suffix":"The goal of multiclass classific"}]}]}
>```
>%%
>*%%PREFIX%%K parameters mustsum to one.5.5%%HIGHLIGHT%% ==Example 3: multiclass classification== %%POSTFIX%%The goal of multiclass classific*
>%%LINK%%[[#^4n9tqj6qgmx|show annotation]]
>%%COMMENT%%
>How to apply the recipe to multi-class classification?
>%%TAGS%%
>#question
^4n9tqj6qgmx


>%%
>```annotation-json
>{"created":"2024-10-08T07:18:34.704Z","updated":"2024-10-08T07:18:34.704Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":157585,"end":157898},{"type":"TextQuoteSelector","exact":"The goal of multiclass classification is to assign an input data example x to one of K > 2classes, so y ∈{1,2,...,K}. Real-world examples include (i) predicting which of K = 10digits y is present in an image x of a handwritten number and (ii) predicting which of Kpossible words y follows an incomplete sentence x","prefix":"ple 3: multiclass classification","suffix":".We once more follow the recipe "}]}]}
>```
>%%
>*%%PREFIX%%ple 3: multiclass classification%%HIGHLIGHT%% ==The goal of multiclass classification is to assign an input data example x to one of K > 2classes, so y ∈{1,2,...,K}. Real-world examples include (i) predicting which of K = 10digits y is present in an image x of a handwritten number and (ii) predicting which of Kpossible words y follows an incomplete sentence x== %%POSTFIX%%.We once more follow the recipe*
>%%LINK%%[[#^ft74njwrt5o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ft74njwrt5o


>%%
>```annotation-json
>{"created":"2024-10-08T07:19:19.552Z","updated":"2024-10-08T07:19:19.552Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":157948,"end":158218},{"type":"TextQuoteSelector","exact":"We first choose a distributionover the prediction space y. In this case, we have y ∈ {1,2,...,K}, so we choosethe categorical distribution (figure 5.9), which is defined on this domain. This has Kparameters λ1,λ2,...,λK , which determine the probability of each category","prefix":"ow the recipe from section 5.2. ","suffix":":Draft: please send errata to ud"}]}]}
>```
>%%
>*%%PREFIX%%ow the recipe from section 5.2.%%HIGHLIGHT%% ==We first choose a distributionover the prediction space y. In this case, we have y ∈ {1,2,...,K}, so we choosethe categorical distribution (figure 5.9), which is defined on this domain. This has Kparameters λ1,λ2,...,λK , which determine the probability of each category== %%POSTFIX%%:Draft: please send errata to ud*
>%%LINK%%[[#^ndy0t2l7jw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ndy0t2l7jw


>%%
>```annotation-json
>{"created":"2024-10-08T07:21:01.169Z","updated":"2024-10-08T07:21:01.169Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":158766,"end":158936},{"type":"TextQuoteSelector","exact":"Pr(y = k) = λk. (5.21)The parameters are constrained to take values between zero and one, and they mustcollectively sum to one to ensure a valid probability distribution.","prefix":"tribution similar to figure 5.9.","suffix":"Then we use a network f[x,φ] wit"}]}]}
>```
>%%
>*%%PREFIX%%tribution similar to figure 5.9.%%HIGHLIGHT%% ==Pr(y = k) = λk. (5.21)The parameters are constrained to take values between zero and one, and they mustcollectively sum to one to ensure a valid probability distribution.== %%POSTFIX%%Then we use a network f[x,φ] wit*
>%%LINK%%[[#^6ilpuj43qeq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6ilpuj43qeq


>%%
>```annotation-json
>{"created":"2024-10-08T07:22:19.631Z","updated":"2024-10-08T07:22:19.631Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":158936,"end":159853},{"type":"TextQuoteSelector","exact":"Then we use a network f[x,φ] with K outputs to compute these K parameters fromthe input x. Unfortunately, the network outputs will not necessarily obey the afore-mentioned constraints. Consequently, we pass the K outputs of the network through afunction that ensures these constraints are respected. A suitable choice is the softmaxfunction (figure 5.10). This takes an arbitrary vector of length K and returns a vectorof the same length but where the elements are now in the range [0,1] and sum to one.The kth output of the softmax function is:softmaxk[z] = exp[zk]∑Kk′=1 exp[zk′], (5.22)where the exponential functions ensure positivity, and the sum in the denominator en-Appendix B.1.3Exponentialfunctionsures that the K numbers sum to one.The likelihood that input x has label y = k (figure 5.10) is hence:Pr(y = k|x) = softmaxk[f[x,φ]]. (5.23)The loss function is the negative log-likelihood of the training data","prefix":" valid probability distribution.","suffix":":This work is subject to a Creat"}]}]}
>```
>%%
>*%%PREFIX%%valid probability distribution.%%HIGHLIGHT%% ==Then we use a network f[x,φ] with K outputs to compute these K parameters fromthe input x. Unfortunately, the network outputs will not necessarily obey the afore-mentioned constraints. Consequently, we pass the K outputs of the network through afunction that ensures these constraints are respected. A suitable choice is the softmaxfunction (figure 5.10). This takes an arbitrary vector of length K and returns a vectorof the same length but where the elements are now in the range [0,1] and sum to one.The kth output of the softmax function is:softmaxk[z] = exp[zk]∑Kk′=1 exp[zk′], (5.22)where the exponential functions ensure positivity, and the sum in the denominator en-Appendix B.1.3Exponentialfunctionsures that the K numbers sum to one.The likelihood that input x has label y = k (figure 5.10) is hence:Pr(y = k|x) = softmaxk[f[x,φ]]. (5.23)The loss function is the negative log-likelihood of the training data== %%POSTFIX%%:This work is subject to a Creat*
>%%LINK%%[[#^2005xwbxrw5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2005xwbxrw5


>%%
>```annotation-json
>{"created":"2024-10-08T07:23:48.475Z","updated":"2024-10-08T07:23:48.475Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":159955,"end":160525},{"type":"TextQuoteSelector","exact":"L[φ] = −I∑i=1log[softmaxyi[f[xi,φ]]]= −I∑i=1(fyi [xi,φ] −log[ K∑k′=1exp [ fk′[xi,φ]]]), (5.24)where fk[x,φ] denotes the kth output of the neural network. For reasons that will beexplained in section 5.7, this is known as the multiclass cross-entropy loss.The transformed model output represents a categorical distribution over possible Notebook 5.3Multiclasscross-entropy lossclasses y ∈{1,2,...,K}. For a point estimate, we take the most probable category ˆy =argmaxk[Pr(y = k|f[x, ˆφ])]. This corresponds to whichever curve is highest for thatvalue of x in figure 5.10","prefix":"IT Press.5.6 Multiple outputs 69","suffix":".5.5.1 Predicting other data typ"}]}]}
>```
>%%
>*%%PREFIX%%IT Press.5.6 Multiple outputs 69%%HIGHLIGHT%% ==L[φ] = −I∑i=1log[softmaxyi[f[xi,φ]]]= −I∑i=1(fyi [xi,φ] −log[ K∑k′=1exp [ fk′[xi,φ]]]), (5.24)where fk[x,φ] denotes the kth output of the neural network. For reasons that will beexplained in section 5.7, this is known as the multiclass cross-entropy loss.The transformed model output represents a categorical distribution over possible Notebook 5.3Multiclasscross-entropy lossclasses y ∈{1,2,...,K}. For a point estimate, we take the most probable category ˆy =argmaxk[Pr(y = k|f[x, ˆφ])]. This corresponds to whichever curve is highest for thatvalue of x in figure 5.10== %%POSTFIX%%.5.5.1 Predicting other data typ*
>%%LINK%%[[#^qux6ozepyje|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qux6ozepyje


>%%
>```annotation-json
>{"created":"2024-10-08T07:44:43.626Z","text":"What are the distributions of loss functions for different prediction types?","updated":"2024-10-08T07:44:43.626Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":163181,"end":163244},{"type":"TextQuoteSelector","exact":"Distributions for loss functions for different prediction types","prefix":"e rankingpermutationFigure 5.11 ","suffix":".When we minimize the negative l"}]}]}
>```
>%%
>*%%PREFIX%%e rankingpermutationFigure 5.11%%HIGHLIGHT%% ==Distributions for loss functions for different prediction types== %%POSTFIX%%.When we minimize the negative l*
>%%LINK%%[[#^1m7a95bibwl|show annotation]]
>%%COMMENT%%
>What are the distributions of loss functions for different prediction types?
>%%TAGS%%
>#question
^1m7a95bibwl


>%%
>```annotation-json
>{"created":"2024-10-08T07:45:31.752Z","updated":"2024-10-08T07:45:31.752Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":161334,"end":161536},{"type":"TextQuoteSelector","exact":"While itis possible to define multivariate probability distributions and use a neural network tomodel their parameters as a function of the input, it is more usual to treat each predictionas independent","prefix":"fication problem, figure 1.4a). ","suffix":".Independence implies that we tr"}]}]}
>```
>%%
>*%%PREFIX%%fication problem, figure 1.4a).%%HIGHLIGHT%% ==While itis possible to define multivariate probability distributions and use a neural network tomodel their parameters as a function of the input, it is more usual to treat each predictionas independent== %%POSTFIX%%.Independence implies that we tr*
>%%LINK%%[[#^5fro9qw1ept|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5fro9qw1ept


>%%
>```annotation-json
>{"created":"2024-10-08T07:45:35.056Z","text":"How to apply the recipe to multiple outputs?","updated":"2024-10-08T07:45:35.056Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":160989,"end":161005},{"type":"TextQuoteSelector","exact":"Multiple outputs","prefix":"s at the end of the chapter.5.6 ","suffix":"Often, we wish to make more than"}]}]}
>```
>%%
>*%%PREFIX%%s at the end of the chapter.5.6%%HIGHLIGHT%% ==Multiple outputs== %%POSTFIX%%Often, we wish to make more than*
>%%LINK%%[[#^24fvt2mnzw9|show annotation]]
>%%COMMENT%%
>How to apply the recipe to multiple outputs?
>%%TAGS%%
>#question
^24fvt2mnzw9


>%%
>```annotation-json
>{"created":"2024-10-08T07:46:36.505Z","updated":"2024-10-08T07:46:36.505Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":161537,"end":162224},{"type":"TextQuoteSelector","exact":"Independence implies that we treat the probability Pr(y|f[x,φ]) as a product of Appendix C.1.5Independenceunivariate terms for each element yd ∈y:Pr(y|f[x,φ]) = ∏dPr(yd|fd[x,φ]), (5.25)where fd[x,φ] is the dth set of network outputs, which describe the parameters of thedistribution over yd. For example, to predict multiple continuous variables yd ∈ R, weuse a normal distribution for each yd, and the network outputs fd[x,φ] predict the meansof these distributions. To predict multiple discrete variables yd ∈{1,2,...,K}, we use acategorical distribution for each yd. Here, each set of network outputs fd[x,φ] predictsthe K values that contribute to the categorical distribution for yd","prefix":"t each predictionas independent.","suffix":".Draft: please send errata to ud"}]}]}
>```
>%%
>*%%PREFIX%%t each predictionas independent.%%HIGHLIGHT%% ==Independence implies that we treat the probability Pr(y|f[x,φ]) as a product of Appendix C.1.5Independenceunivariate terms for each element yd ∈y:Pr(y|f[x,φ]) = ∏dPr(yd|fd[x,φ]), (5.25)where fd[x,φ] is the dth set of network outputs, which describe the parameters of thedistribution over yd. For example, to predict multiple continuous variables yd ∈ R, weuse a normal distribution for each yd, and the network outputs fd[x,φ] predict the meansof these distributions. To predict multiple discrete variables yd ∈{1,2,...,K}, we use acategorical distribution for each yd. Here, each set of network outputs fd[x,φ] predictsthe K values that contribute to the categorical distribution for yd== %%POSTFIX%%.Draft: please send errata to ud*
>%%LINK%%[[#^eznidy683e5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^eznidy683e5


>%%
>```annotation-json
>{"created":"2024-10-08T07:47:00.545Z","updated":"2024-10-08T07:47:00.545Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":163245,"end":163456},{"type":"TextQuoteSelector","exact":"When we minimize the negative log probability, this product becomes a sum of terms:L[φ] = −I∑i=1log[Pr(yi|f[xi,φ])]= −I∑i=1∑dlog[Pr(yid|fd[xi,φ])]. (5.26)where yid is the dth output from the ith training example","prefix":" for different prediction types.","suffix":".To make two or more prediction "}]}]}
>```
>%%
>*%%PREFIX%%for different prediction types.%%HIGHLIGHT%% ==When we minimize the negative log probability, this product becomes a sum of terms:L[φ] = −I∑i=1log[Pr(yi|f[xi,φ])]= −I∑i=1∑dlog[Pr(yid|fd[xi,φ])]. (5.26)where yid is the dth output from the ith training example== %%POSTFIX%%.To make two or more prediction*
>%%LINK%%[[#^sce6jr40hai|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^sce6jr40hai


>%%
>```annotation-json
>{"created":"2024-10-08T07:47:44.438Z","updated":"2024-10-08T07:47:44.438Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":163457,"end":163563},{"type":"TextQuoteSelector","exact":"To make two or more prediction types simultaneously, we similarly assume the errorsin each are independent","prefix":"t from the ith training example.","suffix":". For example, to predict wind d"}]}]}
>```
>%%
>*%%PREFIX%%t from the ith training example.%%HIGHLIGHT%% ==To make two or more prediction types simultaneously, we similarly assume the errorsin each are independent== %%POSTFIX%%. For example, to predict wind d*
>%%LINK%%[[#^ur4uzqo1poe|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ur4uzqo1poe


>%%
>```annotation-json
>{"created":"2024-10-08T07:48:15.848Z","updated":"2024-10-08T07:48:15.848Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":163811,"end":164011},{"type":"TextQuoteSelector","exact":"Theindependence assumption implies that the joint likelihood of the two predictions is theproduct of individual likelihoods. These terms will become additive when we computethe negative log-likelihood","prefix":"real numbers) for the strength. ","suffix":".This work is subject to a Creat"}]}]}
>```
>%%
>*%%PREFIX%%real numbers) for the strength.%%HIGHLIGHT%% ==Theindependence assumption implies that the joint likelihood of the two predictions is theproduct of individual likelihoods. These terms will become additive when we computethe negative log-likelihood== %%POSTFIX%%.This work is subject to a Creat*
>%%LINK%%[[#^zcaogm9cxid|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zcaogm9cxid


>%%
>```annotation-json
>{"created":"2024-10-08T07:48:47.018Z","text":"What is cross entropy loss?","updated":"2024-10-08T07:48:47.018Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":164452,"end":164470},{"type":"TextQuoteSelector","exact":"Cross-entropy loss","prefix":"on of themodel parameters θ.5.7 ","suffix":"In this chapter, we developed lo"}]}]}
>```
>%%
>*%%PREFIX%%on of themodel parameters θ.5.7%%HIGHLIGHT%% ==Cross-entropy loss== %%POSTFIX%%In this chapter, we developed lo*
>%%LINK%%[[#^zc0qa9syypk|show annotation]]
>%%COMMENT%%
>What is cross entropy loss?
>%%TAGS%%
>#question
^zc0qa9syypk


>%%
>```annotation-json
>{"created":"2024-10-08T07:50:27.848Z","updated":"2024-10-08T07:50:27.848Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":164728,"end":165085},{"type":"TextQuoteSelector","exact":"The cross-entropy loss is based on the idea of finding parameters θ that minimize thedistance between the empirical distribution q(y) of the observed data y and a model dis-tribution Pr(y|θ) (figure 5.12). The distance between two probability distributions q(z) Appendix C.5.1KL Divergenceand p(z) can be evaluated using the Kullback-Leibler (KL) divergence","prefix":"o using negative log-likelihood.","suffix":":DKL[q||p] =∫ ∞−∞q(z) log[q(z)]d"}]}]}
>```
>%%
>*%%PREFIX%%o using negative log-likelihood.%%HIGHLIGHT%% ==The cross-entropy loss is based on the idea of finding parameters θ that minimize thedistance between the empirical distribution q(y) of the observed data y and a model dis-tribution Pr(y|θ) (figure 5.12). The distance between two probability distributions q(z) Appendix C.5.1KL Divergenceand p(z) can be evaluated using the Kullback-Leibler (KL) divergence== %%POSTFIX%%:DKL[q||p] =∫ ∞−∞q(z) log[q(z)]d*
>%%LINK%%[[#^3nnnbnqb4bt|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3nnnbnqb4bt


>%%
>```annotation-json
>{"created":"2024-10-08T07:50:42.142Z","updated":"2024-10-08T07:50:42.142Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":165086,"end":165141},{"type":"TextQuoteSelector","exact":"DKL[q||p] =∫ ∞−∞q(z) log[q(z)]dz −∫ ∞−∞q(z) log[p(z)]dz","prefix":"ullback-Leibler (KL) divergence:","suffix":". (5.27)Now consider that we obs"}]}]}
>```
>%%
>*%%PREFIX%%ullback-Leibler (KL) divergence:%%HIGHLIGHT%% ==DKL[q||p] =∫ ∞−∞q(z) log[q(z)]dz −∫ ∞−∞q(z) log[p(z)]dz== %%POSTFIX%%. (5.27)Now consider that we obs*
>%%LINK%%[[#^temd6cwd9zf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^temd6cwd9zf


>%%
>```annotation-json
>{"created":"2024-10-08T07:52:25.838Z","updated":"2024-10-08T07:52:25.838Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":165149,"end":165592},{"type":"TextQuoteSelector","exact":"Now consider that we observe an empirical data distribution at points {yi}Ii=1. Wecan describe this as a weighted sum of point masses:q(y) = 1II∑i=1δ[y −yi], (5.28)where δ[•] is the Dirac delta function. We want to minimize the KL divergence between Appendix B.1.3Dirac deltafunctionthe model distribution Pr(y|θ) and this empirical distribution:ˆθ = argminθ[∫ ∞−∞q(y) log[q(y)]dy −∫ ∞−∞q(y) log[Pr(y|θ)]dy]= argminθ[−∫ ∞−∞q(y) log[Pr(y|θ)]dy]","prefix":"z −∫ ∞−∞q(z) log[p(z)]dz. (5.27)","suffix":", (5.29)Draft: please send errat"}]}]}
>```
>%%
>*%%PREFIX%%z −∫ ∞−∞q(z) log[p(z)]dz. (5.27)%%HIGHLIGHT%% ==Now consider that we observe an empirical data distribution at points {yi}Ii=1. Wecan describe this as a weighted sum of point masses:q(y) = 1II∑i=1δ[y −yi], (5.28)where δ[•] is the Dirac delta function. We want to minimize the KL divergence between Appendix B.1.3Dirac deltafunctionthe model distribution Pr(y|θ) and this empirical distribution:ˆθ = argminθ[∫ ∞−∞q(y) log[q(y)]dy −∫ ∞−∞q(y) log[Pr(y|θ)]dy]= argminθ[−∫ ∞−∞q(y) log[Pr(y|θ)]dy]== %%POSTFIX%%, (5.29)Draft: please send errat*
>%%LINK%%[[#^nbw4u0h59ym|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nbw4u0h59ym


>%%
>```annotation-json
>{"created":"2024-10-08T07:54:16.662Z","updated":"2024-10-08T07:54:16.662Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":165670,"end":166110},{"type":"TextQuoteSelector","exact":"where the first term disappears, as it has no dependence on θ. The remaining secondterm is known as the cross-entropy. It can be interpreted as the amount of uncertaintythat remains in one distribution after taking into account what we already know fromthe other. Now, we substitute in the definition of q(y) from equation 5.28:ˆθ = argminθ[−∫ ∞−∞(1II∑i=1δ[y −yi])log[Pr(y|θ)]dy]= argminθ[−1II∑i=1log[Pr(yi|θ)]]= argminθ[−I∑i=1log[Pr(yi|θ)]","prefix":"il@gmail.com.72 5 Loss functions","suffix":"]. (5.30)The product of the two "}]}]}
>```
>%%
>*%%PREFIX%%il@gmail.com.72 5 Loss functions%%HIGHLIGHT%% ==where the first term disappears, as it has no dependence on θ. The remaining secondterm is known as the cross-entropy. It can be interpreted as the amount of uncertaintythat remains in one distribution after taking into account what we already know fromthe other. Now, we substitute in the definition of q(y) from equation 5.28:ˆθ = argminθ[−∫ ∞−∞(1II∑i=1δ[y −yi])log[Pr(y|θ)]dy]= argminθ[−1II∑i=1log[Pr(yi|θ)]]= argminθ[−I∑i=1log[Pr(yi|θ)]== %%POSTFIX%%]. (5.30)The product of the two*
>%%LINK%%[[#^fowqhsqtlvu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fowqhsqtlvu


>%%
>```annotation-json
>{"created":"2024-10-08T07:55:19.306Z","updated":"2024-10-08T07:55:19.306Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":166119,"end":166499},{"type":"TextQuoteSelector","exact":"The product of the two terms in the first line corresponds to pointwise multiplying thepoint masses in figure 5.12a with the logarithm of the distribution in figure 5.12b. Weare left with a finite set of weighted probability masses centered on the data points. Inthe last line, we have eliminated the constant scaling factor 1/I, as this does not affectthe position of the minimum","prefix":"inθ[−I∑i=1log[Pr(yi|θ)]]. (5.30)","suffix":".In machine learning, the distri"}]}]}
>```
>%%
>*%%PREFIX%%inθ[−I∑i=1log[Pr(yi|θ)]]. (5.30)%%HIGHLIGHT%% ==The product of the two terms in the first line corresponds to pointwise multiplying thepoint masses in figure 5.12a with the logarithm of the distribution in figure 5.12b. Weare left with a finite set of weighted probability masses centered on the data points. Inthe last line, we have eliminated the constant scaling factor 1/I, as this does not affectthe position of the minimum== %%POSTFIX%%.In machine learning, the distri*
>%%LINK%%[[#^r6azwexi21a|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^r6azwexi21a


>%%
>```annotation-json
>{"created":"2024-10-08T07:55:47.415Z","updated":"2024-10-08T07:55:47.415Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":166500,"end":166950},{"type":"TextQuoteSelector","exact":"In machine learning, the distribution parameters θ are computed by the model f[xi,φ],so we have:ˆφ = argminφ[−I∑i=1log[Pr(yi|f[xi,φ])]]. (5.31)This is precisely the negative log-likelihood criterion from the recipe in section 5.2.It follows that the negative log-likelihood criterion (from maximizing the data likeli-hood) and the cross-entropy criterion (from minimizing the distance between the modeland empirical data distributions) are equivalent","prefix":"fectthe position of the minimum.","suffix":".5.8 SummaryWe previously consid"}]}]}
>```
>%%
>*%%PREFIX%%fectthe position of the minimum.%%HIGHLIGHT%% ==In machine learning, the distribution parameters θ are computed by the model f[xi,φ],so we have:ˆφ = argminφ[−I∑i=1log[Pr(yi|f[xi,φ])]]. (5.31)This is precisely the negative log-likelihood criterion from the recipe in section 5.2.It follows that the negative log-likelihood criterion (from maximizing the data likeli-hood) and the cross-entropy criterion (from minimizing the distance between the modeland empirical data distributions) are equivalent== %%POSTFIX%%.5.8 SummaryWe previously consid*
>%%LINK%%[[#^7cez1bpnq7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7cez1bpnq7


>%%
>```annotation-json
>{"created":"2024-10-08T07:59:50.874Z","text":"What is robust regression?","updated":"2024-10-08T07:59:50.874Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":168970,"end":168987},{"type":"TextQuoteSelector","exact":"Robust regression","prefix":"stribution with full covariance.","suffix":": Qi et al. (2020) investigate t"}]}]}
>```
>%%
>*%%PREFIX%%stribution with full covariance.%%HIGHLIGHT%% ==Robust regression== %%POSTFIX%%: Qi et al. (2020) investigate t*
>%%LINK%%[[#^b3i2wxllr7i|show annotation]]
>%%COMMENT%%
>What is robust regression?
>%%TAGS%%
>#question
^b3i2wxllr7i


>%%
>```annotation-json
>{"created":"2024-10-08T08:01:34.792Z","updated":"2024-10-08T08:01:34.792Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":169527,"end":169547},{"type":"TextQuoteSelector","exact":"Estimating quantiles","prefix":" distributions as special cases.","suffix":": Sometimes, we may not want to "}]}]}
>```
>%%
>*%%PREFIX%%distributions as special cases.%%HIGHLIGHT%% ==Estimating quantiles== %%POSTFIX%%: Sometimes, we may not want to*
>%%LINK%%[[#^ij7rqg2a2vq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ij7rqg2a2vq


>%%
>```annotation-json
>{"created":"2024-10-08T08:04:05.693Z","updated":"2024-10-08T08:04:05.693Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":172459,"end":172487},{"type":"TextQuoteSelector","exact":"Non-probabilistic approaches","prefix":"istribution to predict duration.","suffix":": It is not strictly necessary t"}]}]}
>```
>%%
>*%%PREFIX%%istribution to predict duration.%%HIGHLIGHT%% ==Non-probabilistic approaches== %%POSTFIX%%: It is not strictly necessary t*
>%%LINK%%[[#^wy8b9dbcb6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wy8b9dbcb6


>%%
>```annotation-json
>{"created":"2024-10-08T12:35:57.263Z","text":"What is gradient descent?","updated":"2024-10-08T12:35:57.263Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":179630,"end":179646},{"type":"TextQuoteSelector","exact":"Gradient descent","prefix":"adients for neural networks.6.1 ","suffix":"To fit a model, we need a traini"}]}]}
>```
>%%
>*%%PREFIX%%adients for neural networks.6.1%%HIGHLIGHT%% ==Gradient descent== %%POSTFIX%%To fit a model, we need a traini*
>%%LINK%%[[#^00tq056fa70rk|show annotation]]
>%%COMMENT%%
>What is gradient descent?
>%%TAGS%%
>#question
^00tq056fa70rk


>%%
>```annotation-json
>{"created":"2024-10-08T12:37:30.792Z","updated":"2024-10-08T12:37:30.792Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":179941,"end":180025},{"type":"TextQuoteSelector","exact":"The goal of an optimization algorithm is to findparameters ˆφ that minimize the loss","prefix":"s the mismatch in this mapping. ","suffix":":ˆφ = argminφ[L[φ]]. (6.1)There "}]}]}
>```
>%%
>*%%PREFIX%%s the mismatch in this mapping.%%HIGHLIGHT%% ==The goal of an optimization algorithm is to findparameters ˆφ that minimize the loss== %%POSTFIX%%:ˆφ = argminφ[L[φ]]. (6.1)There*
>%%LINK%%[[#^vii3sotz3e|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vii3sotz3e


>%%
>```annotation-json
>{"created":"2024-10-08T12:37:38.018Z","updated":"2024-10-08T12:37:38.018Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":180027,"end":180043},{"type":"TextQuoteSelector","exact":"φ = argminφ[L[φ]","prefix":"ters ˆφ that minimize the loss:ˆ","suffix":"]. (6.1)There are many families "}]}]}
>```
>%%
>*%%PREFIX%%ters ˆφ that minimize the loss:ˆ%%HIGHLIGHT%% ==φ = argminφ[L[φ]== %%POSTFIX%%]. (6.1)There are many families*
>%%LINK%%[[#^f5gl0vyppx|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f5gl0vyppx


>%%
>```annotation-json
>{"created":"2024-10-08T12:37:50.966Z","updated":"2024-10-08T12:37:50.966Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":180051,"end":180299},{"type":"TextQuoteSelector","exact":"There are many families of optimization algorithms, but the standard methods for train-ing neural networks are iterative. These algorithms initialize the parameters heuristicallyand then adjust them repeatedly in such a way that the loss decreases.","prefix":"e loss:ˆφ = argminφ[L[φ]]. (6.1)","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%e loss:ˆφ = argminφ[L[φ]]. (6.1)%%HIGHLIGHT%% ==There are many families of optimization algorithms, but the standard methods for train-ing neural networks are iterative. These algorithms initialize the parameters heuristicallyand then adjust them repeatedly in such a way that the loss decreases.== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^1jwcsbzngne|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1jwcsbzngne


>%%
>```annotation-json
>{"created":"2024-10-08T12:38:39.840Z","updated":"2024-10-08T12:38:39.840Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":180369,"end":180765},{"type":"TextQuoteSelector","exact":"The simplest method in this class is gradient descent. This starts with initial param-eters φ = [φ0,φ1,...,φN ]T and iterates two steps:Step 1. Compute the derivatives of the loss with respect to the parameters:∂L∂φ =∂L∂φ0∂L∂φ1...∂L∂φN. (6.2)Step 2. Update the parameters according to the rule:φ ←−φ−α · ∂L∂φ, (6.3)where the positive scalar α determines the magnitude of the change.","prefix":"il@gmail.com.78 6 Fitting models","suffix":"The first step computes the grad"}]}]}
>```
>%%
>*%%PREFIX%%il@gmail.com.78 6 Fitting models%%HIGHLIGHT%% ==The simplest method in this class is gradient descent. This starts with initial param-eters φ = [φ0,φ1,...,φN ]T and iterates two steps:Step 1. Compute the derivatives of the loss with respect to the parameters:∂L∂φ =∂L∂φ0∂L∂φ1...∂L∂φN. (6.2)Step 2. Update the parameters according to the rule:φ ←−φ−α · ∂L∂φ, (6.3)where the positive scalar α determines the magnitude of the change.== %%POSTFIX%%The first step computes the grad*
>%%LINK%%[[#^qdbqpe7v63n|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qdbqpe7v63n


>%%
>```annotation-json
>{"created":"2024-10-08T12:41:20.021Z","updated":"2024-10-08T12:41:20.021Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":180765,"end":181469},{"type":"TextQuoteSelector","exact":"The first step computes the gradient of the loss function at the current position. Thisdetermines the uphill direction of the loss function. The second step moves a smalldistance α downhill (hence the negative sign). The parameter α may be fixed (in whichNotebook 6.1Line search case, we call it a learning rate), or we may perform a line search where we try severalvalues of α to find the one that most decreases the loss.At the minimum of the loss function, the surface must be flat (or we could improvefurther by going downhill). Hence, the gradient will be zero, and the parameters will stopchanging. In practice, we monitor the gradient magnitude and terminate the algorithmwhen it becomes too small","prefix":"nes the magnitude of the change.","suffix":".6.1.1 Linear regression example"}]}]}
>```
>%%
>*%%PREFIX%%nes the magnitude of the change.%%HIGHLIGHT%% ==The first step computes the gradient of the loss function at the current position. Thisdetermines the uphill direction of the loss function. The second step moves a smalldistance α downhill (hence the negative sign). The parameter α may be fixed (in whichNotebook 6.1Line search case, we call it a learning rate), or we may perform a line search where we try severalvalues of α to find the one that most decreases the loss.At the minimum of the loss function, the surface must be flat (or we could improvefurther by going downhill). Hence, the gradient will be zero, and the parameters will stopchanging. In practice, we monitor the gradient magnitude and terminate the algorithmwhen it becomes too small== %%POSTFIX%%.6.1.1 Linear regression example*
>%%LINK%%[[#^qcn24a4k7xi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qcn24a4k7xi


>%%
>```annotation-json
>{"created":"2024-10-08T12:41:35.133Z","text":"How does gradient descent work with linear regression?","updated":"2024-10-08T12:41:35.133Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":181476,"end":181501},{"type":"TextQuoteSelector","exact":"Linear regression example","prefix":"when it becomes too small.6.1.1 ","suffix":"Consider applying gradient desce"}]}]}
>```
>%%
>*%%PREFIX%%when it becomes too small.6.1.1%%HIGHLIGHT%% ==Linear regression example== %%POSTFIX%%Consider applying gradient desce*
>%%LINK%%[[#^7qwyuyf9wkd|show annotation]]
>%%COMMENT%%
>How does gradient descent work with linear regression?
>%%TAGS%%
>#question
^7qwyuyf9wkd


>%%
>```annotation-json
>{"created":"2024-10-08T12:42:45.182Z","updated":"2024-10-08T12:42:45.182Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":181724,"end":181745},{"type":"TextQuoteSelector","exact":"y = f[x,φ]= φ0 + φ1x.","prefix":"t the y-intercept and the slope:","suffix":" (6.4)Given a dataset {xi,yi} co"}]}]}
>```
>%%
>*%%PREFIX%%t the y-intercept and the slope:%%HIGHLIGHT%% ==y = f[x,φ]= φ0 + φ1x.== %%POSTFIX%%(6.4)Given a dataset {xi,yi} co*
>%%LINK%%[[#^93c5yuqbpij|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^93c5yuqbpij


>%%
>```annotation-json
>{"created":"2024-10-08T12:42:54.778Z","updated":"2024-10-08T12:42:54.778Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":181751,"end":181905},{"type":"TextQuoteSelector","exact":"Given a dataset {xi,yi} containing I input/output pairs, we choose the least squaresloss function:L[φ] =I∑i=1ℓi =I∑i=1(f[xi,φ] −yi)2=I∑i=1(φ0 + φ1xi −yi)2","prefix":"lope:y = f[x,φ]= φ0 + φ1x. (6.4)","suffix":" , (6.5)This work is subject to "}]}]}
>```
>%%
>*%%PREFIX%%lope:y = f[x,φ]= φ0 + φ1x. (6.4)%%HIGHLIGHT%% ==Given a dataset {xi,yi} containing I input/output pairs, we choose the least squaresloss function:L[φ] =I∑i=1ℓi =I∑i=1(f[xi,φ] −yi)2=I∑i=1(φ0 + φ1xi −yi)2== %%POSTFIX%%, (6.5)This work is subject to*
>%%LINK%%[[#^4ljxw0n9jrk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4ljxw0n9jrk


>%%
>```annotation-json
>{"created":"2024-10-08T12:44:33.410Z","updated":"2024-10-08T12:44:33.410Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":182877,"end":182985},{"type":"TextQuoteSelector","exact":"where the term ℓi = (φ0 + φ1xi −yi)2 is the individual contribution to the loss fromthe ith training example","prefix":"il@gmail.com.80 6 Fitting models","suffix":".The derivative of the loss func"}]}]}
>```
>%%
>*%%PREFIX%%il@gmail.com.80 6 Fitting models%%HIGHLIGHT%% ==where the term ℓi = (φ0 + φ1xi −yi)2 is the individual contribution to the loss fromthe ith training example== %%POSTFIX%%.The derivative of the loss func*
>%%LINK%%[[#^v37nyo2a54|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^v37nyo2a54


>%%
>```annotation-json
>{"created":"2024-10-08T12:44:47.656Z","updated":"2024-10-08T12:44:47.656Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":182986,"end":183164},{"type":"TextQuoteSelector","exact":"The derivative of the loss function with respect to the parameters can be decomposedinto the sum of the derivatives of the individual contributions:∂L∂φ = ∂∂φI∑i=1ℓi =I∑i=1∂ℓi∂φ,","prefix":"ss fromthe ith training example.","suffix":" (6.6)where these are given by:P"}]}]}
>```
>%%
>*%%PREFIX%%ss fromthe ith training example.%%HIGHLIGHT%% ==The derivative of the loss function with respect to the parameters can be decomposedinto the sum of the derivatives of the individual contributions:∂L∂φ = ∂∂φI∑i=1ℓi =I∑i=1∂ℓi∂φ,== %%POSTFIX%%(6.6)where these are given by:P*
>%%LINK%%[[#^ewfk9s45ewc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ewfk9s45ewc


>%%
>```annotation-json
>{"created":"2024-10-08T12:46:28.707Z","updated":"2024-10-08T12:46:28.707Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":183170,"end":183268},{"type":"TextQuoteSelector","exact":"where these are given by:Problem 6.1∂ℓi∂φ =∂ℓi∂φ0∂ℓi∂φ1 =[ 2(φ0 + φ1xi −yi)2xi(φ0 + φ1xi −yi)]","prefix":" = ∂∂φI∑i=1ℓi =I∑i=1∂ℓi∂φ, (6.6)","suffix":". (6.7)Figure 6.1 shows the prog"}]}]}
>```
>%%
>*%%PREFIX%%= ∂∂φI∑i=1ℓi =I∑i=1∂ℓi∂φ, (6.6)%%HIGHLIGHT%% ==where these are given by:Problem 6.1∂ℓi∂φ =∂ℓi∂φ0∂ℓi∂φ1 =[ 2(φ0 + φ1xi −yi)2xi(φ0 + φ1xi −yi)]== %%POSTFIX%%. (6.7)Figure 6.1 shows the prog*
>%%LINK%%[[#^rszyuia6gnc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rszyuia6gnc


>%%
>```annotation-json
>{"created":"2024-10-08T12:50:31.172Z","text":"What is Gabor model?","updated":"2024-10-08T12:50:31.172Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":183623,"end":183642},{"type":"TextQuoteSelector","exact":"Gabor model example","prefix":"he most at each iteration.6.1.2 ","suffix":"Loss functions for linear regres"}]}]}
>```
>%%
>*%%PREFIX%%he most at each iteration.6.1.2%%HIGHLIGHT%% ==Gabor model example== %%POSTFIX%%Loss functions for linear regres*
>%%LINK%%[[#^m6ycdht99hf|show annotation]]
>%%COMMENT%%
>What is Gabor model?
>%%TAGS%%
>#question
^m6ycdht99hf


>%%
>```annotation-json
>{"created":"2024-10-08T12:51:19.480Z","updated":"2024-10-08T12:51:19.480Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":183642,"end":184051},{"type":"TextQuoteSelector","exact":"Loss functions for linear regression problems (figure 6.1c) always have a single well-defined global minimum. More formally, they are convex, which means that no chordProblem 6.2 (line segment between two points on the surface) intersects the function. Convexityimplies that wherever we initialize the parameters, we are bound to reach the minimumif we keep walking downhill; the training procedure can’t fail","prefix":"ration.6.1.2 Gabor model example","suffix":".Unfortunately, loss functions f"}]}]}
>```
>%%
>*%%PREFIX%%ration.6.1.2 Gabor model example%%HIGHLIGHT%% ==Loss functions for linear regression problems (figure 6.1c) always have a single well-defined global minimum. More formally, they are convex, which means that no chordProblem 6.2 (line segment between two points on the surface) intersects the function. Convexityimplies that wherever we initialize the parameters, we are bound to reach the minimumif we keep walking downhill; the training procedure can’t fail== %%POSTFIX%%.Unfortunately, loss functions f*
>%%LINK%%[[#^q5xgdd4bmv|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^q5xgdd4bmv


>%%
>```annotation-json
>{"created":"2024-10-08T12:52:10.887Z","updated":"2024-10-08T12:52:10.887Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":184052,"end":184446},{"type":"TextQuoteSelector","exact":"Unfortunately, loss functions for most nonlinear models, including both shallow anddeep networks, are non-convex. Visualizing neural network loss functions is challengingdue to the number of parameters. Hence, we first explore a simpler nonlinear model withtwo parameters to gain insight into the properties of non-convex loss functions:f[x,φ] = sin[φ0 + 0.06 ·φ1x] ·exp(−(φ0 + 0.06 ·φ1x)232.0)","prefix":"e training procedure can’t fail.","suffix":". (6.8)This Gabor model maps sca"}]}]}
>```
>%%
>*%%PREFIX%%e training procedure can’t fail.%%HIGHLIGHT%% ==Unfortunately, loss functions for most nonlinear models, including both shallow anddeep networks, are non-convex. Visualizing neural network loss functions is challengingdue to the number of parameters. Hence, we first explore a simpler nonlinear model withtwo parameters to gain insight into the properties of non-convex loss functions:f[x,φ] = sin[φ0 + 0.06 ·φ1x] ·exp(−(φ0 + 0.06 ·φ1x)232.0)== %%POSTFIX%%. (6.8)This Gabor model maps sca*
>%%LINK%%[[#^0glh59fa11nd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0glh59fa11nd


>%%
>```annotation-json
>{"created":"2024-10-08T12:54:19.713Z","updated":"2024-10-08T12:54:19.713Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":184453,"end":184869},{"type":"TextQuoteSelector","exact":"This Gabor model maps scalar input x to scalar output y and consists of a sinusoidalProblems 6.3–6.5 component (creating an oscillatory function) multiplied by a negative exponential com-ponent (causing the amplitude to decrease as we move from the center). It has twoparameters φ = [φ0,φ1]T , where φ0 ∈ R determines the mean position of the functionand φ1 ∈R+ stretches or squeezes it along the x-axis (figure 6.2)","prefix":"p(−(φ0 + 0.06 ·φ1x)232.0). (6.8)","suffix":".Consider a training set of I ex"}]}]}
>```
>%%
>*%%PREFIX%%p(−(φ0 + 0.06 ·φ1x)232.0). (6.8)%%HIGHLIGHT%% ==This Gabor model maps scalar input x to scalar output y and consists of a sinusoidalProblems 6.3–6.5 component (creating an oscillatory function) multiplied by a negative exponential com-ponent (causing the amplitude to decrease as we move from the center). It has twoparameters φ = [φ0,φ1]T , where φ0 ∈ R determines the mean position of the functionand φ1 ∈R+ stretches or squeezes it along the x-axis (figure 6.2)== %%POSTFIX%%.Consider a training set of I ex*
>%%LINK%%[[#^gb2n8lcuq4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^gb2n8lcuq4


>%%
>```annotation-json
>{"created":"2024-10-08T12:54:30.699Z","updated":"2024-10-08T12:54:30.699Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":184870,"end":185105},{"type":"TextQuoteSelector","exact":"Consider a training set of I examples {xi,yi} (figure 6.3). The least squares lossfunction for I training examples is defined as:L[φ] =I∑i=1(f[xi,φ] −yi)2 . (6.9)Once more, the goal is to find the parameters ˆφ that minimize this loss.","prefix":"t along the x-axis (figure 6.2).","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%t along the x-axis (figure 6.2).%%HIGHLIGHT%% ==Consider a training set of I examples {xi,yi} (figure 6.3). The least squares lossfunction for I training examples is defined as:L[φ] =I∑i=1(f[xi,φ] −yi)2 . (6.9)Once more, the goal is to find the parameters ˆφ that minimize this loss.== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^g6d8wqew8c|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^g6d8wqew8c


>%%
>```annotation-json
>{"created":"2024-10-08T12:56:02.320Z","text":"What are local minima and saddle points?","updated":"2024-10-08T12:56:02.320Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":185963,"end":185993},{"type":"TextQuoteSelector","exact":"Local minima and saddle points","prefix":"ormally distributed noise.6.1.3 ","suffix":"Figure 6.4 depicts the loss func"}]}]}
>```
>%%
>*%%PREFIX%%ormally distributed noise.6.1.3%%HIGHLIGHT%% ==Local minima and saddle points== %%POSTFIX%%Figure 6.4 depicts the loss func*
>%%LINK%%[[#^rurhmjdj1n|show annotation]]
>%%COMMENT%%
>What are local minima and saddle points?
>%%TAGS%%
>#question
^rurhmjdj1n


>%%
>```annotation-json
>{"created":"2024-10-08T12:57:28.274Z","text":"What is local minima?\nWhat is global minima?","updated":"2024-10-08T12:57:28.274Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":185993,"end":186367},{"type":"TextQuoteSelector","exact":"Figure 6.4 depicts the loss function associated with the Gabor model for this dataset.There are numerous local minima (cyan circles). Here the gradient is zero, and the loss Problem 6.6increases if we move in any direction, but we are not at the overall minimum of thefunction. The point with the lowest loss is known as the global minimum and is depictedby the gray circle.","prefix":"3 Local minima and saddle points","suffix":"If we start in a random position"}]}]}
>```
>%%
>*%%PREFIX%%3 Local minima and saddle points%%HIGHLIGHT%% ==Figure 6.4 depicts the loss function associated with the Gabor model for this dataset.There are numerous local minima (cyan circles). Here the gradient is zero, and the loss Problem 6.6increases if we move in any direction, but we are not at the overall minimum of thefunction. The point with the lowest loss is known as the global minimum and is depictedby the gray circle.== %%POSTFIX%%If we start in a random position*
>%%LINK%%[[#^5mpug7d6v1w|show annotation]]
>%%COMMENT%%
>What is local minima?
>What is global minima?
>%%TAGS%%
>#question
^5mpug7d6v1w


>%%
>```annotation-json
>{"created":"2024-10-08T12:59:15.633Z","updated":"2024-10-08T12:59:15.633Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":186367,"end":186742},{"type":"TextQuoteSelector","exact":"If we start in a random position and use gradient descent to go downhill, there is Problems 6.7–6.8no guarantee that we will wind up at the global minimum and find the best parameters(figure 6.5a). It’s equally or even more likely that the algorithm will terminate in oneof the local minima. Furthermore, there is no way of knowing whether there is a bettersolution elsewhere","prefix":"d is depictedby the gray circle.","suffix":".Draft: please send errata to ud"}]}]}
>```
>%%
>*%%PREFIX%%d is depictedby the gray circle.%%HIGHLIGHT%% ==If we start in a random position and use gradient descent to go downhill, there is Problems 6.7–6.8no guarantee that we will wind up at the global minimum and find the best parameters(figure 6.5a). It’s equally or even more likely that the algorithm will terminate in oneof the local minima. Furthermore, there is no way of knowing whether there is a bettersolution elsewhere== %%POSTFIX%%.Draft: please send errata to ud*
>%%LINK%%[[#^xl6x611lzot|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xl6x611lzot


>%%
>```annotation-json
>{"created":"2024-10-08T13:05:31.122Z","text":"What are saddle points?","updated":"2024-10-08T13:05:31.122Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":188130,"end":188642},{"type":"TextQuoteSelector","exact":"In addition, the loss function contains saddle points (e.g., the blue cross in figure 6.4).Here, the gradient is zero, but the function increases in some directions and decreasesin others. If the current parameters are not exactly at the saddle point, then gradientdescent can escape by moving downhill. However, the surface near the saddle point isflat, so it’s hard to be sure that training hasn’t converged; if we terminate the algorithmwhen the gradient is small, we may erroneously stop near a saddle point.","prefix":" still reach the global minimum.","suffix":"6.2 Stochastic gradient descentT"}]}]}
>```
>%%
>*%%PREFIX%%still reach the global minimum.%%HIGHLIGHT%% ==In addition, the loss function contains saddle points (e.g., the blue cross in figure 6.4).Here, the gradient is zero, but the function increases in some directions and decreasesin others. If the current parameters are not exactly at the saddle point, then gradientdescent can escape by moving downhill. However, the surface near the saddle point isflat, so it’s hard to be sure that training hasn’t converged; if we terminate the algorithmwhen the gradient is small, we may erroneously stop near a saddle point.== %%POSTFIX%%6.2 Stochastic gradient descentT*
>%%LINK%%[[#^bdm26ljvpmt|show annotation]]
>%%COMMENT%%
>What are saddle points?
>%%TAGS%%
>#question
^bdm26ljvpmt


>%%
>```annotation-json
>{"created":"2024-10-08T13:10:00.991Z","text":"What is stochastic gradient descent?","updated":"2024-10-08T13:10:00.991Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":188646,"end":188673},{"type":"TextQuoteSelector","exact":"Stochastic gradient descent","prefix":"ly stop near a saddle point.6.2 ","suffix":"The Gabor model has two paramete"}]}]}
>```
>%%
>*%%PREFIX%%ly stop near a saddle point.6.2%%HIGHLIGHT%% ==Stochastic gradient descent== %%POSTFIX%%The Gabor model has two paramete*
>%%LINK%%[[#^44yv5bk91z|show annotation]]
>%%COMMENT%%
>What is stochastic gradient descent?
>%%TAGS%%
>#question
^44yv5bk91z


>%%
>```annotation-json
>{"created":"2024-10-08T13:11:29.848Z","updated":"2024-10-08T13:11:29.848Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":188673,"end":189122},{"type":"TextQuoteSelector","exact":"The Gabor model has two parameters, so we could find the global minimum by either (i)exhaustively searching the parameter space or (ii) repeatedly starting gradient descentfrom different positions and choosing the result with the lowest loss. However, neuralnetwork models can have millions of parameters, so neither approach is practical. Inshort, using gradient descent to find the global optimum of a high-dimensional lossfunction is challenging.","prefix":".6.2 Stochastic gradient descent","suffix":" We can find a minimum, but ther"}]}]}
>```
>%%
>*%%PREFIX%%.6.2 Stochastic gradient descent%%HIGHLIGHT%% ==The Gabor model has two parameters, so we could find the global minimum by either (i)exhaustively searching the parameter space or (ii) repeatedly starting gradient descentfrom different positions and choosing the result with the lowest loss. However, neuralnetwork models can have millions of parameters, so neither approach is practical. Inshort, using gradient descent to find the global optimum of a high-dimensional lossfunction is challenging.== %%POSTFIX%%We can find a minimum, but ther*
>%%LINK%%[[#^v1i1pvxod3p|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^v1i1pvxod3p


>%%
>```annotation-json
>{"created":"2024-10-08T13:11:37.064Z","updated":"2024-10-08T13:11:37.064Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":189123,"end":189186},{"type":"TextQuoteSelector","exact":"We can find a minimum, but there is no way to tell whether this","prefix":"al lossfunction is challenging. ","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%al lossfunction is challenging.%%HIGHLIGHT%% ==We can find a minimum, but there is no way to tell whether this== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^ine8tuz8i2a|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ine8tuz8i2a


>%%
>```annotation-json
>{"created":"2024-10-08T13:11:50.490Z","updated":"2024-10-08T13:11:50.490Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":190247,"end":190287},{"type":"TextQuoteSelector","exact":"is the global minimum or even a good one","prefix":"2 Stochastic gradient descent 85","suffix":".One of the main problems is tha"}]}]}
>```
>%%
>*%%PREFIX%%2 Stochastic gradient descent 85%%HIGHLIGHT%% ==is the global minimum or even a good one== %%POSTFIX%%.One of the main problems is tha*
>%%LINK%%[[#^1s1ord4ye21|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1s1ord4ye21


>%%
>```annotation-json
>{"created":"2024-10-08T13:12:23.912Z","updated":"2024-10-08T13:12:23.912Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":190288,"end":190910},{"type":"TextQuoteSelector","exact":"One of the main problems is that the final destination of a gradient descent algorithm Notebook 6.3Stochasticgradient descentis entirely determined by the starting point. Stochastic gradient descent (SGD) attemptsto remedy this problem by adding some noise to the gradient at each step. The solutionstill moves downhill on average, but at any given iteration, the direction chosen is notnecessarily in the steepest downhill direction. Indeed, it might not be downhill at all.The SGD algorithm has the possibility of moving temporarily uphill and hence jumpingfrom one “valley” of the loss function to another (figure 6.5b)","prefix":"obal minimum or even a good one.","suffix":".6.2.1 Batches and epochsThe mec"}]}]}
>```
>%%
>*%%PREFIX%%obal minimum or even a good one.%%HIGHLIGHT%% ==One of the main problems is that the final destination of a gradient descent algorithm Notebook 6.3Stochasticgradient descentis entirely determined by the starting point. Stochastic gradient descent (SGD) attemptsto remedy this problem by adding some noise to the gradient at each step. The solutionstill moves downhill on average, but at any given iteration, the direction chosen is notnecessarily in the steepest downhill direction. Indeed, it might not be downhill at all.The SGD algorithm has the possibility of moving temporarily uphill and hence jumpingfrom one “valley” of the loss function to another (figure 6.5b)== %%POSTFIX%%.6.2.1 Batches and epochsThe mec*
>%%LINK%%[[#^sahoi4e7w29|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^sahoi4e7w29


>%%
>```annotation-json
>{"created":"2024-10-08T13:14:19.408Z","text":"What are batches and epochs?","updated":"2024-10-08T13:14:19.408Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":190917,"end":190935},{"type":"TextQuoteSelector","exact":"Batches and epochs","prefix":" to another (figure 6.5b).6.2.1 ","suffix":"The mechanism for introducing ra"}]}]}
>```
>%%
>*%%PREFIX%%to another (figure 6.5b).6.2.1%%HIGHLIGHT%% ==Batches and epochs== %%POSTFIX%%The mechanism for introducing ra*
>%%LINK%%[[#^s2vobrl0qhg|show annotation]]
>%%COMMENT%%
>What are batches and epochs?
>%%TAGS%%
>#question
^s2vobrl0qhg


>%%
>```annotation-json
>{"created":"2024-10-08T13:19:18.732Z","updated":"2024-10-08T13:19:18.732Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":190935,"end":191269},{"type":"TextQuoteSelector","exact":"The mechanism for introducing randomness is simple. At each iteration, the algorithmchooses a random subset of the training data and computes the gradient from theseexamples alone. This subset is known as a minibatch or batch for short. The update rulefor the model parameters φt at iteration t is hence:φt+1 ←−φt −α · ∑i∈Bt∂ℓi[φt]∂φ ","prefix":"e 6.5b).6.2.1 Batches and epochs","suffix":", (6.10)where Bt is a set contai"}]}]}
>```
>%%
>*%%PREFIX%%e 6.5b).6.2.1 Batches and epochs%%HIGHLIGHT%% ==The mechanism for introducing randomness is simple. At each iteration, the algorithmchooses a random subset of the training data and computes the gradient from theseexamples alone. This subset is known as a minibatch or batch for short. The update rulefor the model parameters φt at iteration t is hence:φt+1 ←−φt −α · ∑i∈Bt∂ℓi[φt]∂φ== %%POSTFIX%%, (6.10)where Bt is a set contai*
>%%LINK%%[[#^kl7mqyw0rs|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kl7mqyw0rs


>%%
>```annotation-json
>{"created":"2024-10-08T13:21:01.635Z","updated":"2024-10-08T13:21:01.635Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":191277,"end":191654},{"type":"TextQuoteSelector","exact":"where Bt is a set containing the indices of the input/output pairs in the current batchand, as before, ℓi is the loss due to the ith pair. The term α is the learning rate, andtogether with the gradient magnitude, determines the distance moved at each iteration.The learning rate is chosen at the start of the procedure and does not depend on thelocal properties of the function","prefix":"−φt −α · ∑i∈Bt∂ℓi[φt]∂φ , (6.10)","suffix":".The batches are usually drawn f"}]}]}
>```
>%%
>*%%PREFIX%%−φt −α · ∑i∈Bt∂ℓi[φt]∂φ , (6.10)%%HIGHLIGHT%% ==where Bt is a set containing the indices of the input/output pairs in the current batchand, as before, ℓi is the loss due to the ith pair. The term α is the learning rate, andtogether with the gradient magnitude, determines the distance moved at each iteration.The learning rate is chosen at the start of the procedure and does not depend on thelocal properties of the function== %%POSTFIX%%.The batches are usually drawn f*
>%%LINK%%[[#^lt138ipkkdq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lt138ipkkdq


>%%
>```annotation-json
>{"created":"2024-10-08T13:22:04.304Z","text":"What is an epoch?","updated":"2024-10-08T13:22:04.304Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":191655,"end":192155},{"type":"TextQuoteSelector","exact":"The batches are usually drawn from the dataset without replacement. The algorithmworks through the training examples until it has used all the data, at which point it Problem 6.9starts sampling from the full training dataset again. A single pass through the entiretraining dataset is referred to as an epoch. A batch may be as small as a single exampleor as large as the whole dataset. The latter case is called full-batch gradient descent andis identical to regular (non-stochastic) gradient descent","prefix":"ocal properties of the function.","suffix":".An alternative interpretation o"}]}]}
>```
>%%
>*%%PREFIX%%ocal properties of the function.%%HIGHLIGHT%% ==The batches are usually drawn from the dataset without replacement. The algorithmworks through the training examples until it has used all the data, at which point it Problem 6.9starts sampling from the full training dataset again. A single pass through the entiretraining dataset is referred to as an epoch. A batch may be as small as a single exampleor as large as the whole dataset. The latter case is called full-batch gradient descent andis identical to regular (non-stochastic) gradient descent== %%POSTFIX%%.An alternative interpretation o*
>%%LINK%%[[#^0yqjli2587g|show annotation]]
>%%COMMENT%%
>What is an epoch?
>%%TAGS%%
>#question
^0yqjli2587g


>%%
>```annotation-json
>{"created":"2024-10-08T13:23:31.548Z","updated":"2024-10-08T13:23:31.548Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":192156,"end":192630},{"type":"TextQuoteSelector","exact":"An alternative interpretation of SGD is that it computes the gradient of a differentloss function at each iteration; the loss function depends on both the model and thetraining data and hence will differ for each randomly selected batch. In this view,SGD performs deterministic gradient descent on a constantly changing loss function(figure 6.6). However, despite this variability, the expected loss and expected gradientsat any point remain the same as for gradient descent","prefix":"on-stochastic) gradient descent.","suffix":".6.2.2 Properties of stochastic "}]}]}
>```
>%%
>*%%PREFIX%%on-stochastic) gradient descent.%%HIGHLIGHT%% ==An alternative interpretation of SGD is that it computes the gradient of a differentloss function at each iteration; the loss function depends on both the model and thetraining data and hence will differ for each randomly selected batch. In this view,SGD performs deterministic gradient descent on a constantly changing loss function(figure 6.6). However, despite this variability, the expected loss and expected gradientsat any point remain the same as for gradient descent== %%POSTFIX%%.6.2.2 Properties of stochastic*
>%%LINK%%[[#^4v4038w1lvv|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4v4038w1lvv


>%%
>```annotation-json
>{"created":"2024-10-08T13:24:19.964Z","text":"What are the properties of stochastic gradient descent?","updated":"2024-10-08T13:24:19.964Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":192637,"end":192678},{"type":"TextQuoteSelector","exact":"Properties of stochastic gradient descent","prefix":"e as for gradient descent.6.2.2 ","suffix":"SGD has several attractive featu"}]}]}
>```
>%%
>*%%PREFIX%%e as for gradient descent.6.2.2%%HIGHLIGHT%% ==Properties of stochastic gradient descent== %%POSTFIX%%SGD has several attractive featu*
>%%LINK%%[[#^c4sbzuraucp|show annotation]]
>%%COMMENT%%
>What are the properties of stochastic gradient descent?
>%%TAGS%%
>#question
^c4sbzuraucp


>%%
>```annotation-json
>{"created":"2024-10-08T13:24:54.777Z","updated":"2024-10-08T13:24:54.777Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":192678,"end":192898},{"type":"TextQuoteSelector","exact":"SGD has several attractive features. First, although it adds noise to the trajectory, itstill improves the fit to a subset of the data at each iteration. Hence, the updates tendto be sensible even if they are not optimal","prefix":"s of stochastic gradient descent","suffix":". Second, because it draws train"}]}]}
>```
>%%
>*%%PREFIX%%s of stochastic gradient descent%%HIGHLIGHT%% ==SGD has several attractive features. First, although it adds noise to the trajectory, itstill improves the fit to a subset of the data at each iteration. Hence, the updates tendto be sensible even if they are not optimal== %%POSTFIX%%. Second, because it draws train*
>%%LINK%%[[#^yctjb86sfg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yctjb86sfg


>%%
>```annotation-json
>{"created":"2024-10-08T13:25:05.183Z","updated":"2024-10-08T13:25:05.183Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":192901,"end":193045},{"type":"TextQuoteSelector","exact":"econd, because it draws training exampleswithout replacement and iterates through the dataset, the training examples all stillcontribute equally","prefix":" even if they are not optimal. S","suffix":". Third, it is less computationa"}]}]}
>```
>%%
>*%%PREFIX%%even if they are not optimal. S%%HIGHLIGHT%% ==econd, because it draws training exampleswithout replacement and iterates through the dataset, the training examples all stillcontribute equally== %%POSTFIX%%. Third, it is less computationa*
>%%LINK%%[[#^rkwmq7eeaya|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rkwmq7eeaya


>%%
>```annotation-json
>{"created":"2024-10-08T13:25:10.504Z","updated":"2024-10-08T13:25:10.504Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":193047,"end":193114},{"type":"TextQuoteSelector","exact":"Third, it is less computationally expensive to compute the gradient","prefix":"es all stillcontribute equally. ","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%es all stillcontribute equally.%%HIGHLIGHT%% ==Third, it is less computationally expensive to compute the gradient== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^e3kyv8hsnx9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^e3kyv8hsnx9


>%%
>```annotation-json
>{"created":"2024-10-08T13:25:18.919Z","updated":"2024-10-08T13:25:18.919Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":193184,"end":193223},{"type":"TextQuoteSelector","exact":"from just a subset of the training data","prefix":"il@gmail.com.86 6 Fitting models","suffix":". Fourth, it can (in principle) "}]}]}
>```
>%%
>*%%PREFIX%%il@gmail.com.86 6 Fitting models%%HIGHLIGHT%% ==from just a subset of the training data== %%POSTFIX%%. Fourth, it can (in principle)*
>%%LINK%%[[#^cd7wdaya9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^cd7wdaya9


>%%
>```annotation-json
>{"created":"2024-10-08T13:25:25.173Z","updated":"2024-10-08T13:25:25.173Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":193225,"end":193274},{"type":"TextQuoteSelector","exact":"Fourth, it can (in principle) escape local minima","prefix":" a subset of the training data. ","suffix":".Fifth, it reduces the chances o"}]}]}
>```
>%%
>*%%PREFIX%%a subset of the training data.%%HIGHLIGHT%% ==Fourth, it can (in principle) escape local minima== %%POSTFIX%%.Fifth, it reduces the chances o*
>%%LINK%%[[#^a7rqa1jtov6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^a7rqa1jtov6


>%%
>```annotation-json
>{"created":"2024-10-08T13:25:35.298Z","updated":"2024-10-08T13:25:35.298Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":193275,"end":193462},{"type":"TextQuoteSelector","exact":"Fifth, it reduces the chances of getting stuck near saddle points; it is likely that at leastsome of the possible batches will have a significant gradient at any point on the lossfunction","prefix":" principle) escape local minima.","suffix":". Finally, there is some evidenc"}]}]}
>```
>%%
>*%%PREFIX%%principle) escape local minima.%%HIGHLIGHT%% ==Fifth, it reduces the chances of getting stuck near saddle points; it is likely that at leastsome of the possible batches will have a significant gradient at any point on the lossfunction== %%POSTFIX%%. Finally, there is some evidenc*
>%%LINK%%[[#^w7vdllvbxy|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w7vdllvbxy


>%%
>```annotation-json
>{"created":"2024-10-08T13:25:51.233Z","updated":"2024-10-08T13:25:51.233Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":193464,"end":193617},{"type":"TextQuoteSelector","exact":"Finally, there is some evidence that SGD finds parameters for neural networksthat cause them to generalize well to new data in practice (see section 9.2)","prefix":" any point on the lossfunction. ","suffix":".SGD does not necessarily “conve"}]}]}
>```
>%%
>*%%PREFIX%%any point on the lossfunction.%%HIGHLIGHT%% ==Finally, there is some evidence that SGD finds parameters for neural networksthat cause them to generalize well to new data in practice (see section 9.2)== %%POSTFIX%%.SGD does not necessarily “conve*
>%%LINK%%[[#^yo1ntnf17mn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yo1ntnf17mn


>%%
>```annotation-json
>{"created":"2024-10-08T13:26:45.630Z","updated":"2024-10-08T13:26:45.630Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":193618,"end":193914},{"type":"TextQuoteSelector","exact":"SGD does not necessarily “converge” in the traditional sense. However, the hope isthat when we are close to the global minimum, all the data points will be well describedby the model. Consequently, the gradient will be small, whichever batch is chosen, andthe parameters will cease to change much","prefix":"a in practice (see section 9.2).","suffix":". In practice, SGD is often appl"}]}]}
>```
>%%
>*%%PREFIX%%a in practice (see section 9.2).%%HIGHLIGHT%% ==SGD does not necessarily “converge” in the traditional sense. However, the hope isthat when we are close to the global minimum, all the data points will be well describedby the model. Consequently, the gradient will be small, whichever batch is chosen, andthe parameters will cease to change much== %%POSTFIX%%. In practice, SGD is often appl*
>%%LINK%%[[#^9t1tue6govq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9t1tue6govq


>%%
>```annotation-json
>{"created":"2024-10-08T13:27:10.439Z","updated":"2024-10-08T13:27:10.439Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":193916,"end":194382},{"type":"TextQuoteSelector","exact":"In practice, SGD is often applied with alearning rate schedule. The learning rate α starts at a high value and is decreased by aconstant factor every N epochs. The logic is that in the early stages of training, we wantthe algorithm to explore the parameter space, jumping from valley to valley to find asensible region. In later stages, we are roughly in the right place and are more concernedwith fine-tuning the parameters, so we decrease α to make smaller changes","prefix":"ters will cease to change much. ","suffix":".6.3 MomentumA common modificati"}]}]}
>```
>%%
>*%%PREFIX%%ters will cease to change much.%%HIGHLIGHT%% ==In practice, SGD is often applied with alearning rate schedule. The learning rate α starts at a high value and is decreased by aconstant factor every N epochs. The logic is that in the early stages of training, we wantthe algorithm to explore the parameter space, jumping from valley to valley to find asensible region. In later stages, we are roughly in the right place and are more concernedwith fine-tuning the parameters, so we decrease α to make smaller changes== %%POSTFIX%%.6.3 MomentumA common modificati*
>%%LINK%%[[#^0fcrk8vf97qh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0fcrk8vf97qh


>%%
>```annotation-json
>{"created":"2024-10-08T13:27:25.075Z","text":"What is momentum?","updated":"2024-10-08T13:27:25.075Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":194387,"end":194395},{"type":"TextQuoteSelector","exact":"Momentum","prefix":"e α to make smaller changes.6.3 ","suffix":"A common modification to stochas"}]}]}
>```
>%%
>*%%PREFIX%%e α to make smaller changes.6.3%%HIGHLIGHT%% ==Momentum== %%POSTFIX%%A common modification to stochas*
>%%LINK%%[[#^tu1zlhxx1h|show annotation]]
>%%COMMENT%%
>What is momentum?
>%%TAGS%%
>#question
^tu1zlhxx1h


>%%
>```annotation-json
>{"created":"2024-10-08T13:28:47.791Z","updated":"2024-10-08T13:28:47.791Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":194395,"end":194673},{"type":"TextQuoteSelector","exact":"A common modification to stochastic gradient descent is to add a momentum term. Weupdate the parameters with a weighted combination of the gradient computed from thecurrent batch and the direction moved in the previous step:mt+1 ← β ·mt + (1 −β) ∑i∈Bt∂ℓi[φt]∂φφt+1 ← φt −α ·mt+1","prefix":"ake smaller changes.6.3 Momentum","suffix":", (6.11)where mt is the momentum"}]}]}
>```
>%%
>*%%PREFIX%%ake smaller changes.6.3 Momentum%%HIGHLIGHT%% ==A common modification to stochastic gradient descent is to add a momentum term. Weupdate the parameters with a weighted combination of the gradient computed from thecurrent batch and the direction moved in the previous step:mt+1 ← β ·mt + (1 −β) ∑i∈Bt∂ℓi[φt]∂φφt+1 ← φt −α ·mt+1== %%POSTFIX%%, (6.11)where mt is the momentum*
>%%LINK%%[[#^3oc0qfxx5w3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3oc0qfxx5w3


>%%
>```annotation-json
>{"created":"2024-10-08T13:29:09.360Z","updated":"2024-10-08T13:29:09.360Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":194681,"end":194847},{"type":"TextQuoteSelector","exact":"where mt is the momentum (which drives the update at iteration t), β ∈[0,1) controlsthe degree to which the gradient is smoothed over time, and α is the learning rate","prefix":"[φt]∂φφt+1 ← φt −α ·mt+1, (6.11)","suffix":".The recursive formulation of th"}]}]}
>```
>%%
>*%%PREFIX%%[φt]∂φφt+1 ← φt −α ·mt+1, (6.11)%%HIGHLIGHT%% ==where mt is the momentum (which drives the update at iteration t), β ∈[0,1) controlsthe degree to which the gradient is smoothed over time, and α is the learning rate== %%POSTFIX%%.The recursive formulation of th*
>%%LINK%%[[#^h37kfo942nf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^h37kfo942nf


>%%
>```annotation-json
>{"created":"2024-10-08T13:30:39.726Z","updated":"2024-10-08T13:30:39.726Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":194848,"end":195333},{"type":"TextQuoteSelector","exact":"The recursive formulation of the momentum calculation means that the gradient stepis an infinite weighted sum of all the previous gradients, where the weights get smalleras we move back in time. The effective learning rate increases if all these gradientsProblem 6.10 are aligned over multiple iterations but decreases if the gradient direction repeatedlychanges as the terms in the sum cancel out. The overall effect is a smoother trajectoryand reduced oscillatory behavior in valleys","prefix":"ime, and α is the learning rate.","suffix":" (figure 6.7).6.3.1 Nesterov acc"}]}]}
>```
>%%
>*%%PREFIX%%ime, and α is the learning rate.%%HIGHLIGHT%% ==The recursive formulation of the momentum calculation means that the gradient stepis an infinite weighted sum of all the previous gradients, where the weights get smalleras we move back in time. The effective learning rate increases if all these gradientsProblem 6.10 are aligned over multiple iterations but decreases if the gradient direction repeatedlychanges as the terms in the sum cancel out. The overall effect is a smoother trajectoryand reduced oscillatory behavior in valleys== %%POSTFIX%%(figure 6.7).6.3.1 Nesterov acc*
>%%LINK%%[[#^w6lz1pc7qfi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w6lz1pc7qfi


>%%
>```annotation-json
>{"created":"2024-10-08T13:32:27.963Z","text":"What is Nesterov accelerated momentum?","updated":"2024-10-08T13:32:27.963Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":195353,"end":195382},{"type":"TextQuoteSelector","exact":"Nesterov accelerated momentum","prefix":"r in valleys (figure 6.7).6.3.1 ","suffix":"The momentum term can be conside"}]}]}
>```
>%%
>*%%PREFIX%%r in valleys (figure 6.7).6.3.1%%HIGHLIGHT%% ==Nesterov accelerated momentum== %%POSTFIX%%The momentum term can be conside*
>%%LINK%%[[#^3oa2wqk2uax|show annotation]]
>%%COMMENT%%
>What is Nesterov accelerated momentum?
>%%TAGS%%
>#question
^3oa2wqk2uax


>%%
>```annotation-json
>{"created":"2024-10-08T13:33:00.926Z","updated":"2024-10-08T13:33:00.926Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":195382,"end":195622},{"type":"TextQuoteSelector","exact":"The momentum term can be considered a coarse prediction of where the SGD algorithmNotebook 6.4Momentum will move next. Nesterov accelerated momentum (figure 6.8) computes the gradients atthis predicted point rather than at the current point","prefix":".1 Nesterov accelerated momentum","suffix":":This work is subject to a Creat"}]}]}
>```
>%%
>*%%PREFIX%%.1 Nesterov accelerated momentum%%HIGHLIGHT%% ==The momentum term can be considered a coarse prediction of where the SGD algorithmNotebook 6.4Momentum will move next. Nesterov accelerated momentum (figure 6.8) computes the gradients atthis predicted point rather than at the current point== %%POSTFIX%%:This work is subject to a Creat*
>%%LINK%%[[#^0p1g41rkli7q|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0p1g41rkli7q


>%%
>```annotation-json
>{"created":"2024-10-08T13:38:15.206Z","updated":"2024-10-08T13:38:15.206Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":196653,"end":196715},{"type":"TextQuoteSelector","exact":"mt+1 ← β ·mt + (1 −β) ∑i∈Bt∂ℓi[φt −αβ ·mt]∂φφt+1 ← φt −α ·mt+1","prefix":"il@gmail.com.88 6 Fitting models","suffix":", (6.12)where now the gradients "}]}]}
>```
>%%
>*%%PREFIX%%il@gmail.com.88 6 Fitting models%%HIGHLIGHT%% ==mt+1 ← β ·mt + (1 −β) ∑i∈Bt∂ℓi[φt −αβ ·mt]∂φφt+1 ← φt −α ·mt+1== %%POSTFIX%%, (6.12)where now the gradients*
>%%LINK%%[[#^bgfsf9jymft|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bgfsf9jymft


>%%
>```annotation-json
>{"created":"2024-10-08T13:38:51.868Z","updated":"2024-10-08T13:38:51.868Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":196723,"end":196877},{"type":"TextQuoteSelector","exact":"where now the gradients are evaluated at φt −αβ ·mt. One way to think about this isthat the gradient term now corrects the path provided by momentum alone","prefix":"·mt]∂φφt+1 ← φt −α ·mt+1, (6.12)","suffix":".6.4 AdamGradient descent with a"}]}]}
>```
>%%
>*%%PREFIX%%·mt]∂φφt+1 ← φt −α ·mt+1, (6.12)%%HIGHLIGHT%% ==where now the gradients are evaluated at φt −αβ ·mt. One way to think about this isthat the gradient term now corrects the path provided by momentum alone== %%POSTFIX%%.6.4 AdamGradient descent with a*
>%%LINK%%[[#^xmkbi5osb0m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xmkbi5osb0m


>%%
>```annotation-json
>{"created":"2024-10-08T13:41:10.102Z","text":"What is adaptive moment estimation or Adam?","updated":"2024-10-08T13:41:10.102Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":196882,"end":196886},{"type":"TextQuoteSelector","exact":"Adam","prefix":" provided by momentum alone.6.4 ","suffix":"Gradient descent with a fixed st"}]}]}
>```
>%%
>*%%PREFIX%%provided by momentum alone.6.4%%HIGHLIGHT%% ==Adam== %%POSTFIX%%Gradient descent with a fixed st*
>%%LINK%%[[#^24bjs04ttjdh|show annotation]]
>%%COMMENT%%
>What is adaptive moment estimation or Adam?
>%%TAGS%%
>#question
^24bjs04ttjdh


>%%
>```annotation-json
>{"created":"2024-10-08T13:42:41.005Z","updated":"2024-10-08T13:42:41.005Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":196886,"end":197381},{"type":"TextQuoteSelector","exact":"Gradient descent with a fixed step size has the following undesirable property: it makeslarge adjustments to parameters associated with large gradients (where perhaps weshould be more cautious) and small adjustments to parameters associated with smallgradients (where perhaps we should explore further). When the gradient of the losssurface is much steeper in one direction than another, it is diﬀicult to choose a learningrate that (i) makes good progress in both directions and (ii) is stable ","prefix":"vided by momentum alone.6.4 Adam","suffix":"(figures 6.9a–b).A straightforwa"}]}]}
>```
>%%
>*%%PREFIX%%vided by momentum alone.6.4 Adam%%HIGHLIGHT%% ==Gradient descent with a fixed step size has the following undesirable property: it makeslarge adjustments to parameters associated with large gradients (where perhaps weshould be more cautious) and small adjustments to parameters associated with smallgradients (where perhaps we should explore further). When the gradient of the losssurface is much steeper in one direction than another, it is diﬀicult to choose a learningrate that (i) makes good progress in both directions and (ii) is stable== %%POSTFIX%%(figures 6.9a–b).A straightforwa*
>%%LINK%%[[#^bns779yvwhf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bns779yvwhf


>%%
>```annotation-json
>{"created":"2024-10-08T13:42:57.230Z","updated":"2024-10-08T13:42:57.230Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":197398,"end":197623},{"type":"TextQuoteSelector","exact":"A straightforward approach is to normalize the gradients so that we move a fixeddistance (governed by the learning rate) in each direction. To do this, we first measurethe gradient mt+1 and the pointwise squared gradient vt+1","prefix":"(ii) is stable (figures 6.9a–b).","suffix":":mt+1 ← ∂L[φt]∂φvt+1 ←(∂L[φt]∂φ)"}]}]}
>```
>%%
>*%%PREFIX%%(ii) is stable (figures 6.9a–b).%%HIGHLIGHT%% ==A straightforward approach is to normalize the gradients so that we move a fixeddistance (governed by the learning rate) in each direction. To do this, we first measurethe gradient mt+1 and the pointwise squared gradient vt+1== %%POSTFIX%%:mt+1 ← ∂L[φt]∂φvt+1 ←(∂L[φt]∂φ)*
>%%LINK%%[[#^tcairz6cwuc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tcairz6cwuc


>%%
>```annotation-json
>{"created":"2024-10-08T13:43:22.466Z","updated":"2024-10-08T13:43:22.466Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":197624,"end":197656},{"type":"TextQuoteSelector","exact":"mt+1 ← ∂L[φt]∂φvt+1 ←(∂L[φt]∂φ)2","prefix":"pointwise squared gradient vt+1:","suffix":". (6.13)Then we apply the update"}]}]}
>```
>%%
>*%%PREFIX%%pointwise squared gradient vt+1:%%HIGHLIGHT%% ==mt+1 ← ∂L[φt]∂φvt+1 ←(∂L[φt]∂φ)2== %%POSTFIX%%. (6.13)Then we apply the update*
>%%LINK%%[[#^2k0ato834c9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2k0ato834c9


>%%
>```annotation-json
>{"created":"2024-10-08T13:43:54.152Z","updated":"2024-10-08T13:43:54.152Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":197664,"end":197722},{"type":"TextQuoteSelector","exact":"Then we apply the update rule:φt+1 ← φt −α · mt+1√vt+1 + ε","prefix":"L[φt]∂φvt+1 ←(∂L[φt]∂φ)2. (6.13)","suffix":", (6.14)where the square root an"}]}]}
>```
>%%
>*%%PREFIX%%L[φt]∂φvt+1 ←(∂L[φt]∂φ)2. (6.13)%%HIGHLIGHT%% ==Then we apply the update rule:φt+1 ← φt −α · mt+1√vt+1 + ε== %%POSTFIX%%, (6.14)where the square root an*
>%%LINK%%[[#^0pemcz4zfpa|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^0pemcz4zfpa


>%%
>```annotation-json
>{"created":"2024-10-08T13:47:11.709Z","updated":"2024-10-08T13:47:11.709Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":197730,"end":198419},{"type":"TextQuoteSelector","exact":"where the square root and division are both pointwise, α is the learning rate, and ε is asmall constant that prevents division by zero when the gradient magnitude is zero. Theterm vt+1 is the squared gradient, and the positive root of this is used to normalize thegradient itself, so all that remains is the sign in each coordinate direction. The result isthat the algorithm moves a fixed distance α along each coordinate, where the directionis determined by whichever way is downhill (figure 6.9c). This simple algorithm makesgood progress in both directions but will not converge unless it happens to land exactlyat the minimum. Instead, it will bounce back and forth around the minimum.","prefix":" ← φt −α · mt+1√vt+1 + ε, (6.14)","suffix":"Adaptive moment estimation, or A"}]}]}
>```
>%%
>*%%PREFIX%%← φt −α · mt+1√vt+1 + ε, (6.14)%%HIGHLIGHT%% ==where the square root and division are both pointwise, α is the learning rate, and ε is asmall constant that prevents division by zero when the gradient magnitude is zero. Theterm vt+1 is the squared gradient, and the positive root of this is used to normalize thegradient itself, so all that remains is the sign in each coordinate direction. The result isthat the algorithm moves a fixed distance α along each coordinate, where the directionis determined by whichever way is downhill (figure 6.9c). This simple algorithm makesgood progress in both directions but will not converge unless it happens to land exactlyat the minimum. Instead, it will bounce back and forth around the minimum.== %%POSTFIX%%Adaptive moment estimation, or A*
>%%LINK%%[[#^odoqe7ghuod|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^odoqe7ghuod


>%%
>```annotation-json
>{"created":"2024-10-08T13:48:08.979Z","updated":"2024-10-08T13:48:08.979Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":198419,"end":198551},{"type":"TextQuoteSelector","exact":"Adaptive moment estimation, or Adam, takes this idea and adds momentum to boththe estimate of the gradient and the squared gradient:","prefix":"ck and forth around the minimum.","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%ck and forth around the minimum.%%HIGHLIGHT%% ==Adaptive moment estimation, or Adam, takes this idea and adds momentum to boththe estimate of the gradient and the squared gradient:== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^kcgf9lnldsq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kcgf9lnldsq


>%%
>```annotation-json
>{"created":"2024-10-08T13:49:56.833Z","updated":"2024-10-08T13:49:56.833Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":199697,"end":199759},{"type":"TextQuoteSelector","exact":"mt+1 ← β ·mt + (1 −β)∂L[φt]∂φvt+1 ← γ ·vt + (1 −γ)(∂L[φt]∂φ)2,","prefix":"il@gmail.com.90 6 Fitting models","suffix":" (6.15)where β and γ are the mom"}]}]}
>```
>%%
>*%%PREFIX%%il@gmail.com.90 6 Fitting models%%HIGHLIGHT%% ==mt+1 ← β ·mt + (1 −β)∂L[φt]∂φvt+1 ← γ ·vt + (1 −γ)(∂L[φt]∂φ)2,== %%POSTFIX%%(6.15)where β and γ are the mom*
>%%LINK%%[[#^akfpunwou8w|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^akfpunwou8w


>%%
>```annotation-json
>{"created":"2024-10-08T13:50:16.565Z","updated":"2024-10-08T13:50:16.565Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":199766,"end":199831},{"type":"TextQuoteSelector","exact":"where β and γ are the momentum coeﬀicients for the two statistics","prefix":" ·vt + (1 −γ)(∂L[φt]∂φ)2, (6.15)","suffix":".Using momentum is equivalent to"}]}]}
>```
>%%
>*%%PREFIX%%·vt + (1 −γ)(∂L[φt]∂φ)2, (6.15)%%HIGHLIGHT%% ==where β and γ are the momentum coeﬀicients for the two statistics== %%POSTFIX%%.Using momentum is equivalent to*
>%%LINK%%[[#^qhgc8p5n0y|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qhgc8p5n0y


>%%
>```annotation-json
>{"created":"2024-10-08T13:50:39.955Z","updated":"2024-10-08T13:50:39.955Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":199832,"end":200156},{"type":"TextQuoteSelector","exact":"Using momentum is equivalent to taking a weighted average over the history of eachof these statistics. At the start of the procedure, all the previous measurements areeffectively zero, resulting in unrealistically small estimates. Consequently, we modifythese statistics using the rule: ̃mt+1 ←mt+11 −βt+1 ̃vt+1 ←vt+11 −γt+1","prefix":"ﬀicients for the two statistics.","suffix":" . (6.16)Since β and γ are in th"}]}]}
>```
>%%
>*%%PREFIX%%ﬀicients for the two statistics.%%HIGHLIGHT%% ==Using momentum is equivalent to taking a weighted average over the history of eachof these statistics. At the start of the procedure, all the previous measurements areeffectively zero, resulting in unrealistically small estimates. Consequently, we modifythese statistics using the rule: ̃mt+1 ←mt+11 −βt+1 ̃vt+1 ←vt+11 −γt+1== %%POSTFIX%%. (6.16)Since β and γ are in th*
>%%LINK%%[[#^huo8u0k2phm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^huo8u0k2phm


>%%
>```annotation-json
>{"created":"2024-10-08T13:51:04.669Z","updated":"2024-10-08T13:51:04.669Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":200165,"end":200351},{"type":"TextQuoteSelector","exact":"Since β and γ are in the range [0,1), the terms with exponents t+1 become smallerwith each time step, the denominators become closer to one, and this modification hasa diminishing effect","prefix":"βt+1 ̃vt+1 ←vt+11 −γt+1 . (6.16)","suffix":".Finally, we update the paramete"}]}]}
>```
>%%
>*%%PREFIX%%βt+1 ̃vt+1 ←vt+11 −γt+1 . (6.16)%%HIGHLIGHT%% ==Since β and γ are in the range [0,1), the terms with exponents t+1 become smallerwith each time step, the denominators become closer to one, and this modification hasa diminishing effect== %%POSTFIX%%.Finally, we update the paramete*
>%%LINK%%[[#^o5j7hjf5r5m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^o5j7hjf5r5m


>%%
>```annotation-json
>{"created":"2024-10-08T13:51:45.575Z","updated":"2024-10-08T13:51:45.575Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":200352,"end":200458},{"type":"TextQuoteSelector","exact":"Finally, we update the parameters as before, but with the modified terms:φt+1 ← φt −α ·  ̃mt+1√ ̃vt+1 + ε.","prefix":"ication hasa diminishing effect.","suffix":" (6.17)The result is an algorith"}]}]}
>```
>%%
>*%%PREFIX%%ication hasa diminishing effect.%%HIGHLIGHT%% ==Finally, we update the parameters as before, but with the modified terms:φt+1 ← φt −α ·  ̃mt+1√ ̃vt+1 + ε.== %%POSTFIX%%(6.17)The result is an algorith*
>%%LINK%%[[#^vdg0c4qkb7o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vdg0c4qkb7o


>%%
>```annotation-json
>{"created":"2024-10-08T13:52:09.842Z","updated":"2024-10-08T13:52:09.842Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":200465,"end":200813},{"type":"TextQuoteSelector","exact":"The result is an algorithm that can converge to the overall minimum and makes goodNotebook 6.5Adam progress in every direction in the parameter space. Note that Adam is usually used in astochastic setting where the gradients and their squares are computed from mini-batches:mt+1 ← β ·mt + (1 −β) ∑i∈Bt∂ℓi[φt]∂φvt+1 ← γ ·vt + (1 −γ)(∑i∈Bt∂ℓi[φt]∂φ)2","prefix":"t −α ·  ̃mt+1√ ̃vt+1 + ε. (6.17)","suffix":", (6.18)and so the trajectory is"}]}]}
>```
>%%
>*%%PREFIX%%t −α ·  ̃mt+1√ ̃vt+1 + ε. (6.17)%%HIGHLIGHT%% ==The result is an algorithm that can converge to the overall minimum and makes goodNotebook 6.5Adam progress in every direction in the parameter space. Note that Adam is usually used in astochastic setting where the gradients and their squares are computed from mini-batches:mt+1 ← β ·mt + (1 −β) ∑i∈Bt∂ℓi[φt]∂φvt+1 ← γ ·vt + (1 −γ)(∑i∈Bt∂ℓi[φt]∂φ)2== %%POSTFIX%%, (6.18)and so the trajectory is*
>%%LINK%%[[#^7jr83xi4v3o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7jr83xi4v3o


>%%
>```annotation-json
>{"created":"2024-10-08T13:52:49.433Z","updated":"2024-10-08T13:52:49.433Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":200821,"end":200863},{"type":"TextQuoteSelector","exact":"and so the trajectory is noisy in practice","prefix":" (1 −γ)(∑i∈Bt∂ℓi[φt]∂φ)2, (6.18)","suffix":".As we shall see in chapter 7, t"}]}]}
>```
>%%
>*%%PREFIX%%(1 −γ)(∑i∈Bt∂ℓi[φt]∂φ)2, (6.18)%%HIGHLIGHT%% ==and so the trajectory is noisy in practice== %%POSTFIX%%.As we shall see in chapter 7, t*
>%%LINK%%[[#^5s165j2rzu5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5s165j2rzu5


>%%
>```annotation-json
>{"created":"2024-10-08T13:54:20.936Z","updated":"2024-10-08T13:54:20.936Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":200864,"end":201283},{"type":"TextQuoteSelector","exact":"As we shall see in chapter 7, the gradient magnitudes of neural network parameterscan depend on their depth in the network. Adam helps compensate for this tendencyand balances out changes across the different layers. In practice, Adam also has theadvantage of being less sensitive to the initial learning rate because it avoids situationslike those in figures 6.9a–b, so it doesn’t need complex learning rate schedules.","prefix":"trajectory is noisy in practice.","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%trajectory is noisy in practice.%%HIGHLIGHT%% ==As we shall see in chapter 7, the gradient magnitudes of neural network parameterscan depend on their depth in the network. Adam helps compensate for this tendencyand balances out changes across the different layers. In practice, Adam also has theadvantage of being less sensitive to the initial learning rate because it avoids situationslike those in figures 6.9a–b, so it doesn’t need complex learning rate schedules.== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^osz85jgr7dm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^osz85jgr7dm


>%%
>```annotation-json
>{"created":"2024-10-08T13:56:59.690Z","text":"What are training algorithm hyperparameters?","updated":"2024-10-08T13:56:59.690Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":201406,"end":201440},{"type":"TextQuoteSelector","exact":"Training algorithm hyperparameters","prefix":"algorithm hyperparameters 916.5 ","suffix":"The choices of learning algorith"}]}]}
>```
>%%
>*%%PREFIX%%algorithm hyperparameters 916.5%%HIGHLIGHT%% ==Training algorithm hyperparameters== %%POSTFIX%%The choices of learning algorith*
>%%LINK%%[[#^ce0cvl8zsul|show annotation]]
>%%COMMENT%%
>What are training algorithm hyperparameters?
>%%TAGS%%
>#question
^ce0cvl8zsul


>%%
>```annotation-json
>{"created":"2024-10-08T13:58:01.046Z","updated":"2024-10-08T13:58:01.046Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":201440,"end":201865},{"type":"TextQuoteSelector","exact":"The choices of learning algorithm, batch size, learning rate schedule, and momentumcoeﬀicients are all considered hyperparameters of the training algorithm; these directlyaffect the final model performance but are distinct from the model parameters. Choosingthese can be more art than science, and it’s common to train many models with differenthyperparameters and choose the best one. This is known as hyperparameter search.","prefix":"aining algorithm hyperparameters","suffix":" Wereturn to this issue in chapt"}]}]}
>```
>%%
>*%%PREFIX%%aining algorithm hyperparameters%%HIGHLIGHT%% ==The choices of learning algorithm, batch size, learning rate schedule, and momentumcoeﬀicients are all considered hyperparameters of the training algorithm; these directlyaffect the final model performance but are distinct from the model parameters. Choosingthese can be more art than science, and it’s common to train many models with differenthyperparameters and choose the best one. This is known as hyperparameter search.== %%POSTFIX%%Wereturn to this issue in chapt*
>%%LINK%%[[#^48gurvz5l92|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^48gurvz5l92


>%%
>```annotation-json
>{"created":"2024-10-08T14:00:33.318Z","updated":"2024-10-08T14:00:33.318Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":204544,"end":204580},{"type":"TextQuoteSelector","exact":"Convexity, minima, and saddle points","prefix":"il@gmail.com.92 6 Fitting models","suffix":": A function is convex if no cho"}]}]}
>```
>%%
>*%%PREFIX%%il@gmail.com.92 6 Fitting models%%HIGHLIGHT%% ==Convexity, minima, and saddle points== %%POSTFIX%%: A function is convex if no cho*
>%%LINK%%[[#^fckjrqte0te|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^fckjrqte0te


>%%
>```annotation-json
>{"created":"2024-10-08T14:01:38.419Z","updated":"2024-10-08T14:01:38.419Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":205664,"end":205675},{"type":"TextQuoteSelector","exact":"Line search","prefix":"tionswhere we are at a maximum).","suffix":": Gradient descent with a fixed "}]}]}
>```
>%%
>*%%PREFIX%%tionswhere we are at a maximum).%%HIGHLIGHT%% ==Line search== %%POSTFIX%%: Gradient descent with a fixed*
>%%LINK%%[[#^xk0hxzqbme|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xk0hxzqbme


>%%
>```annotation-json
>{"created":"2024-10-08T14:02:56.680Z","updated":"2024-10-08T14:02:56.680Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":206395,"end":206418},{"type":"TextQuoteSelector","exact":"Beyond gradient descent","prefix":"s (e.g., path 1 in figure 6.5a).","suffix":": Numerous algorithms have been "}]}]}
>```
>%%
>*%%PREFIX%%s (e.g., path 1 in figure 6.5a).%%HIGHLIGHT%% ==Beyond gradient descent== %%POSTFIX%%: Numerous algorithms have been*
>%%LINK%%[[#^9bg4af4u68|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9bg4af4u68


>%%
>```annotation-json
>{"created":"2024-10-08T14:03:19.939Z","updated":"2024-10-08T14:03:19.939Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":206527,"end":206540},{"type":"TextQuoteSelector","exact":"Newton method","prefix":"nt descent. Most notable is the ","suffix":", which takes the curvature of t"}]}]}
>```
>%%
>*%%PREFIX%%nt descent. Most notable is the%%HIGHLIGHT%% ==Newton method== %%POSTFIX%%, which takes the curvature of t*
>%%LINK%%[[#^a2jvwvu35lu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^a2jvwvu35lu


>%%
>```annotation-json
>{"created":"2024-10-08T14:03:54.838Z","updated":"2024-10-08T14:03:54.838Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":204739,"end":204788},{"type":"TextQuoteSelector","exact":"Hessian matrix (the matrix of second derivatives)","prefix":"algebraically byconsidering the ","suffix":":H[φ] =∂2L∂φ20∂2L∂φ0∂φ1 "}]}]}
>```
>%%
>*%%PREFIX%%algebraically byconsidering the%%HIGHLIGHT%% ==Hessian matrix (the matrix of second derivatives)== %%POSTFIX%%:H[φ] =∂2L∂φ20∂2L∂φ0∂φ1*
>%%LINK%%[[#^n06crbk1sr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^n06crbk1sr


>%%
>```annotation-json
>{"created":"2024-10-08T14:04:04.534Z","updated":"2024-10-08T14:04:04.534Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":207146,"end":207163},{"type":"TextQuoteSelector","exact":"Properties of SGD","prefix":"is large, as in neural networks.","suffix":": The limit of SGD as the learni"}]}]}
>```
>%%
>*%%PREFIX%%is large, as in neural networks.%%HIGHLIGHT%% ==Properties of SGD== %%POSTFIX%%: The limit of SGD as the learni*
>%%LINK%%[[#^a7qdztnohuc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^a7qdztnohuc


>%%
>```annotation-json
>{"created":"2024-10-08T14:04:42.929Z","updated":"2024-10-08T14:04:42.929Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":208116,"end":208124},{"type":"TextQuoteSelector","exact":"Momentum","prefix":"eneralization(see figure 20.10).","suffix":": The idea of using momentum to "}]}]}
>```
>%%
>*%%PREFIX%%eneralization(see figure 20.10).%%HIGHLIGHT%% ==Momentum== %%POSTFIX%%: The idea of using momentum to*
>%%LINK%%[[#^9gi3wv17rrl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9gi3wv17rrl


>%%
>```annotation-json
>{"created":"2024-10-08T14:05:47.608Z","updated":"2024-10-08T14:05:47.608Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":209050,"end":209078},{"type":"TextQuoteSelector","exact":"Adaptive training algorithms","prefix":"cent by Sutskever et al. (2013).","suffix":": AdaGrad (Duchi et al., 2011) i"}]}]}
>```
>%%
>*%%PREFIX%%cent by Sutskever et al. (2013).%%HIGHLIGHT%% ==Adaptive training algorithms== %%POSTFIX%%: AdaGrad (Duchi et al., 2011) i*
>%%LINK%%[[#^6osqot01ioc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6osqot01ioc


>%%
>```annotation-json
>{"created":"2024-10-08T14:07:36.504Z","updated":"2024-10-08T14:07:36.504Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":211320,"end":211332},{"type":"TextQuoteSelector","exact":"SGD vs. Adam","prefix":"omentum into the Adam algorithm.","suffix":": There has been a lively discus"}]}]}
>```
>%%
>*%%PREFIX%%omentum into the Adam algorithm.%%HIGHLIGHT%% ==SGD vs. Adam== %%POSTFIX%%: There has been a lively discus*
>%%LINK%%[[#^91a7gmquza4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^91a7gmquza4


>%%
>```annotation-json
>{"created":"2024-10-08T14:08:25.744Z","updated":"2024-10-08T14:08:25.744Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":212291,"end":212308},{"type":"TextQuoteSelector","exact":"Exhaustive search","prefix":"nal generalization performance).","suffix":": All the algorithms discussed i"}]}]}
>```
>%%
>*%%PREFIX%%nal generalization performance).%%HIGHLIGHT%% ==Exhaustive search== %%POSTFIX%%: All the algorithms discussed i*
>%%LINK%%[[#^1q1qvnu718m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1q1qvnu718m


>%%
>```annotation-json
>{"created":"2024-10-08T15:49:13.778Z","updated":"2024-10-08T15:49:13.778Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":216742,"end":217207},{"type":"TextQuoteSelector","exact":"First, weconsider how to calculate the gradients eﬀiciently. This is a serious challenge since thelargest models at the time of writing have ∼1012 parameters, and the gradient needs tobe computed for every parameter at every iteration of the training algorithm. Second,we consider how to initialize the parameters. If this is not done carefully, the initiallosses and their gradients can be extremely large or small. In either case, this impedesthe training process","prefix":"re specific to neural networks. ","suffix":".7.1 Problem definitionsConsider"}]}]}
>```
>%%
>*%%PREFIX%%re specific to neural networks.%%HIGHLIGHT%% ==First, weconsider how to calculate the gradients eﬀiciently. This is a serious challenge since thelargest models at the time of writing have ∼1012 parameters, and the gradient needs tobe computed for every parameter at every iteration of the training algorithm. Second,we consider how to initialize the parameters. If this is not done carefully, the initiallosses and their gradients can be extremely large or small. In either case, this impedesthe training process== %%POSTFIX%%.7.1 Problem definitionsConsider*
>%%LINK%%[[#^sb2espno6b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^sb2espno6b


>%%
>```annotation-json
>{"created":"2024-10-08T15:50:23.108Z","updated":"2024-10-08T15:50:23.108Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":217231,"end":217631},{"type":"TextQuoteSelector","exact":"Consider a network f[x,φ] with multivariate input x, parameters φ, and three hiddenlayers h1,h2, and h3:h1 = a[β0 + Ω0x]h2 = a[β1 + Ω1h1]h3 = a[β2 + Ω2h2]f[x,φ] = β3 + Ω3h3, (7.1)where the function a[•] applies the activation function separately to every element of theinput. The model parameters φ = {β0,Ω0,β1,Ω1,β2,Ω2,β3,Ω3} consist of the biasvectors βk and weight matrices Ωk between every layer ","prefix":" process.7.1 Problem definitions","suffix":"(figure 7.1).This work is subjec"}]}]}
>```
>%%
>*%%PREFIX%%process.7.1 Problem definitions%%HIGHLIGHT%% ==Consider a network f[x,φ] with multivariate input x, parameters φ, and three hiddenlayers h1,h2, and h3:h1 = a[β0 + Ω0x]h2 = a[β1 + Ω1h1]h3 = a[β2 + Ω2h2]f[x,φ] = β3 + Ω3h3, (7.1)where the function a[•] applies the activation function separately to every element of theinput. The model parameters φ = {β0,Ω0,β1,Ω1,β2,Ω2,β3,Ω3} consist of the biasvectors βk and weight matrices Ωk between every layer== %%POSTFIX%%(figure 7.1).This work is subjec*
>%%LINK%%[[#^i7gxjpgsr2r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^i7gxjpgsr2r


>%%
>```annotation-json
>{"created":"2024-10-08T15:51:21.266Z","updated":"2024-10-08T15:51:21.266Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":217750,"end":218060},{"type":"TextQuoteSelector","exact":"We also have individual loss terms ℓi, which return the negative log-likelihood ofthe ground truth label yi given the model prediction f[xi,φ] for training input xi. Forexample, this might be the least squares loss ℓi = (f[xi,φ] −yi)2. The total loss is thesum of these terms over the training data:L[φ] =I∑i=1","prefix":"ess.7.2 Computing derivatives 97","suffix":"ℓi. (7.2)The most commonly used "}]}]}
>```
>%%
>*%%PREFIX%%ess.7.2 Computing derivatives 97%%HIGHLIGHT%% ==We also have individual loss terms ℓi, which return the negative log-likelihood ofthe ground truth label yi given the model prediction f[xi,φ] for training input xi. Forexample, this might be the least squares loss ℓi = (f[xi,φ] −yi)2. The total loss is thesum of these terms over the training data:L[φ] =I∑i=1== %%POSTFIX%%ℓi. (7.2)The most commonly used*
>%%LINK%%[[#^4iqtwji77pn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4iqtwji77pn


>%%
>```annotation-json
>{"created":"2024-10-08T15:51:51.961Z","updated":"2024-10-08T15:51:51.961Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":218069,"end":218404},{"type":"TextQuoteSelector","exact":"The most commonly used optimization algorithm for training neural networks isstochastic gradient descent (SGD), which updates the parameters as:φt+1 ←−φt −α ∑i∈Bt∂ℓi[φt]∂φ , (7.3)where α is the learning rate, and Bt contains the batch indices at iteration t. To computethis update, we need to calculate the derivatives:∂ℓi∂βkand ∂ℓi∂Ωk","prefix":"aining data:L[φ] =I∑i=1ℓi. (7.2)","suffix":", (7.4)for the parameters {βk,Ωk"}]}]}
>```
>%%
>*%%PREFIX%%aining data:L[φ] =I∑i=1ℓi. (7.2)%%HIGHLIGHT%% ==The most commonly used optimization algorithm for training neural networks isstochastic gradient descent (SGD), which updates the parameters as:φt+1 ←−φt −α ∑i∈Bt∂ℓi[φt]∂φ , (7.3)where α is the learning rate, and Bt contains the batch indices at iteration t. To computethis update, we need to calculate the derivatives:∂ℓi∂βkand ∂ℓi∂Ωk== %%POSTFIX%%, (7.4)for the parameters {βk,Ωk*
>%%LINK%%[[#^ly9cjdqptqc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ly9cjdqptqc


>%%
>```annotation-json
>{"created":"2024-10-08T15:52:44.860Z","updated":"2024-10-08T15:52:44.860Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":218411,"end":218838},{"type":"TextQuoteSelector","exact":"for the parameters {βk,Ωk} at every layer k ∈ {0,1,...,K} and for each index i in Problem 7.1the batch. The first part of this chapter describes the backpropagation algorithm, whichcomputes these derivatives eﬀiciently.In the second part of the chapter, we consider how to initialize the network parametersbefore we commence training. We describe methods to choose the initial weights Ωk andbiases βk so that training is stable","prefix":"ivatives:∂ℓi∂βkand ∂ℓi∂Ωk, (7.4)","suffix":".7.2 Computing derivativesThe de"}]}]}
>```
>%%
>*%%PREFIX%%ivatives:∂ℓi∂βkand ∂ℓi∂Ωk, (7.4)%%HIGHLIGHT%% ==for the parameters {βk,Ωk} at every layer k ∈ {0,1,...,K} and for each index i in Problem 7.1the batch. The first part of this chapter describes the backpropagation algorithm, whichcomputes these derivatives eﬀiciently.In the second part of the chapter, we consider how to initialize the network parametersbefore we commence training. We describe methods to choose the initial weights Ωk andbiases βk so that training is stable== %%POSTFIX%%.7.2 Computing derivativesThe de*
>%%LINK%%[[#^t8xm9sevddf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^t8xm9sevddf


>%%
>```annotation-json
>{"created":"2024-10-08T15:53:08.531Z","text":"How do you compute derivatives? ","updated":"2024-10-08T15:53:08.531Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":218843,"end":218864},{"type":"TextQuoteSelector","exact":"Computing derivatives","prefix":" so that training is stable.7.2 ","suffix":"The derivatives of the loss tell"}]}]}
>```
>%%
>*%%PREFIX%%so that training is stable.7.2%%HIGHLIGHT%% ==Computing derivatives== %%POSTFIX%%The derivatives of the loss tell*
>%%LINK%%[[#^5gcbxr993ps|show annotation]]
>%%COMMENT%%
>How do you compute derivatives? 
>%%TAGS%%
>#question
^5gcbxr993ps


>%%
>```annotation-json
>{"created":"2024-10-08T15:53:45.788Z","updated":"2024-10-08T15:53:45.788Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":218864,"end":219243},{"type":"TextQuoteSelector","exact":"The derivatives of the loss tell us how the loss changes when we make a small changeto the parameters. Optimization algorithms exploit this information to manipulate theparameters so that the loss becomes smaller. The backpropagation algorithm computesthese derivatives. The mathematical details are somewhat involved, so we first make twoobservations that provide some intuition","prefix":"stable.7.2 Computing derivatives","suffix":".Observation 1: Each weight (ele"}]}]}
>```
>%%
>*%%PREFIX%%stable.7.2 Computing derivatives%%HIGHLIGHT%% ==The derivatives of the loss tell us how the loss changes when we make a small changeto the parameters. Optimization algorithms exploit this information to manipulate theparameters so that the loss becomes smaller. The backpropagation algorithm computesthese derivatives. The mathematical details are somewhat involved, so we first make twoobservations that provide some intuition== %%POSTFIX%%.Observation 1: Each weight (ele*
>%%LINK%%[[#^1qqioujfql|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1qqioujfql


>%%
>```annotation-json
>{"created":"2024-10-08T15:54:34.995Z","updated":"2024-10-08T15:54:34.995Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":219244,"end":219767},{"type":"TextQuoteSelector","exact":"Observation 1: Each weight (element of Ωk) multiplies the activation at a source hiddenunit and adds the result to a destination hidden unit in the next layer. It follows that theeffect of any small change to the weight is amplified or attenuated by the activation atthe source hidden unit. Hence, we run the network for each data example in the batchand store the activations of all the hidden units. This is known as the forward pass(figure 7.1). The stored activations will subsequently be used to compute the gradients.","prefix":"ons that provide some intuition.","suffix":"Observation 2: A small change in"}]}]}
>```
>%%
>*%%PREFIX%%ons that provide some intuition.%%HIGHLIGHT%% ==Observation 1: Each weight (element of Ωk) multiplies the activation at a source hiddenunit and adds the result to a destination hidden unit in the next layer. It follows that theeffect of any small change to the weight is amplified or attenuated by the activation atthe source hidden unit. Hence, we run the network for each data example in the batchand store the activations of all the hidden units. This is known as the forward pass(figure 7.1). The stored activations will subsequently be used to compute the gradients.== %%POSTFIX%%Observation 2: A small change in*
>%%LINK%%[[#^enqwtn1avkb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^enqwtn1avkb


>%%
>```annotation-json
>{"created":"2024-10-08T15:55:28.733Z","updated":"2024-10-08T15:55:28.733Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":219767,"end":219937},{"type":"TextQuoteSelector","exact":"Observation 2: A small change in a bias or weight causes a ripple effect of changesthrough the subsequent network. The change modifies the value of its destination hidden","prefix":"e used to compute the gradients.","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%e used to compute the gradients.%%HIGHLIGHT%% ==Observation 2: A small change in a bias or weight causes a ripple effect of changesthrough the subsequent network. The change modifies the value of its destination hidden== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^st4d9q3wfqn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^st4d9q3wfqn


>%%
>```annotation-json
>{"created":"2024-10-08T15:55:48.449Z","updated":"2024-10-08T15:55:48.449Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":220906,"end":221125},{"type":"TextQuoteSelector","exact":"unit. This, in turn, changes the values of the hidden units in the subsequent layer, whichwill change the hidden units in the layer after that, and so on, until a change is made tothe model output and, finally, the loss","prefix":" network equations sequentially.","suffix":".Hence, to know how changing a p"}]}]}
>```
>%%
>*%%PREFIX%%network equations sequentially.%%HIGHLIGHT%% ==unit. This, in turn, changes the values of the hidden units in the subsequent layer, whichwill change the hidden units in the layer after that, and so on, until a change is made tothe model output and, finally, the loss== %%POSTFIX%%.Hence, to know how changing a p*
>%%LINK%%[[#^58pq6idjsdc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^58pq6idjsdc


>%%
>```annotation-json
>{"created":"2024-10-08T15:58:18.092Z","updated":"2024-10-08T15:58:18.092Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":221126,"end":221574},{"type":"TextQuoteSelector","exact":"Hence, to know how changing a parameter modifies the loss, we also need to knowhow changes to every subsequent hidden layer will, in turn, modify their successor. Thesesame quantities are required when considering other parameters in the same or earlierlayers. It follows that we can calculate them once and reuse them. For example, considercomputing the effect of a small change in weights that feed into hidden layers h3, h2,and h1, respectively:","prefix":"l output and, finally, the loss.","suffix":"• To calculate how a small chang"}]}]}
>```
>%%
>*%%PREFIX%%l output and, finally, the loss.%%HIGHLIGHT%% ==Hence, to know how changing a parameter modifies the loss, we also need to knowhow changes to every subsequent hidden layer will, in turn, modify their successor. Thesesame quantities are required when considering other parameters in the same or earlierlayers. It follows that we can calculate them once and reuse them. For example, considercomputing the effect of a small change in weights that feed into hidden layers h3, h2,and h1, respectively:== %%POSTFIX%%• To calculate how a small chang*
>%%LINK%%[[#^eezw8wytjij|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^eezw8wytjij


>%%
>```annotation-json
>{"created":"2024-10-08T15:58:37.955Z","updated":"2024-10-08T15:58:37.955Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":221577,"end":221816},{"type":"TextQuoteSelector","exact":"o calculate how a small change in a weight or bias feeding into hidden layer h3modifies the loss, we need to know (i) how a change in layer h3 changes the modeloutput f, and (ii) how a change in this output changes the loss ℓ (figure 7.2a)","prefix":" h3, h2,and h1, respectively:• T","suffix":".• To calculate how a small chan"}]}]}
>```
>%%
>*%%PREFIX%%h3, h2,and h1, respectively:• T%%HIGHLIGHT%% ==o calculate how a small change in a weight or bias feeding into hidden layer h3modifies the loss, we need to know (i) how a change in layer h3 changes the modeloutput f, and (ii) how a change in this output changes the loss ℓ (figure 7.2a)== %%POSTFIX%%.• To calculate how a small chan*
>%%LINK%%[[#^d2u6vgc7dyt|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^d2u6vgc7dyt


>%%
>```annotation-json
>{"created":"2024-10-08T15:58:48.384Z","updated":"2024-10-08T15:58:48.384Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":221820,"end":222068},{"type":"TextQuoteSelector","exact":"o calculate how a small change in a weight or bias feeding into hidden layer h2modifies the loss, we need to know (i) how a change in layer h2 affects h3, (ii) how h3changes the model output, and (iii) how this output changes the loss (figure 7.2b)","prefix":"ges the loss ℓ (figure 7.2a).• T","suffix":".• To calculate how a small chan"}]}]}
>```
>%%
>*%%PREFIX%%ges the loss ℓ (figure 7.2a).• T%%HIGHLIGHT%% ==o calculate how a small change in a weight or bias feeding into hidden layer h2modifies the loss, we need to know (i) how a change in layer h2 affects h3, (ii) how h3changes the model output, and (iii) how this output changes the loss (figure 7.2b)== %%POSTFIX%%.• To calculate how a small chan*
>%%LINK%%[[#^v6b0er49cr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^v6b0er49cr


>%%
>```annotation-json
>{"created":"2024-10-08T15:59:34.694Z","updated":"2024-10-08T15:59:34.694Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":222072,"end":222384},{"type":"TextQuoteSelector","exact":"o calculate how a small change in a weight or bias feeding into hidden layer h1modifies the loss, we need to know (i) how a change in layer h1 affects layer h2,(ii) how a change in layer h2 affects layer h3, (iii) how layer h3 changes the modeloutput, and (iv) how the model output changes the loss (figure 7.2c)","prefix":"anges the loss (figure 7.2b).• T","suffix":".This work is subject to a Creat"}]}]}
>```
>%%
>*%%PREFIX%%anges the loss (figure 7.2b).• T%%HIGHLIGHT%% ==o calculate how a small change in a weight or bias feeding into hidden layer h1modifies the loss, we need to know (i) how a change in layer h1 affects layer h2,(ii) how a change in layer h2 affects layer h3, (iii) how layer h3 changes the modeloutput, and (iv) how the model output changes the loss (figure 7.2c)== %%POSTFIX%%.This work is subject to a Creat*
>%%LINK%%[[#^hizvw6tvxy|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hizvw6tvxy


>%%
>```annotation-json
>{"created":"2024-10-08T16:01:10.285Z","text":"What is a backward pass?","updated":"2024-10-08T16:01:10.285Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":223394,"end":223662},{"type":"TextQuoteSelector","exact":"As we move backward through the network, we see that most of the terms we needwere already calculated in the previous step, so we do not need to re-compute them.Proceeding backward through the network in this way to compute the derivatives isknown as the backward pass","prefix":"0 7 Gradients and initialization","suffix":".The ideas behind backpropagatio"}]}]}
>```
>%%
>*%%PREFIX%%0 7 Gradients and initialization%%HIGHLIGHT%% ==As we move backward through the network, we see that most of the terms we needwere already calculated in the previous step, so we do not need to re-compute them.Proceeding backward through the network in this way to compute the derivatives isknown as the backward pass== %%POSTFIX%%.The ideas behind backpropagatio*
>%%LINK%%[[#^e24sn4jmtzr|show annotation]]
>%%COMMENT%%
>What is a backward pass?
>%%TAGS%%
>#question
^e24sn4jmtzr


>%%
>```annotation-json
>{"created":"2024-10-08T16:01:58.972Z","updated":"2024-10-08T16:01:58.972Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":223663,"end":224055},{"type":"TextQuoteSelector","exact":"The ideas behind backpropagation are relatively easy to understand. However, thederivation requires matrix calculus because the bias and weight terms are vectors andmatrices, respectively. To help grasp the underlying mechanics, the following sectionderives backpropagation for a simpler toy model with scalar parameters. We then applythe same approach to a deep neural network in section 7.4","prefix":"es isknown as the backward pass.","suffix":".7.3 Toy exampleConsider a model"}]}]}
>```
>%%
>*%%PREFIX%%es isknown as the backward pass.%%HIGHLIGHT%% ==The ideas behind backpropagation are relatively easy to understand. However, thederivation requires matrix calculus because the bias and weight terms are vectors andmatrices, respectively. To help grasp the underlying mechanics, the following sectionderives backpropagation for a simpler toy model with scalar parameters. We then applythe same approach to a deep neural network in section 7.4== %%POSTFIX%%.7.3 Toy exampleConsider a model*
>%%LINK%%[[#^kr3vbdik7zb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kr3vbdik7zb


>%%
>```annotation-json
>{"created":"2024-10-08T16:03:06.009Z","updated":"2024-10-08T16:03:06.009Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":224060,"end":224071},{"type":"TextQuoteSelector","exact":"Toy example","prefix":"ural network in section 7.4.7.3 ","suffix":"Consider a model f[x,φ] with eig"}]}]}
>```
>%%
>*%%PREFIX%%ural network in section 7.4.7.3%%HIGHLIGHT%% ==Toy example== %%POSTFIX%%Consider a model f[x,φ] with eig*
>%%LINK%%[[#^24whqiokbp9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^24whqiokbp9


>%%
>```annotation-json
>{"created":"2024-10-08T16:03:30.657Z","updated":"2024-10-08T16:03:30.657Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":224071,"end":224383},{"type":"TextQuoteSelector","exact":"Consider a model f[x,φ] with eight scalar parameters φ = {β0,ω0,β1,ω1,β2,ω2,β3,ω3}that consists of a composition of the functions sin[•],exp[•], and cos[•]:f[x,φ] = β3 + ω3 ·cos[β2 + ω2 ·exp[β1 + ω1 ·sin[β0 + ω0 ·x]]], (7.5)and a least squares loss function L[φ] = ∑i ℓi with individual terms:ℓi = (f[xi,φ] −yi)2","prefix":"k in section 7.4.7.3 Toy example","suffix":", (7.6)where, as usual, xi is th"}]}]}
>```
>%%
>*%%PREFIX%%k in section 7.4.7.3 Toy example%%HIGHLIGHT%% ==Consider a model f[x,φ] with eight scalar parameters φ = {β0,ω0,β1,ω1,β2,ω2,β3,ω3}that consists of a composition of the functions sin[•],exp[•], and cos[•]:f[x,φ] = β3 + ω3 ·cos[β2 + ω2 ·exp[β1 + ω1 ·sin[β0 + ω0 ·x]]], (7.5)and a least squares loss function L[φ] = ∑i ℓi with individual terms:ℓi = (f[xi,φ] −yi)2== %%POSTFIX%%, (7.6)where, as usual, xi is th*
>%%LINK%%[[#^z96p2zdvegn|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^z96p2zdvegn


>%%
>```annotation-json
>{"created":"2024-10-08T16:04:17.413Z","updated":"2024-10-08T16:04:17.413Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":224390,"end":224758},{"type":"TextQuoteSelector","exact":"where, as usual, xi is the ith training input, and yi is the ith training output. You canthink of this as a simple neural network with one input, one output, one hidden unit ateach layer, and different activation functions sin[•],exp[•], and cos[•] between each layer.We aim to compute the derivatives:∂ℓi∂β0, ∂ℓi∂ω0, ∂ℓi∂β1, ∂ℓi∂ω1, ∂ℓi∂β2, ∂ℓi∂ω2, ∂ℓi∂β3, and ∂ℓi∂ω3","prefix":"terms:ℓi = (f[xi,φ] −yi)2, (7.6)","suffix":".Of course, we could find expres"}]}]}
>```
>%%
>*%%PREFIX%%terms:ℓi = (f[xi,φ] −yi)2, (7.6)%%HIGHLIGHT%% ==where, as usual, xi is the ith training input, and yi is the ith training output. You canthink of this as a simple neural network with one input, one output, one hidden unit ateach layer, and different activation functions sin[•],exp[•], and cos[•] between each layer.We aim to compute the derivatives:∂ℓi∂β0, ∂ℓi∂ω0, ∂ℓi∂β1, ∂ℓi∂ω1, ∂ℓi∂β2, ∂ℓi∂ω2, ∂ℓi∂β3, and ∂ℓi∂ω3== %%POSTFIX%%.Of course, we could find expres*
>%%LINK%%[[#^g7f52gtdlf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^g7f52gtdlf


>%%
>```annotation-json
>{"created":"2024-10-08T16:05:00.618Z","updated":"2024-10-08T16:05:00.618Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":224759,"end":224904},{"type":"TextQuoteSelector","exact":"Of course, we could find expressions for these derivatives by hand and compute themdirectly. However, some of these expressions are quite complex","prefix":"∂β2, ∂ℓi∂ω2, ∂ℓi∂β3, and ∂ℓi∂ω3.","suffix":". For example:∂ℓi∂ω0= −2(β3 + ω3"}]}]}
>```
>%%
>*%%PREFIX%%∂β2, ∂ℓi∂ω2, ∂ℓi∂β3, and ∂ℓi∂ω3.%%HIGHLIGHT%% ==Of course, we could find expressions for these derivatives by hand and compute themdirectly. However, some of these expressions are quite complex== %%POSTFIX%%. For example:∂ℓi∂ω0= −2(β3 + ω3*
>%%LINK%%[[#^mfb9uypq06|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mfb9uypq06


>%%
>```annotation-json
>{"created":"2024-10-08T16:05:17.424Z","updated":"2024-10-08T16:05:17.424Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":225099,"end":225259},{"type":"TextQuoteSelector","exact":"Such expressions are awkward to derive and code without mistakes and do not exploitthe inherent redundancy; notice that the three exponential terms are the same","prefix":" + ω1 ·sin[β0 + ω0 ·xi]]]. (7.7)","suffix":".The backpropagation algorithm i"}]}]}
>```
>%%
>*%%PREFIX%%+ ω1 ·sin[β0 + ω0 ·xi]]]. (7.7)%%HIGHLIGHT%% ==Such expressions are awkward to derive and code without mistakes and do not exploitthe inherent redundancy; notice that the three exponential terms are the same== %%POSTFIX%%.The backpropagation algorithm i*
>%%LINK%%[[#^daq2batj91b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^daq2batj91b


>%%
>```annotation-json
>{"created":"2024-10-08T16:05:34.497Z","updated":"2024-10-08T16:05:34.497Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":225260,"end":225513},{"type":"TextQuoteSelector","exact":"The backpropagation algorithm is an eﬀicient method for computing all of thesederivatives at once. It consists of (i) a forward pass, in which we compute and store aseries of intermediate values and the network output, and (ii) a backward pass, in which","prefix":" exponential terms are the same.","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%exponential terms are the same.%%HIGHLIGHT%% ==The backpropagation algorithm is an eﬀicient method for computing all of thesederivatives at once. It consists of (i) a forward pass, in which we compute and store aseries of intermediate values and the network output, and (ii) a backward pass, in which== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^zevbwm8sqoe|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zevbwm8sqoe


>%%
>```annotation-json
>{"created":"2024-10-08T16:05:48.099Z","updated":"2024-10-08T16:05:48.099Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":225750,"end":225894},{"type":"TextQuoteSelector","exact":"we calculate the derivatives of each parameter, starting at the end of the network, andreusing previous calculations as we move toward the start","prefix":"l we finally calculate the loss.","suffix":".Forward pass: We treat the comp"}]}]}
>```
>%%
>*%%PREFIX%%l we finally calculate the loss.%%HIGHLIGHT%% ==we calculate the derivatives of each parameter, starting at the end of the network, andreusing previous calculations as we move toward the start== %%POSTFIX%%.Forward pass: We treat the comp*
>%%LINK%%[[#^ps3fbvggv1e|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ps3fbvggv1e


>%%
>```annotation-json
>{"created":"2024-10-08T16:06:11.107Z","updated":"2024-10-08T16:06:11.107Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":225895,"end":226088},{"type":"TextQuoteSelector","exact":"Forward pass: We treat the computation of the loss as a series of calculations:f0 = β0 + ω0 ·xih1 = sin[f0]f1 = β1 + ω1 ·h1h2 = exp[f1]f2 = β2 + ω2 ·h2h3 = cos[f2]f3 = β3 + ω3 ·h3ℓi = (f3 −yi)2","prefix":"ons as we move toward the start.","suffix":". (7.8)We compute and store the "}]}]}
>```
>%%
>*%%PREFIX%%ons as we move toward the start.%%HIGHLIGHT%% ==Forward pass: We treat the computation of the loss as a series of calculations:f0 = β0 + ω0 ·xih1 = sin[f0]f1 = β1 + ω1 ·h1h2 = exp[f1]f2 = β2 + ω2 ·h2h3 = cos[f2]f3 = β3 + ω3 ·h3ℓi = (f3 −yi)2== %%POSTFIX%%. (7.8)We compute and store the*
>%%LINK%%[[#^jpx6b1241u|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jpx6b1241u


>%%
>```annotation-json
>{"created":"2024-10-08T16:06:50.445Z","updated":"2024-10-08T16:06:50.445Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":226095,"end":226179},{"type":"TextQuoteSelector","exact":"We compute and store the values of the intermediate variables fk and hk (figure 7.3)","prefix":"β3 + ω3 ·h3ℓi = (f3 −yi)2. (7.8)","suffix":".Backward pass #1: We now comput"}]}]}
>```
>%%
>*%%PREFIX%%β3 + ω3 ·h3ℓi = (f3 −yi)2. (7.8)%%HIGHLIGHT%% ==We compute and store the values of the intermediate variables fk and hk (figure 7.3)== %%POSTFIX%%.Backward pass #1: We now comput*
>%%LINK%%[[#^pef1c4ba2b|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^pef1c4ba2b


>%%
>```annotation-json
>{"created":"2024-10-08T16:07:37.157Z","updated":"2024-10-08T16:07:37.157Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":226180,"end":226521},{"type":"TextQuoteSelector","exact":"Backward pass #1: We now compute the derivatives of ℓi with respect to these inter-mediate variables, but in reverse order:∂ℓi∂f3, ∂ℓi∂h3, ∂ℓi∂f2, ∂ℓi∂h2, ∂ℓi∂f1, ∂ℓi∂h1, and ∂ℓi∂f0. (7.9)The first of these derivatives is straightforward:∂ℓi∂f3= 2(f3 −yi). (7.10)The next derivative can be calculated using the chain rule:∂ℓi∂h3= ∂f3∂h3∂ℓi∂f","prefix":"ariables fk and hk (figure 7.3).","suffix":"3. (7.11)The left-hand side asks"}]}]}
>```
>%%
>*%%PREFIX%%ariables fk and hk (figure 7.3).%%HIGHLIGHT%% ==Backward pass #1: We now compute the derivatives of ℓi with respect to these inter-mediate variables, but in reverse order:∂ℓi∂f3, ∂ℓi∂h3, ∂ℓi∂f2, ∂ℓi∂h2, ∂ℓi∂f1, ∂ℓi∂h1, and ∂ℓi∂f0. (7.9)The first of these derivatives is straightforward:∂ℓi∂f3= 2(f3 −yi). (7.10)The next derivative can be calculated using the chain rule:∂ℓi∂h3= ∂f3∂h3∂ℓi∂f== %%POSTFIX%%3. (7.11)The left-hand side asks*
>%%LINK%%[[#^9t3c0zl35mo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9t3c0zl35mo


>%%
>```annotation-json
>{"created":"2024-10-08T16:08:37.545Z","updated":"2024-10-08T16:08:37.545Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":226530,"end":226791},{"type":"TextQuoteSelector","exact":"The left-hand side asks how ℓi changes when h3 changes. The right-hand side says we candecompose this into (i) how f3 changes when h3 changes and (ii) how ℓi changes when f3changes. In the original equations, h3 changes f3, which changes ℓi, and the derivatives","prefix":"ule:∂ℓi∂h3= ∂f3∂h3∂ℓi∂f3. (7.11)","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%ule:∂ℓi∂h3= ∂f3∂h3∂ℓi∂f3. (7.11)%%HIGHLIGHT%% ==The left-hand side asks how ℓi changes when h3 changes. The right-hand side says we candecompose this into (i) how f3 changes when h3 changes and (ii) how ℓi changes when f3changes. In the original equations, h3 changes f3, which changes ℓi, and the derivatives== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^us33eupq8j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^us33eupq8j


>%%
>```annotation-json
>{"created":"2024-10-08T16:08:52.841Z","updated":"2024-10-08T16:08:52.841Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":227174,"end":227352},{"type":"TextQuoteSelector","exact":"represent the effects of this chain. Notice that we already computed the second of thesederivatives, and the other is the derivative of β3 +ω3 ·h3 with respect to h3, which is ω3","prefix":"f the form ∂fk/∂hk or ∂hk/∂fk−1.","suffix":".We continue in this way, comput"}]}]}
>```
>%%
>*%%PREFIX%%f the form ∂fk/∂hk or ∂hk/∂fk−1.%%HIGHLIGHT%% ==represent the effects of this chain. Notice that we already computed the second of thesederivatives, and the other is the derivative of β3 +ω3 ·h3 with respect to h3, which is ω3== %%POSTFIX%%.We continue in this way, comput*
>%%LINK%%[[#^yee148zyf9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yee148zyf9


>%%
>```annotation-json
>{"created":"2024-10-08T16:09:29.552Z","updated":"2024-10-08T16:09:29.552Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":227353,"end":227991},{"type":"TextQuoteSelector","exact":"We continue in this way, computing the derivatives of the output with respect tothese intermediate quantities (figure 7.4):∂ℓi∂f2= ∂h3∂f2(∂f3∂h3∂ℓi∂f3)∂ℓi∂h2= ∂f2∂h2(∂h3∂f2∂f3∂h3∂ℓi∂f3)∂ℓi∂f1= ∂h2∂f1(∂f2∂h2∂h3∂f2∂f3∂h3∂ℓi∂f3)∂ℓi∂h1= ∂f1∂h1(∂h2∂f1∂f2∂h2∂h3∂f2∂f3∂h3∂ℓi∂f3)∂ℓi∂f0= ∂h1∂f0(∂f1∂h1∂h2∂f1∂f2∂h2∂h3∂f2∂f3∂h3∂ℓi∂f3). (7.12)In each case, we have already computed the quantities in the brackets in the previousProblem 7.2 step, and the last term has a simple expression. These equations embody Observation 2from the previous section (figure 7.2); we can reuse the previously computed derivativesif we calculate them in reverse order","prefix":"with respect to h3, which is ω3.","suffix":".Backward pass #2: Finally, we c"}]}]}
>```
>%%
>*%%PREFIX%%with respect to h3, which is ω3.%%HIGHLIGHT%% ==We continue in this way, computing the derivatives of the output with respect tothese intermediate quantities (figure 7.4):∂ℓi∂f2= ∂h3∂f2(∂f3∂h3∂ℓi∂f3)∂ℓi∂h2= ∂f2∂h2(∂h3∂f2∂f3∂h3∂ℓi∂f3)∂ℓi∂f1= ∂h2∂f1(∂f2∂h2∂h3∂f2∂f3∂h3∂ℓi∂f3)∂ℓi∂h1= ∂f1∂h1(∂h2∂f1∂f2∂h2∂h3∂f2∂f3∂h3∂ℓi∂f3)∂ℓi∂f0= ∂h1∂f0(∂f1∂h1∂h2∂f1∂f2∂h2∂h3∂f2∂f3∂h3∂ℓi∂f3). (7.12)In each case, we have already computed the quantities in the brackets in the previousProblem 7.2 step, and the last term has a simple expression. These equations embody Observation 2from the previous section (figure 7.2); we can reuse the previously computed derivativesif we calculate them in reverse order== %%POSTFIX%%.Backward pass #2: Finally, we c*
>%%LINK%%[[#^6is94tzxgv8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6is94tzxgv8


>%%
>```annotation-json
>{"created":"2024-10-08T16:10:57.619Z","updated":"2024-10-08T16:10:57.619Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":227992,"end":228343},{"type":"TextQuoteSelector","exact":"Backward pass #2: Finally, we consider how the loss ℓi changes when we change theparameters {βk} and {ωk}. Once more, we apply the chain rule (figure 7.5):∂ℓi∂βk= ∂fk∂βk∂ℓi∂fk∂ℓi∂ωk= ∂fk∂ωk∂ℓi∂fk. (7.13)In each case, the second term on the right-hand side was computed in equation 7.12.When k > 0, we have fk = βk + ωk ·hk, so:∂fk∂βk= 1 and ∂fk∂ωk= hk","prefix":"calculate them in reverse order.","suffix":". (7.14)This work is subject to "}]}]}
>```
>%%
>*%%PREFIX%%calculate them in reverse order.%%HIGHLIGHT%% ==Backward pass #2: Finally, we consider how the loss ℓi changes when we change theparameters {βk} and {ωk}. Once more, we apply the chain rule (figure 7.5):∂ℓi∂βk= ∂fk∂βk∂ℓi∂fk∂ℓi∂ωk= ∂fk∂ωk∂ℓi∂fk. (7.13)In each case, the second term on the right-hand side was computed in equation 7.12.When k > 0, we have fk = βk + ωk ·hk, so:∂fk∂βk= 1 and ∂fk∂ωk= hk== %%POSTFIX%%. (7.14)This work is subject to*
>%%LINK%%[[#^zmbuh1dczrl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^zmbuh1dczrl


>%%
>```annotation-json
>{"created":"2024-10-08T16:11:40.270Z","updated":"2024-10-08T16:11:40.270Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":228661,"end":229103},{"type":"TextQuoteSelector","exact":"This is consistent with Observation 1 from the previous section; the effect of a changein the weight ωk is proportional to the value of the source variable hk (which was storedin the forward pass). The final derivatives from the term f0 = β0 + ω0 ·xi are: Notebook 7.1Backpropagationin toy model∂f0∂β0= 1 and ∂f0∂ω0= xi. (7.15)Backpropagation is both simpler and more eﬀicient than computing the derivatives in-dividually, as in equation 7.7.","prefix":"k/∂βk or ∂fk/∂ωk as appropriate.","suffix":"17.4 Backpropagation algorithmNo"}]}]}
>```
>%%
>*%%PREFIX%%k/∂βk or ∂fk/∂ωk as appropriate.%%HIGHLIGHT%% ==This is consistent with Observation 1 from the previous section; the effect of a changein the weight ωk is proportional to the value of the source variable hk (which was storedin the forward pass). The final derivatives from the term f0 = β0 + ω0 ·xi are: Notebook 7.1Backpropagationin toy model∂f0∂β0= 1 and ∂f0∂ω0= xi. (7.15)Backpropagation is both simpler and more eﬀicient than computing the derivatives in-dividually, as in equation 7.7.== %%POSTFIX%%17.4 Backpropagation algorithmNo*
>%%LINK%%[[#^pp9546a73ta|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^pp9546a73ta


>%%
>```annotation-json
>{"created":"2024-10-08T16:12:47.803Z","text":"What is the backpropagation algorithm?","updated":"2024-10-08T16:12:47.803Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":229108,"end":229133},{"type":"TextQuoteSelector","exact":"Backpropagation algorithm","prefix":"dually, as in equation 7.7.17.4 ","suffix":"Now we repeat this process for a"}]}]}
>```
>%%
>*%%PREFIX%%dually, as in equation 7.7.17.4%%HIGHLIGHT%% ==Backpropagation algorithm== %%POSTFIX%%Now we repeat this process for a*
>%%LINK%%[[#^m8eixw7oyo|show annotation]]
>%%COMMENT%%
>What is the backpropagation algorithm?
>%%TAGS%%
>#question
^m8eixw7oyo


>%%
>```annotation-json
>{"created":"2024-10-08T16:14:07.763Z","updated":"2024-10-08T16:14:07.763Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":229133,"end":229634},{"type":"TextQuoteSelector","exact":"Now we repeat this process for a three-layer network (figure 7.1). The intuition and muchof the algebra are identical. The main differences are that intermediate variables fk,hkare vectors, the biases βk are vectors, the weights Ωk are matrices, and we are usingReLU functions rather than simple algebraic functions like cos[•].Forward pass: We write the network as a series of sequential calculations:f0 = β0 + Ω0xih1 = a[f0]f1 = β1 + Ω1h1h2 = a[f1]f2 = β2 + Ω2h2h3 = a[f2]f3 = β3 + Ω3h3ℓi = l[f3,yi]","prefix":"7.17.4 Backpropagation algorithm","suffix":", (7.16)1Note that we did not ac"}]}]}
>```
>%%
>*%%PREFIX%%7.17.4 Backpropagation algorithm%%HIGHLIGHT%% ==Now we repeat this process for a three-layer network (figure 7.1). The intuition and muchof the algebra are identical. The main differences are that intermediate variables fk,hkare vectors, the biases βk are vectors, the weights Ωk are matrices, and we are usingReLU functions rather than simple algebraic functions like cos[•].Forward pass: We write the network as a series of sequential calculations:f0 = β0 + Ω0xih1 = a[f0]f1 = β1 + Ω1h1h2 = a[f1]f2 = β2 + Ω2h2h3 = a[f2]f3 = β3 + Ω3h3ℓi = l[f3,yi]== %%POSTFIX%%, (7.16)1Note that we did not ac*
>%%LINK%%[[#^lbu7uhrgq6|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lbu7uhrgq6


>%%
>```annotation-json
>{"created":"2024-10-08T16:14:59.304Z","updated":"2024-10-08T16:14:59.304Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":230251,"end":230647},{"type":"TextQuoteSelector","exact":"where fk−1 represents the pre-activations at the kth hidden layer (i.e., the values beforethe ReLU function a[•]) and hk contains the activations at the kth hidden layer (i.e., afterthe ReLU function). The term l[f3,yi] represents the loss function (e.g., least squares orbinary cross-entropy loss). In the forward pass, we work through these calculations andstore all the intermediate quantities","prefix":"ro(since the slope here is one).","suffix":".Backward pass #1: Now let’s con"}]}]}
>```
>%%
>*%%PREFIX%%ro(since the slope here is one).%%HIGHLIGHT%% ==where fk−1 represents the pre-activations at the kth hidden layer (i.e., the values beforethe ReLU function a[•]) and hk contains the activations at the kth hidden layer (i.e., afterthe ReLU function). The term l[f3,yi] represents the loss function (e.g., least squares orbinary cross-entropy loss). In the forward pass, we work through these calculations andstore all the intermediate quantities== %%POSTFIX%%.Backward pass #1: Now let’s con*
>%%LINK%%[[#^wndavfbqasl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wndavfbqasl


>%%
>```annotation-json
>{"created":"2024-10-08T16:16:08.142Z","updated":"2024-10-08T16:16:08.142Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":230648,"end":231110},{"type":"TextQuoteSelector","exact":"Backward pass #1: Now let’s consider how the loss changes when we modify the pre-activations f0,f1,f2. Applying the chain rule, the expression for the derivative of theAppendix B.5Matrix calculus loss ℓi with respect to f2 is:∂ℓi∂f2= ∂h3∂f2∂f3∂h3∂ℓi∂f3. (7.17)The three terms on the right-hand side have sizes D3 × D3,D3 × Df , and Df × 1,respectively, where D3 is the number of hidden units in the third layer, and Df is thedimensionality of the model output f3","prefix":"all the intermediate quantities.","suffix":".Similarly, we can compute how t"}]}]}
>```
>%%
>*%%PREFIX%%all the intermediate quantities.%%HIGHLIGHT%% ==Backward pass #1: Now let’s consider how the loss changes when we modify the pre-activations f0,f1,f2. Applying the chain rule, the expression for the derivative of theAppendix B.5Matrix calculus loss ℓi with respect to f2 is:∂ℓi∂f2= ∂h3∂f2∂f3∂h3∂ℓi∂f3. (7.17)The three terms on the right-hand side have sizes D3 × D3,D3 × Df , and Df × 1,respectively, where D3 is the number of hidden units in the third layer, and Df is thedimensionality of the model output f3== %%POSTFIX%%.Similarly, we can compute how t*
>%%LINK%%[[#^myw71cno97|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^myw71cno97


>%%
>```annotation-json
>{"created":"2024-10-08T16:16:56.708Z","updated":"2024-10-08T16:16:56.708Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":231111,"end":231813},{"type":"TextQuoteSelector","exact":"Similarly, we can compute how the loss changes when we change f1 and f0:∂ℓi∂f1= ∂h2∂f1∂f2∂h2(∂h3∂f2∂f3∂h3∂ℓi∂f3)(7.18)∂ℓi∂f0= ∂h1∂f0∂f1∂h1(∂h2∂f1∂f2∂h2∂h3∂f2∂f3∂h3∂ℓi∂f3). (7.19)Note that in each case, the term in brackets was computed in the previous step. ByProblem 7.3 working backward through the network, we can reuse the previous computations.Moreover, the terms themselves are simple. Working backward through the right-Problems 7.4–7.5 hand side of equation 7.17, we have:• The derivative ∂ℓi/∂f3 of the loss ℓi with respect to the network output f3 willdepend on the loss function but usually has a simple form.• The derivative ∂f3/∂h3 of the network output with respect to hidden layer h3 is:","prefix":"ionality of the model output f3.","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%ionality of the model output f3.%%HIGHLIGHT%% ==Similarly, we can compute how the loss changes when we change f1 and f0:∂ℓi∂f1= ∂h2∂f1∂f2∂h2(∂h3∂f2∂f3∂h3∂ℓi∂f3)(7.18)∂ℓi∂f0= ∂h1∂f0∂f1∂h1(∂h2∂f1∂f2∂h2∂h3∂f2∂f3∂h3∂ℓi∂f3). (7.19)Note that in each case, the term in brackets was computed in the previous step. ByProblem 7.3 working backward through the network, we can reuse the previous computations.Moreover, the terms themselves are simple. Working backward through the right-Problems 7.4–7.5 hand side of equation 7.17, we have:• The derivative ∂ℓi/∂f3 of the loss ℓi with respect to the network output f3 willdepend on the loss function but usually has a simple form.• The derivative ∂f3/∂h3 of the network output with respect to hidden layer h3 is:== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^epvus6161hf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^epvus6161hf


>%%
>```annotation-json
>{"created":"2024-10-08T16:17:59.085Z","updated":"2024-10-08T16:17:59.085Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":231924,"end":232573},{"type":"TextQuoteSelector","exact":"∂f3∂h3= ∂∂h3(β3 + Ω3h3) = ΩT3 . (7.20)If you are unfamiliar with matrix calculus, this result is not obvious. It is explored Problem 7.6in problem 7.6.• The derivative ∂h3/∂f2 of the output h3 of the activation function with respect toits input f2 will depend on the activation function. It will be a diagonal matrixsince each activation only depends on the corresponding pre-activation. For ReLUfunctions, the diagonal terms are zero everywhere f2 is less than zero and one Problems 7.7–7.8otherwise (figure 7.6). Rather than multiply by this matrix, we extract the diagonalterms as a vector I[f2 > 0] and pointwise multiply, which is more eﬀicient","prefix":".4 Backpropagation algorithm 105","suffix":".The terms on the right-hand sid"}]}]}
>```
>%%
>*%%PREFIX%%.4 Backpropagation algorithm 105%%HIGHLIGHT%% ==∂f3∂h3= ∂∂h3(β3 + Ω3h3) = ΩT3 . (7.20)If you are unfamiliar with matrix calculus, this result is not obvious. It is explored Problem 7.6in problem 7.6.• The derivative ∂h3/∂f2 of the output h3 of the activation function with respect toits input f2 will depend on the activation function. It will be a diagonal matrixsince each activation only depends on the corresponding pre-activation. For ReLUfunctions, the diagonal terms are zero everywhere f2 is less than zero and one Problems 7.7–7.8otherwise (figure 7.6). Rather than multiply by this matrix, we extract the diagonalterms as a vector I[f2 > 0] and pointwise multiply, which is more eﬀicient== %%POSTFIX%%.The terms on the right-hand sid*
>%%LINK%%[[#^bhwmbifjjia|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bhwmbifjjia


>%%
>```annotation-json
>{"created":"2024-10-08T16:19:03.012Z","updated":"2024-10-08T16:19:03.012Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":232574,"end":232877},{"type":"TextQuoteSelector","exact":"The terms on the right-hand side of equations 7.18 and 7.19 have similar forms. Aswe progress back through the network, we alternately (i) multiply by the transpose ofthe weight matrices ΩTk and (ii) threshold based on the inputs fk−1 to the hidden layer.These inputs were stored during the forward pass","prefix":"ultiply, which is more eﬀicient.","suffix":".Backward pass #2: Now that we k"}]}]}
>```
>%%
>*%%PREFIX%%ultiply, which is more eﬀicient.%%HIGHLIGHT%% ==The terms on the right-hand side of equations 7.18 and 7.19 have similar forms. Aswe progress back through the network, we alternately (i) multiply by the transpose ofthe weight matrices ΩTk and (ii) threshold based on the inputs fk−1 to the hidden layer.These inputs were stored during the forward pass== %%POSTFIX%%.Backward pass #2: Now that we k*
>%%LINK%%[[#^dly27d4rgx8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dly27d4rgx8


>%%
>```annotation-json
>{"created":"2024-10-08T16:19:56.145Z","updated":"2024-10-08T16:19:56.145Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":232878,"end":233878},{"type":"TextQuoteSelector","exact":"Backward pass #2: Now that we know how to compute ∂ℓi/∂fk, we can focus oncalculating the derivatives of the loss with respect to the weights and biases. To calculatethe derivatives of the loss with respect to the biases βk, we again use the chain rule:∂ℓi∂βk= ∂fk∂βk∂ℓi∂fk= ∂∂βk(βk + Ωkhk) ∂ℓi∂fk= ∂ℓi∂fk, (7.21)which we already calculated in equations 7.17 and 7.18.Similarly, the derivative for the weights matrix Ωk, is given by:∂ℓi∂Ωk= ∂fk∂Ωk∂ℓi∂fk= ∂∂Ωk(βk + Ωkhk) ∂ℓi∂fk= ∂ℓi∂fkhTk . (7.22)Again, the progression from line two to line three is not obvious and is explored in Problem 7.9problem 7.9. However, the result makes sense. The final line is a matrix of the same sizeas Ωk. It depends linearly on hk, which was multiplied by Ωk in the original expression.This is also consistent with the initial intuition that the derivative of the weights in Ωkwill be proportional to the values of the hidden units hk that they multiply. Recall thatwe already computed these during the forward pass.","prefix":" stored during the forward pass.","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%stored during the forward pass.%%HIGHLIGHT%% ==Backward pass #2: Now that we know how to compute ∂ℓi/∂fk, we can focus oncalculating the derivatives of the loss with respect to the weights and biases. To calculatethe derivatives of the loss with respect to the biases βk, we again use the chain rule:∂ℓi∂βk= ∂fk∂βk∂ℓi∂fk= ∂∂βk(βk + Ωkhk) ∂ℓi∂fk= ∂ℓi∂fk, (7.21)which we already calculated in equations 7.17 and 7.18.Similarly, the derivative for the weights matrix Ωk, is given by:∂ℓi∂Ωk= ∂fk∂Ωk∂ℓi∂fk= ∂∂Ωk(βk + Ωkhk) ∂ℓi∂fk= ∂ℓi∂fkhTk . (7.22)Again, the progression from line two to line three is not obvious and is explored in Problem 7.9problem 7.9. However, the result makes sense. The final line is a matrix of the same sizeas Ωk. It depends linearly on hk, which was multiplied by Ωk in the original expression.This is also consistent with the initial intuition that the derivative of the weights in Ωkwill be proportional to the values of the hidden units hk that they multiply. Recall thatwe already computed these during the forward pass.== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^hgp7umqvo94|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hgp7umqvo94


>%%
>```annotation-json
>{"created":"2024-10-08T16:22:34.123Z","updated":"2024-10-08T16:22:34.123Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":233969,"end":234002},{"type":"TextQuoteSelector","exact":"Backpropagation algorithm summary","prefix":"adients and initialization7.4.1 ","suffix":"We now briefly summarize the fin"}]}]}
>```
>%%
>*%%PREFIX%%adients and initialization7.4.1%%HIGHLIGHT%% ==Backpropagation algorithm summary== %%POSTFIX%%We now briefly summarize the fin*
>%%LINK%%[[#^f2tw9z0cawf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f2tw9z0cawf


>%%
>```annotation-json
>{"created":"2024-10-08T16:22:40.695Z","updated":"2024-10-08T16:22:40.695Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":234002,"end":235582},{"type":"TextQuoteSelector","exact":"We now briefly summarize the final backpropagation algorithm. Consider a deep neuralnetwork f[xi,φ] that takes input xi, has K hidden layers with ReLU activations, andindividual loss term ℓi = l[f[xi,φ],yi]. The goal of backpropagation is to compute thederivatives ∂ℓi/∂βk and ∂ℓi/∂Ωk with respect to the biases βk and weights Ωk.Forward pass: We compute and store the following quantities:f0 = β0 + Ω0xihk = a[fk−1] k ∈{1,2,...,K}fk = βk + Ωkhk. k ∈{1,2,...,K} (7.23)Backward pass: We start with the derivative ∂ℓi/∂fK of the loss function ℓi with respectto the network output fK and work backward through the network:∂ℓi∂βk= ∂ℓi∂fkk ∈{K,K −1,...,1}∂ℓi∂Ωk= ∂ℓi∂fkhTk k ∈{K,K −1,...,1}∂ℓi∂fk−1= I[fk−1 > 0] ⊙(ΩTk∂ℓi∂fk), k ∈{K,K −1,...,1} (7.24)where ⊙ denotes pointwise multiplication, and I[fk−1 > 0] is a vector containing oneswhere fk−1 is greater than zero and zeros elsewhere. Finally, we compute the derivativeswith respect to the first set of biases and weights:∂ℓi∂β0= ∂ℓi∂f0∂ℓi∂Ω0= ∂ℓi∂f0xTi . (7.25)We calculate these derivatives for every training example in the batch and sum themProblem 7.10 together to retrieve the gradient for the SGD update.Notebook 7.2BackpropagationNote that the backpropagation algorithm is extremely eﬀicient; the most demandingcomputational step in both the forward and backward pass is matrix multiplication (by Ωand ΩT , respectively) which only requires additions and multiplications. However, it isnot memory eﬀicient; the intermediate values in the forward pass must all be stored, andthis can limit the size of the model we can train.","prefix":"ackpropagation algorithm summary","suffix":"7.4.2 Algorithmic differentiatio"}]}]}
>```
>%%
>*%%PREFIX%%ackpropagation algorithm summary%%HIGHLIGHT%% ==We now briefly summarize the final backpropagation algorithm. Consider a deep neuralnetwork f[xi,φ] that takes input xi, has K hidden layers with ReLU activations, andindividual loss term ℓi = l[f[xi,φ],yi]. The goal of backpropagation is to compute thederivatives ∂ℓi/∂βk and ∂ℓi/∂Ωk with respect to the biases βk and weights Ωk.Forward pass: We compute and store the following quantities:f0 = β0 + Ω0xihk = a[fk−1] k ∈{1,2,...,K}fk = βk + Ωkhk. k ∈{1,2,...,K} (7.23)Backward pass: We start with the derivative ∂ℓi/∂fK of the loss function ℓi with respectto the network output fK and work backward through the network:∂ℓi∂βk= ∂ℓi∂fkk ∈{K,K −1,...,1}∂ℓi∂Ωk= ∂ℓi∂fkhTk k ∈{K,K −1,...,1}∂ℓi∂fk−1= I[fk−1 > 0] ⊙(ΩTk∂ℓi∂fk), k ∈{K,K −1,...,1} (7.24)where ⊙ denotes pointwise multiplication, and I[fk−1 > 0] is a vector containing oneswhere fk−1 is greater than zero and zeros elsewhere. Finally, we compute the derivativeswith respect to the first set of biases and weights:∂ℓi∂β0= ∂ℓi∂f0∂ℓi∂Ω0= ∂ℓi∂f0xTi . (7.25)We calculate these derivatives for every training example in the batch and sum themProblem 7.10 together to retrieve the gradient for the SGD update.Notebook 7.2BackpropagationNote that the backpropagation algorithm is extremely eﬀicient; the most demandingcomputational step in both the forward and backward pass is matrix multiplication (by Ωand ΩT , respectively) which only requires additions and multiplications. However, it isnot memory eﬀicient; the intermediate values in the forward pass must all be stored, andthis can limit the size of the model we can train.== %%POSTFIX%%7.4.2 Algorithmic differentiatio*
>%%LINK%%[[#^e1yjn3xbvx|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^e1yjn3xbvx


>%%
>```annotation-json
>{"created":"2024-10-08T16:23:06.750Z","updated":"2024-10-08T16:23:06.750Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":235588,"end":235615},{"type":"TextQuoteSelector","exact":"Algorithmic differentiation","prefix":"of the model we can train.7.4.2 ","suffix":"Although it’s important to under"}]}]}
>```
>%%
>*%%PREFIX%%of the model we can train.7.4.2%%HIGHLIGHT%% ==Algorithmic differentiation== %%POSTFIX%%Although it’s important to under*
>%%LINK%%[[#^c5m8rnu0ni|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c5m8rnu0ni


>%%
>```annotation-json
>{"created":"2024-10-08T16:23:16.464Z","updated":"2024-10-08T16:23:16.464Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":235615,"end":235787},{"type":"TextQuoteSelector","exact":"Although it’s important to understand the backpropagation algorithm, it’s unlikely thatyou will need to code it in practice. Modern deep learning frameworks such as PyTorch","prefix":".4.2 Algorithmic differentiation","suffix":"This work is subject to a Creati"}]}]}
>```
>%%
>*%%PREFIX%%.4.2 Algorithmic differentiation%%HIGHLIGHT%% ==Although it’s important to understand the backpropagation algorithm, it’s unlikely thatyou will need to code it in practice. Modern deep learning frameworks such as PyTorch== %%POSTFIX%%This work is subject to a Creati*
>%%LINK%%[[#^e92f3idpz8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^e92f3idpz8


>%%
>```annotation-json
>{"created":"2024-10-08T16:23:20.963Z","text":"What is algorithmic differentiation?","updated":"2024-10-08T16:23:20.963Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":235897,"end":236028},{"type":"TextQuoteSelector","exact":"and TensorFlow calculate the derivatives automatically, given the model specification.This is known as algorithmic differentiation.","prefix":"7.5 Parameter initialization 107","suffix":"Each functional component (linea"}]}]}
>```
>%%
>*%%PREFIX%%7.5 Parameter initialization 107%%HIGHLIGHT%% ==and TensorFlow calculate the derivatives automatically, given the model specification.This is known as algorithmic differentiation.== %%POSTFIX%%Each functional component (linea*
>%%LINK%%[[#^h3j9bn2upc|show annotation]]
>%%COMMENT%%
>What is algorithmic differentiation?
>%%TAGS%%
>#question
^h3j9bn2upc


>%%
>```annotation-json
>{"created":"2024-10-08T16:26:18.699Z","text":"What is a tensor?","updated":"2024-10-08T16:26:18.699Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":237091,"end":237594},{"type":"TextQuoteSelector","exact":"Since the training algorithm now processes the entire batch in parallel, the inputbecomes a multi-dimensional tensor. In this context, a tensor can be considered thegeneralization of a matrix to arbitrary dimensions. Hence, a vector is a 1D tensor, amatrix is a 2D tensor, and a 3D tensor is a 3D grid of numbers. Until now, the trainingdata have been 1D, so the input for backpropagation would be a 2D tensor where thefirst dimension indexes the batch element and the second indexes the data dimension.","prefix":"not exceed the available memory.","suffix":"In subsequent chapters, we will "}]}]}
>```
>%%
>*%%PREFIX%%not exceed the available memory.%%HIGHLIGHT%% ==Since the training algorithm now processes the entire batch in parallel, the inputbecomes a multi-dimensional tensor. In this context, a tensor can be considered thegeneralization of a matrix to arbitrary dimensions. Hence, a vector is a 1D tensor, amatrix is a 2D tensor, and a 3D tensor is a 3D grid of numbers. Until now, the trainingdata have been 1D, so the input for backpropagation would be a 2D tensor where thefirst dimension indexes the batch element and the second indexes the data dimension.== %%POSTFIX%%In subsequent chapters, we will*
>%%LINK%%[[#^0qmpywlie8v|show annotation]]
>%%COMMENT%%
>What is a tensor?
>%%TAGS%%
>#question
^0qmpywlie8v


>%%
>```annotation-json
>{"created":"2024-10-08T16:27:15.976Z","updated":"2024-10-08T16:27:15.976Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":237909,"end":237952},{"type":"TextQuoteSelector","exact":"Extension to arbitrary computational graphs","prefix":"indexes the batch element.7.4.3 ","suffix":"We have described backpropagatio"}]}]}
>```
>%%
>*%%PREFIX%%indexes the batch element.7.4.3%%HIGHLIGHT%% ==Extension to arbitrary computational graphs== %%POSTFIX%%We have described backpropagatio*
>%%LINK%%[[#^7r1xbyq7aqf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7r1xbyq7aqf


>%%
>```annotation-json
>{"created":"2024-10-08T16:27:43.619Z","text":"What is parameter initialisation? ","updated":"2024-10-08T16:27:43.619Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":238606,"end":238630},{"type":"TextQuoteSelector","exact":"Parameter initialization","prefix":"cyclic computational graphs.7.5 ","suffix":"The backpropagation algorithm co"}]}]}
>```
>%%
>*%%PREFIX%%cyclic computational graphs.7.5%%HIGHLIGHT%% ==Parameter initialization== %%POSTFIX%%The backpropagation algorithm co*
>%%LINK%%[[#^lexu83haqx|show annotation]]
>%%COMMENT%%
>What is parameter initialisation? 
>%%TAGS%%
>#question
^lexu83haqx


>%%
>```annotation-json
>{"created":"2024-10-08T16:28:36.976Z","updated":"2024-10-08T16:28:36.976Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":238831,"end":238943},{"type":"TextQuoteSelector","exact":"To see why this is crucial, consider that during theforward pass, each set of pre-activations fk is computed as:","prefix":"eters before we start training. ","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%eters before we start training.%%HIGHLIGHT%% ==To see why this is crucial, consider that during theforward pass, each set of pre-activations fk is computed as:== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^mm139wxesm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mm139wxesm


>%%
>```annotation-json
>{"created":"2024-10-08T16:28:45.710Z","updated":"2024-10-08T16:28:45.710Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":239028,"end":239059},{"type":"TextQuoteSelector","exact":"fk = βk + Ωkhk= βk + Ωka[fk−1],","prefix":"8 7 Gradients and initialization","suffix":" (7.26)where a[•] applies the Re"}]}]}
>```
>%%
>*%%PREFIX%%8 7 Gradients and initialization%%HIGHLIGHT%% ==fk = βk + Ωkhk= βk + Ωka[fk−1],== %%POSTFIX%%(7.26)where a[•] applies the Re*
>%%LINK%%[[#^9ax5orr3nfi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9ax5orr3nfi


>%%
>```annotation-json
>{"created":"2024-10-08T16:30:56.974Z","text":"What is the vanishing gradient problem? \nWhat is the exploding gradient problem?","updated":"2024-10-08T16:30:56.974Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":239066,"end":240823},{"type":"TextQuoteSelector","exact":"where a[•] applies the ReLU functions and Ωk and βk are the weights and biases, respec-tively. Imagine that we initialize all the biases to zero and the elements of Ωk accordingto a normal distribution with mean zero and variance σ2. Consider two scenarios:• If the variance σ2 is very small (e.g., 10−5), then each element of βk +Ωkhk will bea weighted sum of hk where the weights are very small; the result will likely havea smaller magnitude than the input. In addition, the ReLU function clips valuesless than zero, so the range of hk will be half that of fk−1. Consequently, themagnitudes of the pre-activations at the hidden layers will get smaller and smalleras we progress through the network.• If the variance σ2 is very large (e.g., 105), then each element of βk + Ωkhk will bea weighted sum of hk where the weights are very large; the result is likely to havea much larger magnitude than the input. The ReLU function halves the range ofthe inputs, but if σ2 is large enough, the magnitudes of the pre-activations will stillget larger as we progress through the network.In these two situations, the values at the pre-activations can become so small or so largethat they cannot be represented with finite precision floating point arithmetic.Even if the forward pass is tractable, the same logic applies to the backward pass.Each gradient update (equation 7.24) consists of multiplying by ΩT . If the values of Ωare not initialized sensibly, then the gradient magnitudes may decrease or increase un-controllably during the backward pass. These cases are known as the vanishing gradientproblem and the exploding gradient problem, respectively. In the former case, updates tothe model become vanishingly small. In the latter case, they become unstable","prefix":"k + Ωkhk= βk + Ωka[fk−1], (7.26)","suffix":".7.5.1 Initialization for forwar"}]}]}
>```
>%%
>*%%PREFIX%%k + Ωkhk= βk + Ωka[fk−1], (7.26)%%HIGHLIGHT%% ==where a[•] applies the ReLU functions and Ωk and βk are the weights and biases, respec-tively. Imagine that we initialize all the biases to zero and the elements of Ωk accordingto a normal distribution with mean zero and variance σ2. Consider two scenarios:• If the variance σ2 is very small (e.g., 10−5), then each element of βk +Ωkhk will bea weighted sum of hk where the weights are very small; the result will likely havea smaller magnitude than the input. In addition, the ReLU function clips valuesless than zero, so the range of hk will be half that of fk−1. Consequently, themagnitudes of the pre-activations at the hidden layers will get smaller and smalleras we progress through the network.• If the variance σ2 is very large (e.g., 105), then each element of βk + Ωkhk will bea weighted sum of hk where the weights are very large; the result is likely to havea much larger magnitude than the input. The ReLU function halves the range ofthe inputs, but if σ2 is large enough, the magnitudes of the pre-activations will stillget larger as we progress through the network.In these two situations, the values at the pre-activations can become so small or so largethat they cannot be represented with finite precision floating point arithmetic.Even if the forward pass is tractable, the same logic applies to the backward pass.Each gradient update (equation 7.24) consists of multiplying by ΩT . If the values of Ωare not initialized sensibly, then the gradient magnitudes may decrease or increase un-controllably during the backward pass. These cases are known as the vanishing gradientproblem and the exploding gradient problem, respectively. In the former case, updates tothe model become vanishingly small. In the latter case, they become unstable== %%POSTFIX%%.7.5.1 Initialization for forwar*
>%%LINK%%[[#^byxsevioow|show annotation]]
>%%COMMENT%%
>What is the vanishing gradient problem? 
>What is the exploding gradient problem?
>%%TAGS%%
>#question
^byxsevioow


>%%
>```annotation-json
>{"created":"2024-10-08T16:32:27.693Z","text":"How to initialise for forward pass?","updated":"2024-10-08T16:32:27.693Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":240830,"end":240861},{"type":"TextQuoteSelector","exact":"Initialization for forward pass","prefix":"ase, they become unstable.7.5.1 ","suffix":"We now present a mathematical ve"}]}]}
>```
>%%
>*%%PREFIX%%ase, they become unstable.7.5.1%%HIGHLIGHT%% ==Initialization for forward pass== %%POSTFIX%%We now present a mathematical ve*
>%%LINK%%[[#^qzsbl217wfq|show annotation]]
>%%COMMENT%%
>How to initialise for forward pass?
>%%TAGS%%
>#question
^qzsbl217wfq


>%%
>```annotation-json
>{"created":"2024-10-08T16:33:20.439Z","updated":"2024-10-08T16:33:20.439Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":240861,"end":241027},{"type":"TextQuoteSelector","exact":"We now present a mathematical version of the same argument. Consider the computationbetween adjacent pre-activations f and f′ with dimensions Dh and Dh′, respectively","prefix":" Initialization for forward pass","suffix":":h = a[f],f′ = β + Ωh (7.27)wher"}]}]}
>```
>%%
>*%%PREFIX%%Initialization for forward pass%%HIGHLIGHT%% ==We now present a mathematical version of the same argument. Consider the computationbetween adjacent pre-activations f and f′ with dimensions Dh and Dh′, respectively== %%POSTFIX%%:h = a[f],f′ = β + Ωh (7.27)wher*
>%%LINK%%[[#^5op1ow0c7qj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5op1ow0c7qj


>%%
>```annotation-json
>{"created":"2024-10-08T16:33:49.381Z","updated":"2024-10-08T16:33:49.381Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":241028,"end":241048},{"type":"TextQuoteSelector","exact":"h = a[f],f′ = β + Ωh","prefix":"nsions Dh and Dh′, respectively:","suffix":" (7.27)where f represents the pr"}]}]}
>```
>%%
>*%%PREFIX%%nsions Dh and Dh′, respectively:%%HIGHLIGHT%% ==h = a[f],f′ = β + Ωh== %%POSTFIX%%(7.27)where f represents the pr*
>%%LINK%%[[#^uz8vmi5bq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^uz8vmi5bq


>%%
>```annotation-json
>{"created":"2024-10-08T16:34:01.440Z","updated":"2024-10-08T16:34:01.440Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":241055,"end":241172},{"type":"TextQuoteSelector","exact":"where f represents the pre-activations, Ω, and β represent the weights and biases,and a[•] is the activation function","prefix":"vely:h = a[f],f′ = β + Ωh (7.27)","suffix":".Assume the pre-activations fj i"}]}]}
>```
>%%
>*%%PREFIX%%vely:h = a[f],f′ = β + Ωh (7.27)%%HIGHLIGHT%% ==where f represents the pre-activations, Ω, and β represent the weights and biases,and a[•] is the activation function== %%POSTFIX%%.Assume the pre-activations fj i*
>%%LINK%%[[#^ehw5oau3534|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ehw5oau3534


>%%
>```annotation-json
>{"created":"2024-10-08T16:34:28.586Z","updated":"2024-10-08T16:34:28.586Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":241173,"end":241465},{"type":"TextQuoteSelector","exact":"Assume the pre-activations fj in the input layer f have variance σ2f . Consider ini-tializing the biases βi to zero and the weights Ωij as normally distributed with meanzero and variance σ2Ω. Now we derive expressions for the mean and variance of thepre-activations f′ in the subsequent layer","prefix":"a[•] is the activation function.","suffix":".This work is subject to a Creat"}]}]}
>```
>%%
>*%%PREFIX%%a[•] is the activation function.%%HIGHLIGHT%% ==Assume the pre-activations fj in the input layer f have variance σ2f . Consider ini-tializing the biases βi to zero and the weights Ωij as normally distributed with meanzero and variance σ2Ω. Now we derive expressions for the mean and variance of thepre-activations f′ in the subsequent layer== %%POSTFIX%%.This work is subject to a Creat*
>%%LINK%%[[#^ntf97rjtbla|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ntf97rjtbla


>%%
>```annotation-json
>{"created":"2024-10-08T16:34:37.250Z","updated":"2024-10-08T16:34:37.250Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":241576,"end":241640},{"type":"TextQuoteSelector","exact":"The expectation (mean) E[f′i ] of the intermediate values f′i is","prefix":"7.5 Parameter initialization 109","suffix":": Appendix C.2ExpectationE[f′i ]"}]}]}
>```
>%%
>*%%PREFIX%%7.5 Parameter initialization 109%%HIGHLIGHT%% ==The expectation (mean) E[f′i ] of the intermediate values f′i is== %%POSTFIX%%: Appendix C.2ExpectationE[f′i ]*
>%%LINK%%[[#^bctvzhvp3jw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bctvzhvp3jw


>%%
>```annotation-json
>{"created":"2024-10-08T16:36:25.544Z","updated":"2024-10-08T16:36:25.544Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":241788,"end":242151},{"type":"TextQuoteSelector","exact":"where Dh is the dimensionality of the input layer h. We have used the rules for manipu- Appendix C.2.1Expectation ruleslating expectations, and we have assumed that the distributions over the hidden units hjand the network weights Ωij are independent between the second and third lines.Using this result, we see that the variance σ2f′of the pre-activations f′i is","prefix":" 0 +Dh∑j=10 ·E [hj ] = 0, (7.28)","suffix":":σ2f′= E[f′2i ] −E[f′i ]2= E"}]}]}
>```
>%%
>*%%PREFIX%%0 +Dh∑j=10 ·E [hj ] = 0, (7.28)%%HIGHLIGHT%% ==where Dh is the dimensionality of the input layer h. We have used the rules for manipu- Appendix C.2.1Expectation ruleslating expectations, and we have assumed that the distributions over the hidden units hjand the network weights Ωij are independent between the second and third lines.Using this result, we see that the variance σ2f′of the pre-activations f′i is== %%POSTFIX%%:σ2f′= E[f′2i ] −E[f′i ]2= E*
>%%LINK%%[[#^nn53862byue|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nn53862byue


>%%
>```annotation-json
>{"created":"2024-10-08T16:36:29.662Z","updated":"2024-10-08T16:36:29.662Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":241665,"end":241780},{"type":"TextQuoteSelector","exact":"E[f′i ] = Eβi +Dh∑j=1Ωij hj= E [βi] +Dh∑j=1E [Ωij hj ]= E [βi] +Dh∑j=1E [Ωij ] E [hj ]= 0 +Dh∑j=10 ·E [hj ] = 0","prefix":" f′i is: Appendix C.2Expectation","suffix":", (7.28)where Dh is the dimensio"}]}]}
>```
>%%
>*%%PREFIX%%f′i is: Appendix C.2Expectation%%HIGHLIGHT%% ==E[f′i ] = Eβi +Dh∑j=1Ωij hj= E [βi] +Dh∑j=1E [Ωij hj ]= E [βi] +Dh∑j=1E [Ωij ] E [hj ]= 0 +Dh∑j=10 ·E [hj ] = 0== %%POSTFIX%%, (7.28)where Dh is the dimensio*
>%%LINK%%[[#^kcswqhv8fh8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kcswqhv8fh8


>%%
>```annotation-json
>{"created":"2024-10-08T16:36:58.219Z","updated":"2024-10-08T16:36:58.219Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":242152,"end":242292},{"type":"TextQuoteSelector","exact":"σ2f′= E[f′2i ] −E[f′i ]2= Eβi +Dh∑j=1Ωij hj2−0= EDh∑j=1Ωij hj2=Dh∑j=1E [Ω2ij]E [h2j]=Dh∑j=1σ2ΩE [h2j] = σ2ΩDh∑j=1E [h2j]","prefix":"f′of the pre-activations f′i is:","suffix":", (7.29)where we have used the v"}]}]}
>```
>%%
>*%%PREFIX%%f′of the pre-activations f′i is:%%HIGHLIGHT%% ==σ2f′= E[f′2i ] −E[f′i ]2= Eβi +Dh∑j=1Ωij hj2−0= EDh∑j=1Ωij hj2=Dh∑j=1E [Ω2ij]E [h2j]=Dh∑j=1σ2ΩE [h2j] = σ2ΩDh∑j=1E [h2j]== %%POSTFIX%%, (7.29)where we have used the v*
>%%LINK%%[[#^7mr16zn9hzg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7mr16zn9hzg


>%%
>```annotation-json
>{"created":"2024-10-08T16:37:28.332Z","updated":"2024-10-08T16:37:28.332Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":242300,"end":242542},{"type":"TextQuoteSelector","exact":"where we have used the variance identity σ2 = E[(z −E[z])2] = E[z2] −E[z]2. We have Appendix C.2.3Variance identityassumed once more that the distributions of the weights Ωij and the hidden units hj areindependent between lines three and four","prefix":"[h2j] = σ2ΩDh∑j=1E [h2j], (7.29)","suffix":".Assuming that the input distrib"}]}]}
>```
>%%
>*%%PREFIX%%[h2j] = σ2ΩDh∑j=1E [h2j], (7.29)%%HIGHLIGHT%% ==where we have used the variance identity σ2 = E[(z −E[z])2] = E[z2] −E[z]2. We have Appendix C.2.3Variance identityassumed once more that the distributions of the weights Ωij and the hidden units hj areindependent between lines three and four== %%POSTFIX%%.Assuming that the input distrib*
>%%LINK%%[[#^xmdrqv7ehir|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xmdrqv7ehir


>%%
>```annotation-json
>{"created":"2024-10-08T16:37:55.376Z","updated":"2024-10-08T16:37:55.376Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":242543,"end":242822},{"type":"TextQuoteSelector","exact":"Assuming that the input distribution of pre-activations fj is symmetric about zero,half of these pre-activations will be clipped by the ReLU function, and the second momentE[h2j ] will be half the variance σ2f of fj (see problem 7.14): Problem 7.14σ2f′= σ2ΩDh∑j=1σ2f2 = 12Dhσ2Ωσ2","prefix":"nt between lines three and four.","suffix":"f . (7.30)Draft: please send err"}]}]}
>```
>%%
>*%%PREFIX%%nt between lines three and four.%%HIGHLIGHT%% ==Assuming that the input distribution of pre-activations fj is symmetric about zero,half of these pre-activations will be clipped by the ReLU function, and the second momentE[h2j ] will be half the variance σ2f of fj (see problem 7.14): Problem 7.14σ2f′= σ2ΩDh∑j=1σ2f2 = 12Dhσ2Ωσ2== %%POSTFIX%%f . (7.30)Draft: please send err*
>%%LINK%%[[#^x4v6ar508v|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^x4v6ar508v


>%%
>```annotation-json
>{"created":"2024-10-08T16:40:56.967Z","updated":"2024-10-08T16:40:56.967Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":244027,"end":244226},{"type":"TextQuoteSelector","exact":"This, in turn, implies that if we want the variance σ2f′of the subsequent pre-activations f′to be the same as the variance σ2f of the original pre-activations f during the forwardpass, we should set:","prefix":"gradient problems, respectively.","suffix":"σ2Ω = 2Dh, (7.31)where Dh is the"}]}]}
>```
>%%
>*%%PREFIX%%gradient problems, respectively.%%HIGHLIGHT%% ==This, in turn, implies that if we want the variance σ2f′of the subsequent pre-activations f′to be the same as the variance σ2f of the original pre-activations f during the forwardpass, we should set:== %%POSTFIX%%σ2Ω = 2Dh, (7.31)where Dh is the*
>%%LINK%%[[#^7oq76twk7zm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7oq76twk7zm


>%%
>```annotation-json
>{"created":"2024-10-08T16:41:08.234Z","text":"What is He initialisation?","updated":"2024-10-08T16:41:08.234Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":244226,"end":244359},{"type":"TextQuoteSelector","exact":"σ2Ω = 2Dh, (7.31)where Dh is the dimension of the original layer to which the weights were applied. Thisis known as He initialization","prefix":" the forwardpass, we should set:","suffix":".7.5.2 Initialization for backwa"}]}]}
>```
>%%
>*%%PREFIX%%the forwardpass, we should set:%%HIGHLIGHT%% ==σ2Ω = 2Dh, (7.31)where Dh is the dimension of the original layer to which the weights were applied. Thisis known as He initialization== %%POSTFIX%%.7.5.2 Initialization for backwa*
>%%LINK%%[[#^ej5ko3drdx|show annotation]]
>%%COMMENT%%
>What is He initialisation?
>%%TAGS%%
>#question
^ej5ko3drdx


>%%
>```annotation-json
>{"created":"2024-10-08T16:41:57.460Z","text":"How do we initialise for backward pass?","updated":"2024-10-08T16:41:57.460Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":244366,"end":244398},{"type":"TextQuoteSelector","exact":"Initialization for backward pass","prefix":"nown as He initialization.7.5.2 ","suffix":"A similar argument establishes h"}]}]}
>```
>%%
>*%%PREFIX%%nown as He initialization.7.5.2%%HIGHLIGHT%% ==Initialization for backward pass== %%POSTFIX%%A similar argument establishes h*
>%%LINK%%[[#^ue4bjnnyh7e|show annotation]]
>%%COMMENT%%
>How do we initialise for backward pass?
>%%TAGS%%
>#question
^ue4bjnnyh7e


>%%
>```annotation-json
>{"created":"2024-10-08T16:42:34.350Z","updated":"2024-10-08T16:42:34.350Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":244398,"end":244634},{"type":"TextQuoteSelector","exact":"A similar argument establishes how the variance of the gradients ∂l/∂fk changes duringthe backward pass. During the backward pass, we multiply by the transpose ΩT of theweight matrix (equation 7.24), so the equivalent expression becomes","prefix":"Initialization for backward pass","suffix":":This work is subject to a Creat"}]}]}
>```
>%%
>*%%PREFIX%%Initialization for backward pass%%HIGHLIGHT%% ==A similar argument establishes how the variance of the gradients ∂l/∂fk changes duringthe backward pass. During the backward pass, we multiply by the transpose ΩT of theweight matrix (equation 7.24), so the equivalent expression becomes== %%POSTFIX%%:This work is subject to a Creat*
>%%LINK%%[[#^w2yzmzkav7q|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w2yzmzkav7q


>%%
>```annotation-json
>{"created":"2024-10-08T16:42:42.614Z","updated":"2024-10-08T16:42:42.614Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":244742,"end":244826},{"type":"TextQuoteSelector","exact":"σ2Ω = 2Dh′, (7.32)where Dh′is the dimension of the layer that the weights feed into.","prefix":"ss.7.6 Example training code 111","suffix":"7.5.3 Initialization for both fo"}]}]}
>```
>%%
>*%%PREFIX%%ss.7.6 Example training code 111%%HIGHLIGHT%% ==σ2Ω = 2Dh′, (7.32)where Dh′is the dimension of the layer that the weights feed into.== %%POSTFIX%%7.5.3 Initialization for both fo*
>%%LINK%%[[#^i317k595dx|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^i317k595dx


>%%
>```annotation-json
>{"created":"2024-10-08T16:43:43.632Z","text":"How to initialise for both forward and backward pass?","updated":"2024-10-08T16:43:43.632Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":244832,"end":244881},{"type":"TextQuoteSelector","exact":"Initialization for both forward and backward pass","prefix":"hat the weights feed into.7.5.3 ","suffix":"If the weight matrix Ω is not sq"}]}]}
>```
>%%
>*%%PREFIX%%hat the weights feed into.7.5.3%%HIGHLIGHT%% ==Initialization for both forward and backward pass== %%POSTFIX%%If the weight matrix Ω is not sq*
>%%LINK%%[[#^lqnlc91mw6|show annotation]]
>%%COMMENT%%
>How to initialise for both forward and backward pass?
>%%TAGS%%
>#question
^lqnlc91mw6


>%%
>```annotation-json
>{"created":"2024-10-08T16:44:09.732Z","updated":"2024-10-08T16:44:09.732Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":244881,"end":245494},{"type":"TextQuoteSelector","exact":"If the weight matrix Ω is not square (i.e., there are different numbers of hidden unitsin the two adjacent layers, so Dh and Dh′differ), then it is not possible to choose thevariance to satisfy both equations 7.31 and 7.32 simultaneously. One possible compromiseis to use the mean (Dh + Dh′)/2 as a proxy for the number of terms, which gives:σ2Ω = 4Dh + Dh′. (7.33)Figure 7.7 shows empirically that both the variance of the hidden units in the forward Problem 7.15Notebook 7.3Initializationpass and the variance of the gradients in the backward pass remain stable when theparameters are initialized appropriately.","prefix":"r both forward and backward pass","suffix":"7.6 Example training codeThe pri"}]}]}
>```
>%%
>*%%PREFIX%%r both forward and backward pass%%HIGHLIGHT%% ==If the weight matrix Ω is not square (i.e., there are different numbers of hidden unitsin the two adjacent layers, so Dh and Dh′differ), then it is not possible to choose thevariance to satisfy both equations 7.31 and 7.32 simultaneously. One possible compromiseis to use the mean (Dh + Dh′)/2 as a proxy for the number of terms, which gives:σ2Ω = 4Dh + Dh′. (7.33)Figure 7.7 shows empirically that both the variance of the hidden units in the forward Problem 7.15Notebook 7.3Initializationpass and the variance of the gradients in the backward pass remain stable when theparameters are initialized appropriately.== %%POSTFIX%%7.6 Example training codeThe pri*
>%%LINK%%[[#^j97cpg3ehrl|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^j97cpg3ehrl


>%%
>```annotation-json
>{"created":"2024-10-08T16:44:58.417Z","updated":"2024-10-08T16:44:58.417Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":245498,"end":245519},{"type":"TextQuoteSelector","exact":"Example training code","prefix":"e initialized appropriately.7.6 ","suffix":"The primary focus of this book i"}]}]}
>```
>%%
>*%%PREFIX%%e initialized appropriately.7.6%%HIGHLIGHT%% ==Example training code== %%POSTFIX%%The primary focus of this book i*
>%%LINK%%[[#^s2lv0kzum5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^s2lv0kzum5


>%%
>```annotation-json
>{"created":"2024-10-08T16:48:00.073Z","updated":"2024-10-08T16:48:00.073Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":249364,"end":249379},{"type":"TextQuoteSelector","exact":"Backpropagation","prefix":"sure the model performance.Notes","suffix":": Eﬀicient reuse of partial comp"}]}]}
>```
>%%
>*%%PREFIX%%sure the model performance.Notes%%HIGHLIGHT%% ==Backpropagation== %%POSTFIX%%: Eﬀicient reuse of partial comp*
>%%LINK%%[[#^60lyhc5f1rq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^60lyhc5f1rq


>%%
>```annotation-json
>{"created":"2024-10-08T16:48:02.228Z","updated":"2024-10-08T16:48:02.228Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":250755,"end":250769},{"type":"TextQuoteSelector","exact":"Initialization","prefix":"(2008) and Baydin et al. (2018).","suffix":": He initialization was first in"}]}]}
>```
>%%
>*%%PREFIX%%(2008) and Baydin et al. (2018).%%HIGHLIGHT%% ==Initialization== %%POSTFIX%%: He initialization was first in*
>%%LINK%%[[#^typboj9fg2|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^typboj9fg2


>%%
>```annotation-json
>{"created":"2024-10-08T16:48:09.164Z","updated":"2024-10-08T16:48:09.164Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":250854,"end":250860},{"type":"TextQuoteSelector","exact":"Glorot","prefix":" (2015). It follows closelyfrom ","suffix":" or Xavier initialization (Gloro"}]}]}
>```
>%%
>*%%PREFIX%%(2015). It follows closelyfrom%%HIGHLIGHT%% ==Glorot== %%POSTFIX%%or Xavier initialization (Gloro*
>%%LINK%%[[#^d9ffq67rp0u|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^d9ffq67rp0u


>%%
>```annotation-json
>{"created":"2024-10-08T16:48:10.776Z","updated":"2024-10-08T16:48:10.776Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":250864,"end":250870},{"type":"TextQuoteSelector","exact":"Xavier","prefix":"t follows closelyfrom Glorot or ","suffix":" initialization (Glorot & Bengio"}]}]}
>```
>%%
>*%%PREFIX%%t follows closelyfrom Glorot or%%HIGHLIGHT%% ==Xavier== %%POSTFIX%%initialization (Glorot & Bengio*
>%%LINK%%[[#^lz7vhroeoql|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lz7vhroeoql


>%%
>```annotation-json
>{"created":"2024-10-08T16:48:55.025Z","updated":"2024-10-08T16:48:55.025Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":251913,"end":251958},{"type":"TextQuoteSelector","exact":"Layer-sequential unit variance initialization","prefix":"eempirically observed variance. ","suffix":" (Mishkin & Matas,2016) is an ex"}]}]}
>```
>%%
>*%%PREFIX%%eempirically observed variance.%%HIGHLIGHT%% ==Layer-sequential unit variance initialization== %%POSTFIX%%(Mishkin & Matas,2016) is an ex*
>%%LINK%%[[#^chc0n7wnicb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^chc0n7wnicb


>%%
>```annotation-json
>{"created":"2024-10-08T16:49:24.211Z","updated":"2024-10-08T16:49:24.211Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":252376,"end":252400},{"type":"TextQuoteSelector","exact":"Activation normalization","prefix":"nton the maximum gradient norm. ","suffix":" or ActNorm adds a learnable sca"}]}]}
>```
>%%
>*%%PREFIX%%nton the maximum gradient norm.%%HIGHLIGHT%% ==Activation normalization== %%POSTFIX%%or ActNorm adds a learnable sca*
>%%LINK%%[[#^2a8gifth3zb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2a8gifth3zb


>%%
>```annotation-json
>{"created":"2024-10-08T16:49:46.165Z","updated":"2024-10-08T16:49:46.165Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":252856,"end":252865},{"type":"TextQuoteSelector","exact":"BatchNorm","prefix":"ese methods are schemes such as ","suffix":" (Ioffe & Szegedy, 2015), inwhic"}]}]}
>```
>%%
>*%%PREFIX%%ese methods are schemes such as%%HIGHLIGHT%% ==BatchNorm== %%POSTFIX%%(Ioffe & Szegedy, 2015), inwhic*
>%%LINK%%[[#^f63qk8q7o7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f63qk8q7o7


>%%
>```annotation-json
>{"created":"2024-10-08T16:49:56.578Z","updated":"2024-10-08T16:49:56.578Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":253134,"end":253155},{"type":"TextQuoteSelector","exact":"ConvolutionOrthogonal","prefix":"ic architectures, including the ","suffix":" initializer (Xiaoet al., 2018a)"}]}]}
>```
>%%
>*%%PREFIX%%ic architectures, including the%%HIGHLIGHT%% ==ConvolutionOrthogonal== %%POSTFIX%%initializer (Xiaoet al., 2018a)*
>%%LINK%%[[#^xits4ee613|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xits4ee613


>%%
>```annotation-json
>{"created":"2024-10-08T16:50:14.375Z","updated":"2024-10-08T16:50:14.375Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":253216,"end":253221},{"type":"TextQuoteSelector","exact":"Fixup","prefix":"8a) for convolutional networks, ","suffix":" (Zhang et al., 2019a) for resid"}]}]}
>```
>%%
>*%%PREFIX%%8a) for convolutional networks,%%HIGHLIGHT%% ==Fixup== %%POSTFIX%%(Zhang et al., 2019a) for resid*
>%%LINK%%[[#^ss8m7xay8q|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ss8m7xay8q


>%%
>```annotation-json
>{"created":"2024-10-08T16:50:19.457Z","updated":"2024-10-08T16:50:19.457Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":253270,"end":253276},{"type":"TextQuoteSelector","exact":"TFixup","prefix":"019a) for residual networks, and","suffix":" (Huang et al., 2020a) and DTFix"}]}]}
>```
>%%
>*%%PREFIX%%019a) for residual networks, and%%HIGHLIGHT%% ==TFixup== %%POSTFIX%%(Huang et al., 2020a) and DTFix*
>%%LINK%%[[#^lmh0n10gshe|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lmh0n10gshe


>%%
>```annotation-json
>{"created":"2024-10-08T16:50:21.386Z","updated":"2024-10-08T16:50:21.386Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":253303,"end":253310},{"type":"TextQuoteSelector","exact":"DTFixup","prefix":"Fixup (Huang et al., 2020a) and ","suffix":" (Xu et al., 2021b) for transfor"}]}]}
>```
>%%
>*%%PREFIX%%Fixup (Huang et al., 2020a) and%%HIGHLIGHT%% ==DTFixup== %%POSTFIX%%(Xu et al., 2021b) for transfor*
>%%LINK%%[[#^37bmyqvci22|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^37bmyqvci22


>%%
>```annotation-json
>{"created":"2024-10-08T16:50:30.004Z","updated":"2024-10-08T16:50:30.004Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":253347,"end":253375},{"type":"TextQuoteSelector","exact":"Reducing memory requirements","prefix":"et al., 2021b) for transformers.","suffix":": Training neural networks is me"}]}]}
>```
>%%
>*%%PREFIX%%et al., 2021b) for transformers.%%HIGHLIGHT%% ==Reducing memory requirements== %%POSTFIX%%: Training neural networks is me*
>%%LINK%%[[#^rwtl5ei80oo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rwtl5ei80oo


>%%
>```annotation-json
>{"created":"2024-10-08T16:51:24.625Z","updated":"2024-10-08T16:51:24.625Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":254550,"end":254570},{"type":"TextQuoteSelector","exact":"Distributed training","prefix":"to reducing memory requirements.","suffix":": For suﬀiciently large models, "}]}]}
>```
>%%
>*%%PREFIX%%to reducing memory requirements.%%HIGHLIGHT%% ==Distributed training== %%POSTFIX%%: For suﬀiciently large models,*
>%%LINK%%[[#^z6guh5akcu|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^z6guh5akcu


>%%
>```annotation-json
>{"created":"2024-10-08T16:51:56.154Z","updated":"2024-10-08T16:51:56.154Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":254717,"end":254735},{"type":"TextQuoteSelector","exact":"istributedtraining","prefix":"sor. In this case, we must use d","suffix":", in which training takes place "}]}]}
>```
>%%
>*%%PREFIX%%sor. In this case, we must use d%%HIGHLIGHT%% ==istributedtraining== %%POSTFIX%%, in which training takes place*
>%%LINK%%[[#^5w689ygigij|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5w689ygigij


>%%
>```annotation-json
>{"created":"2024-10-08T16:52:01.777Z","updated":"2024-10-08T16:52:01.777Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":254854,"end":254870},{"type":"TextQuoteSelector","exact":"data parallelism","prefix":"alapproaches to parallelism. In ","suffix":", each processor or node contain"}]}]}
>```
>%%
>*%%PREFIX%%alapproaches to parallelism. In%%HIGHLIGHT%% ==data parallelism== %%POSTFIX%%, each processor or node contain*
>%%LINK%%[[#^ayom1sf2hq4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ayom1sf2hq4


>%%
>```annotation-json
>{"created":"2024-10-08T16:52:05.911Z","updated":"2024-10-08T16:52:05.911Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":255157,"end":255177},{"type":"TextQuoteSelector","exact":"synchronous training","prefix":"in consistent. This is known as ","suffix":". The synchronizationrequired to"}]}]}
>```
>%%
>*%%PREFIX%%in consistent. This is known as%%HIGHLIGHT%% ==synchronous training== %%POSTFIX%%. The synchronizationrequired to*
>%%LINK%%[[#^n7h8yx1zj2s|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^n7h8yx1zj2s


>%%
>```annotation-json
>{"created":"2024-10-08T16:52:13.127Z","updated":"2024-10-08T16:52:13.127Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":255356,"end":255363},{"type":"TextQuoteSelector","exact":"Hogwild","prefix":"s training. For example, in the ","suffix":"! algorithm (Rechtet al., 2011),"}]}]}
>```
>%%
>*%%PREFIX%%s training. For example, in the%%HIGHLIGHT%% ==Hogwild== %%POSTFIX%%! algorithm (Rechtet al., 2011),*
>%%LINK%%[[#^f1yntqd76xd|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^f1yntqd76xd


>%%
>```annotation-json
>{"created":"2024-10-08T16:52:44.117Z","updated":"2024-10-08T16:52:44.117Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":255951,"end":255977},{"type":"TextQuoteSelector","exact":"Pipeline model parallelism","prefix":" in the memory of asingle node. ","suffix":" stores different layers of the "}]}]}
>```
>%%
>*%%PREFIX%%in the memory of asingle node.%%HIGHLIGHT%% ==Pipeline model parallelism== %%POSTFIX%%stores different layers of the*
>%%LINK%%[[#^1ud687ij4e1|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^1ud687ij4e1


>%%
>```annotation-json
>{"created":"2024-10-08T16:53:35.029Z","updated":"2024-10-08T16:53:35.029Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":256635,"end":256659},{"type":"TextQuoteSelector","exact":"tensor model parallelism","prefix":"nan et al., 2021a). Finally, in ","suffix":", computation at a single networ"}]}]}
>```
>%%
>*%%PREFIX%%nan et al., 2021a). Finally, in%%HIGHLIGHT%% ==tensor model parallelism== %%POSTFIX%%, computation at a single networ*
>%%LINK%%[[#^po07fk4dzyb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^po07fk4dzyb


>%%
>```annotation-json
>{"created":"2024-11-01T11:08:28.514Z","updated":"2024-11-01T11:08:28.514Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":262376,"end":262588},{"type":"TextQuoteSelector","exact":"We will see that the test errors have three distinct causes and that their relativecontributions depend on (i) the inherent uncertainty in the task, (ii) the amount oftraining data, and (iii) the choice of model.","prefix":"eneralize well to new test data.","suffix":" The latter dependency raises th"}]}]}
>```
>%%
>*%%PREFIX%%eneralize well to new test data.%%HIGHLIGHT%% ==We will see that the test errors have three distinct causes and that their relativecontributions depend on (i) the inherent uncertainty in the task, (ii) the amount oftraining data, and (iii) the choice of model.== %%POSTFIX%%The latter dependency raises th*
>%%LINK%%[[#^vccgc9roxge|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^vccgc9roxge


>%%
>```annotation-json
>{"created":"2024-11-01T11:12:58.761Z","updated":"2024-11-01T11:12:58.761Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":266282,"end":266580},{"type":"TextQuoteSelector","exact":" This decreases the probability of the correctanswers and thus increases the negative log-likelihood. This increasing confidence is aside-effect of the softmax function; the pre-softmax activations are driven to increasinglyextreme values to make the probability of the training data approach one (","prefix":" but with increasing confidence.","suffix":"see figure 5.10).8.2 Sources of "}]}]}
>```
>%%
>*%%PREFIX%%but with increasing confidence.%%HIGHLIGHT%% ==This decreases the probability of the correctanswers and thus increases the negative log-likelihood. This increasing confidence is aside-effect of the softmax function; the pre-softmax activations are driven to increasinglyextreme values to make the probability of the training data approach one (== %%POSTFIX%%see figure 5.10).8.2 Sources of*
>%%LINK%%[[#^jy76qhao2gg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jy76qhao2gg


>%%
>```annotation-json
>{"created":"2024-11-01T11:18:12.463Z","updated":"2024-11-01T11:18:12.463Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":269372,"end":269397},{"type":"TextQuoteSelector","exact":"Noise, bias, and variance","prefix":"his region was calculated.8.2.1 ","suffix":"There are three possible sources"}]}]}
>```
>%%
>*%%PREFIX%%his region was calculated.8.2.1%%HIGHLIGHT%% ==Noise, bias, and variance== %%POSTFIX%%There are three possible sources*
>%%LINK%%[[#^ataoe9z1r9d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ataoe9z1r9d


>%%
>```annotation-json
>{"created":"2024-11-01T11:19:04.462Z","updated":"2024-11-01T11:19:04.462Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":269510,"end":270349},{"type":"TextQuoteSelector","exact":"Noise The data generation process includes the addition of noise, so there are multiplepossible valid outputs y for each input x (figure 8.5a). This source of error is insurmount-able for the test data. Note that it does not necessarily limit the training performance;we will likely never see the same input x twice during training, so it is still possible tofit the training data perfectly.Noise may arise because there is a genuine stochastic element to the data generationprocess, because some of the data are mislabeled, or because there are further explanatoryvariables that were not observed. In rare cases, noise may be absent; for example,a network might approximate a function that is deterministic but requires significantcomputation to evaluate. However, noise is usually a fundamental limitation on thepossible test performance","prefix":"riancerespectively (figure 8.5):","suffix":".Bias A second potential source "}]}]}
>```
>%%
>*%%PREFIX%%riancerespectively (figure 8.5):%%HIGHLIGHT%% ==Noise The data generation process includes the addition of noise, so there are multiplepossible valid outputs y for each input x (figure 8.5a). This source of error is insurmount-able for the test data. Note that it does not necessarily limit the training performance;we will likely never see the same input x twice during training, so it is still possible tofit the training data perfectly.Noise may arise because there is a genuine stochastic element to the data generationprocess, because some of the data are mislabeled, or because there are further explanatoryvariables that were not observed. In rare cases, noise may be absent; for example,a network might approximate a function that is deterministic but requires significantcomputation to evaluate. However, noise is usually a fundamental limitation on thepossible test performance== %%POSTFIX%%.Bias A second potential source*
>%%LINK%%[[#^2yibjcisvyr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2yibjcisvyr


>%%
>```annotation-json
>{"created":"2024-11-01T11:19:26.555Z","updated":"2024-11-01T11:19:26.555Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":270350,"end":270662},{"type":"TextQuoteSelector","exact":"Bias A second potential source of error may occur because the model is not flexibleenough to fit the true function perfectly. For example, the three-region neural networkmodel cannot exactly describe the quasi-sinusoidal function, even when the parametersare chosen optimally (figure 8.5b). This is known as bias","prefix":"on thepossible test performance.","suffix":".This work is subject to a Creat"}]}]}
>```
>%%
>*%%PREFIX%%on thepossible test performance.%%HIGHLIGHT%% ==Bias A second potential source of error may occur because the model is not flexibleenough to fit the true function perfectly. For example, the three-region neural networkmodel cannot exactly describe the quasi-sinusoidal function, even when the parametersare chosen optimally (figure 8.5b). This is known as bias== %%POSTFIX%%.This work is subject to a Creat*
>%%LINK%%[[#^57pwqumrggf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^57pwqumrggf


>%%
>```annotation-json
>{"created":"2024-11-01T11:21:41.872Z","updated":"2024-11-01T11:21:41.872Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":270765,"end":271373},{"type":"TextQuoteSelector","exact":"Variance We have limited training examples, and there is no way to distinguish sys-tematic changes in the underlying function from noise in the underlying data. Whenwe fit a model, we do not get the closest possible approximation to the true underly-ing function. Indeed, for different training datasets, the result will be slightly differenteach time. This additional source of variability in the fitted function is termed variance(figure 8.5c). In practice, there might also be additional variance due to the stochasticlearning algorithm, which does not necessarily converge to the same solution each time.","prefix":"T Press.8.2 Sources of error 123","suffix":"8.2.2 Mathematical formulation o"}]}]}
>```
>%%
>*%%PREFIX%%T Press.8.2 Sources of error 123%%HIGHLIGHT%% ==Variance We have limited training examples, and there is no way to distinguish sys-tematic changes in the underlying function from noise in the underlying data. Whenwe fit a model, we do not get the closest possible approximation to the true underly-ing function. Indeed, for different training datasets, the result will be slightly differenteach time. This additional source of variability in the fitted function is termed variance(figure 8.5c). In practice, there might also be additional variance due to the stochasticlearning algorithm, which does not necessarily converge to the same solution each time.== %%POSTFIX%%8.2.2 Mathematical formulation o*
>%%LINK%%[[#^kwiqp46ckz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kwiqp46ckz


>%%
>```annotation-json
>{"created":"2024-11-01T11:31:05.283Z","updated":"2024-11-01T11:31:05.283Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":273172,"end":275020},{"type":"TextQuoteSelector","exact":"noise σ2. We can see that the expected loss has been broken down into two terms; thefirst term is the squared deviation between the model and the true function mean, andthe second term is the noise.The first term can be further partitioned into bias and variance. The parameters φ ofthe model f[x,φ] depend on the training dataset D = {xi,yi}, so more properly, we shouldwrite f[x,φ[D]]. The training dataset is a random sample from the data generationprocess; with a different sample of training data, we would learn different parametervalues. The expected model output fμ[x] with respect to all possible datasets D is hence:fμ[x] = ED[f[x,φ[D]]]. (8.4)Returning to the first term of equation 8.3, we add and subtract fμ[x] and expand:(f[x,φ[D]]−μ[x])2 (8.5)=((f[x,φ[D]]−fμ[x])+ (fμ[x] −μ[x]))2= (f[x,φ[D]]−fμ[x])2 + 2(f[x,φ[D]]−fμ[x])(fμ[x]−μ[x])+ (fμ[x]−μ[x])2.We then take the expectation with respect to the training dataset D:ED[(f[x,φ[D]] −μ[x])2]= ED[(f[x,φ[D]] −fμ[x])2]+ (fμ[x] −μ[x])2, (8.6)where we have simplified using similar steps as for equation 8.3. Finally, we substitutethis result into equation 8.3:ED[Ey[L[x]]]= ED[(f[x,φ[D]] −fμ[x])2]︸ ︷︷ ︸variance+ (fμ[x]−μ[x])2︸ ︷︷ ︸bias+ σ2.︸︷︷︸noise(8.7)This equation says that the expected loss after considering the uncertainty in the trainingdata D and the test data y consists of three additive components. The variance isuncertainty in the fitted model due to the particular training dataset we sample. The biasis the systematic deviation of the model from the mean of the function we are modeling.The noise is the inherent uncertainty in the true mapping from input to output. Thesethree sources of error will be present for any task. They combine additively for linearregression with a least squares loss. However, their interaction can be more complex forother types of problems.","prefix":".com.124 8 Measuring performance","suffix":"8.3 Reducing errorIn the previou"}]}]}
>```
>%%
>*%%PREFIX%%.com.124 8 Measuring performance%%HIGHLIGHT%% ==noise σ2. We can see that the expected loss has been broken down into two terms; thefirst term is the squared deviation between the model and the true function mean, andthe second term is the noise.The first term can be further partitioned into bias and variance. The parameters φ ofthe model f[x,φ] depend on the training dataset D = {xi,yi}, so more properly, we shouldwrite f[x,φ[D]]. The training dataset is a random sample from the data generationprocess; with a different sample of training data, we would learn different parametervalues. The expected model output fμ[x] with respect to all possible datasets D is hence:fμ[x] = ED[f[x,φ[D]]]. (8.4)Returning to the first term of equation 8.3, we add and subtract fμ[x] and expand:(f[x,φ[D]]−μ[x])2 (8.5)=((f[x,φ[D]]−fμ[x])+ (fμ[x] −μ[x]))2= (f[x,φ[D]]−fμ[x])2 + 2(f[x,φ[D]]−fμ[x])(fμ[x]−μ[x])+ (fμ[x]−μ[x])2.We then take the expectation with respect to the training dataset D:ED[(f[x,φ[D]] −μ[x])2]= ED[(f[x,φ[D]] −fμ[x])2]+ (fμ[x] −μ[x])2, (8.6)where we have simplified using similar steps as for equation 8.3. Finally, we substitutethis result into equation 8.3:ED[Ey[L[x]]]= ED[(f[x,φ[D]] −fμ[x])2]︸ ︷︷ ︸variance+ (fμ[x]−μ[x])2︸ ︷︷ ︸bias+ σ2.︸︷︷︸noise(8.7)This equation says that the expected loss after considering the uncertainty in the trainingdata D and the test data y consists of three additive components. The variance isuncertainty in the fitted model due to the particular training dataset we sample. The biasis the systematic deviation of the model from the mean of the function we are modeling.The noise is the inherent uncertainty in the true mapping from input to output. Thesethree sources of error will be present for any task. They combine additively for linearregression with a least squares loss. However, their interaction can be more complex forother types of problems.== %%POSTFIX%%8.3 Reducing errorIn the previou*
>%%LINK%%[[#^68e8gxwu7nj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^68e8gxwu7nj


>%%
>```annotation-json
>{"created":"2024-11-01T11:31:16.002Z","updated":"2024-11-01T11:31:16.002Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":271417,"end":273094},{"type":"TextQuoteSelector","exact":"We now make the notions of noise, bias, and variance mathematically precise. Considera 1D regression problem where the data generation process has additive noise with vari-ance σ2 (e.g., figure 8.3); we can observe different outputs y for the same input x, so for Appendix C.2Expectationeach x, there is a distribution Pr(y|x) with expected value (mean) μ[x]:μ[x] = Ey[y[x]] =∫y[x]Pr(y|x)dy, (8.1)and fixed noise σ2 = Ey[(μ[x] −y[x])2]. Here we have used the notation y[x] to specifythat we are considering the output y at a given input position x.Now consider a least squares loss between the model prediction f[x,φ] at position xand the observed value y[x] at that position:L[x] = (f[x,φ] −y[x])2 (8.2)=((f[x,φ] −μ[x])+ (μ[x] −y[x]))2= (f[x,φ] −μ[x])2 + 2(f[x,φ] −μ[x])(μ[x] −y[x])+ (μ[x] −y[x])2,where we have both added and subtracted the mean μ[x] of the underlying function inthe second line and have expanded out the squared term in the third line.The underlying function is stochastic, so this loss depends on the particular y[x] weobserve. The expected loss is:Ey[L[x]] = Ey[(f[x,φ]−μ[x])2 + 2(f[x,φ]−μ[x])(μ[x]−y[x])+ (μ[x]−y[x])2]= (f[x,φ]−μ[x])2 + 2(f[x,φ] −μ[x])(μ[x]−Ey [y[x]])+ Ey[(μ[x]−y[x])2]= (f[x,φ]−μ[x])2 + 2(f[x,φ]−μ[x])·0 + Ey[(μ[x]−y[x])2]= (f[x,φ] −μ[x])2 + σ2, (8.3)where we have made use of the rules for manipulating expectations. In the second line, we Appendix C.2.1Expectation ruleshave distributed the expectation operator and removed it from terms with no dependenceon y[x], and in the third line, we note that the second term is zero since Ey[y[x]] = μ[x]by definition. Finally, in the fourth line, we have substituted in the definition of the","prefix":"atical formulation of test error","suffix":"Draft: please send errata to udl"}]}]}
>```
>%%
>*%%PREFIX%%atical formulation of test error%%HIGHLIGHT%% ==We now make the notions of noise, bias, and variance mathematically precise. Considera 1D regression problem where the data generation process has additive noise with vari-ance σ2 (e.g., figure 8.3); we can observe different outputs y for the same input x, so for Appendix C.2Expectationeach x, there is a distribution Pr(y|x) with expected value (mean) μ[x]:μ[x] = Ey[y[x]] =∫y[x]Pr(y|x)dy, (8.1)and fixed noise σ2 = Ey[(μ[x] −y[x])2]. Here we have used the notation y[x] to specifythat we are considering the output y at a given input position x.Now consider a least squares loss between the model prediction f[x,φ] at position xand the observed value y[x] at that position:L[x] = (f[x,φ] −y[x])2 (8.2)=((f[x,φ] −μ[x])+ (μ[x] −y[x]))2= (f[x,φ] −μ[x])2 + 2(f[x,φ] −μ[x])(μ[x] −y[x])+ (μ[x] −y[x])2,where we have both added and subtracted the mean μ[x] of the underlying function inthe second line and have expanded out the squared term in the third line.The underlying function is stochastic, so this loss depends on the particular y[x] weobserve. The expected loss is:Ey[L[x]] = Ey[(f[x,φ]−μ[x])2 + 2(f[x,φ]−μ[x])(μ[x]−y[x])+ (μ[x]−y[x])2]= (f[x,φ]−μ[x])2 + 2(f[x,φ] −μ[x])(μ[x]−Ey [y[x]])+ Ey[(μ[x]−y[x])2]= (f[x,φ]−μ[x])2 + 2(f[x,φ]−μ[x])·0 + Ey[(μ[x]−y[x])2]= (f[x,φ] −μ[x])2 + σ2, (8.3)where we have made use of the rules for manipulating expectations. In the second line, we Appendix C.2.1Expectation ruleshave distributed the expectation operator and removed it from terms with no dependenceon y[x], and in the third line, we note that the second term is zero since Ey[y[x]] = μ[x]by definition. Finally, in the fourth line, we have substituted in the definition of the== %%POSTFIX%%Draft: please send errata to udl*
>%%LINK%%[[#^3ymui5j18lz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3ymui5j18lz


>%%
>```annotation-json
>{"created":"2024-11-01T12:09:55.895Z","updated":"2024-11-01T12:09:55.895Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":275444,"end":276210},{"type":"TextQuoteSelector","exact":"Reducing varianceRecall that the variance results from limited noisy training data. Fitting the modelto two different training sets results in slightly different parameters. It follows we canreduce the variance by increasing the quantity of training data. This averages out theinherent noise and ensures that the input space is well sampled.Figure 8.6 shows the effect of training with 6, 10, and 100 samples. For each datasetsize, we show the best-fitting model for three training datasets. With only six samples,the fitted function is quite different each time: the variance is significant. As we increasethe number of samples, the fitted models become very similar, and the variance reduces.In general, adding training data almost always improves test performance","prefix":"ess.8.3 Reducing error 1258.3.1 ","suffix":".8.3.2 Reducing biasThe bias ter"}]}]}
>```
>%%
>*%%PREFIX%%ess.8.3 Reducing error 1258.3.1%%HIGHLIGHT%% ==Reducing varianceRecall that the variance results from limited noisy training data. Fitting the modelto two different training sets results in slightly different parameters. It follows we canreduce the variance by increasing the quantity of training data. This averages out theinherent noise and ensures that the input space is well sampled.Figure 8.6 shows the effect of training with 6, 10, and 100 samples. For each datasetsize, we show the best-fitting model for three training datasets. With only six samples,the fitted function is quite different each time: the variance is significant. As we increasethe number of samples, the fitted models become very similar, and the variance reduces.In general, adding training data almost always improves test performance== %%POSTFIX%%.8.3.2 Reducing biasThe bias ter*
>%%LINK%%[[#^li3e6asq0wo|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^li3e6asq0wo


>%%
>```annotation-json
>{"created":"2024-11-01T12:10:23.256Z","updated":"2024-11-01T12:10:23.256Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":276217,"end":276871},{"type":"TextQuoteSelector","exact":"Reducing biasThe bias term results from the inability of the model to describe the true underlyingfunction. This suggests that we can reduce this error by making the model more flexible.This is usually done by increasing the model capacity. For neural networks, this meansadding more hidden units and/or hidden layers.In the simplified model, adding capacity corresponds to adding more hidden unitsso that the interval [0,1] is divided into more linear regions. Figures 8.7a–c show that(unsurprisingly) this does indeed reduce the bias; as we increase the number of linearregions to ten, the model becomes flexible enough to fit the true function closely","prefix":"improves test performance.8.3.2 ","suffix":".8.3.3 Bias-variance trade-offHo"}]}]}
>```
>%%
>*%%PREFIX%%improves test performance.8.3.2%%HIGHLIGHT%% ==Reducing biasThe bias term results from the inability of the model to describe the true underlyingfunction. This suggests that we can reduce this error by making the model more flexible.This is usually done by increasing the model capacity. For neural networks, this meansadding more hidden units and/or hidden layers.In the simplified model, adding capacity corresponds to adding more hidden unitsso that the interval [0,1] is divided into more linear regions. Figures 8.7a–c show that(unsurprisingly) this does indeed reduce the bias; as we increase the number of linearregions to ten, the model becomes flexible enough to fit the true function closely== %%POSTFIX%%.8.3.3 Bias-variance trade-offHo*
>%%LINK%%[[#^lyyc2g6f4w|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lyyc2g6f4w


>%%
>```annotation-json
>{"created":"2024-11-01T12:11:59.264Z","updated":"2024-11-01T12:11:59.264Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":276878,"end":277217},{"type":"TextQuoteSelector","exact":"Bias-variance trade-offHowever, figures 8.7d–f show an unexpected side-effect of increasing the model capac-ity. For a fixed-size training dataset, the variance term increases as the model capacityincreases. Consequently, increasing the model capacity does not necessarily reduce thetest error. This is known as the bias-variance trade-off","prefix":"the true function closely.8.3.3 ","suffix":".Figure 8.8 explores this phenom"}]}]}
>```
>%%
>*%%PREFIX%%the true function closely.8.3.3%%HIGHLIGHT%% ==Bias-variance trade-offHowever, figures 8.7d–f show an unexpected side-effect of increasing the model capac-ity. For a fixed-size training dataset, the variance term increases as the model capacityincreases. Consequently, increasing the model capacity does not necessarily reduce thetest error. This is known as the bias-variance trade-off== %%POSTFIX%%.Figure 8.8 explores this phenom*
>%%LINK%%[[#^iwc9orxkzva|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^iwc9orxkzva


>%%
>```annotation-json
>{"created":"2024-11-01T12:12:35.597Z","updated":"2024-11-01T12:12:35.597Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":277818,"end":278070},{"type":"TextQuoteSelector","exact":"We’ve seen that as we add capacity to the model, the bias decreases, but the varianceincreases for a fixed-size training dataset. This suggests that there is an optimal capacitywhere the bias is not too large and the variance is still relatively small.","prefix":"nomenon is known as overfitting.","suffix":" Figure 8.9 showshow these terms"}]}]}
>```
>%%
>*%%PREFIX%%nomenon is known as overfitting.%%HIGHLIGHT%% ==We’ve seen that as we add capacity to the model, the bias decreases, but the varianceincreases for a fixed-size training dataset. This suggests that there is an optimal capacitywhere the bias is not too large and the variance is still relatively small.== %%POSTFIX%%Figure 8.9 showshow these terms*
>%%LINK%%[[#^61b5xq9f5ct|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^61b5xq9f5ct


>%%
>```annotation-json
>{"created":"2024-11-01T12:12:54.668Z","updated":"2024-11-01T12:12:54.668Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":277565,"end":277818},{"type":"TextQuoteSelector","exact":"Thismodel has more flexibility, but this is disadvantageous; the model certainly fits the databetter, and the training error will be lower, but much of the extra descriptive power isdevoted to modeling the noise. This phenomenon is known as overfitting.","prefix":"ons to the same three datasets. ","suffix":"We’ve seen that as we add capaci"}]}]}
>```
>%%
>*%%PREFIX%%ons to the same three datasets.%%HIGHLIGHT%% ==Thismodel has more flexibility, but this is disadvantageous; the model certainly fits the databetter, and the training error will be lower, but much of the extra descriptive power isdevoted to modeling the noise. This phenomenon is known as overfitting.== %%POSTFIX%%We’ve seen that as we add capaci*
>%%LINK%%[[#^tsliz9rli08|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tsliz9rli08


>%%
>```annotation-json
>{"created":"2024-11-01T12:16:11.317Z","updated":"2024-11-01T12:16:11.317Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":279668,"end":279681},{"type":"TextQuoteSelector","exact":"Double descen","prefix":" thebias-variance trade-off.8.4 ","suffix":"tIn the previous section, we exa"}]}]}
>```
>%%
>*%%PREFIX%%thebias-variance trade-off.8.4%%HIGHLIGHT%% ==Double descen== %%POSTFIX%%tIn the previous section, we exa*
>%%LINK%%[[#^dxki0qfgsw4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^dxki0qfgsw4


>%%
>```annotation-json
>{"created":"2024-11-01T12:18:51.232Z","updated":"2024-11-01T12:18:51.232Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":282519,"end":283022},{"type":"TextQuoteSelector","exact":"This phenomenon is known as double descent. For some datasets like MNIST, it ispresent with the original data (figure 8.10c). For others, like MNIST-1D and CIFAR-100(figure 8.10d), it emerges or becomes more prominent when we add noise to the labels. Notebook 8.3Double descentThe first part of the curve is referred to as the classical or under-parameterized regime,and the second part as the modern or over-parameterized regime. The central part wherethe error increases is termed the critical regime.","prefix":"din the first part of the curve.","suffix":"8.4.1 ExplanationThe discovery o"}]}]}
>```
>%%
>*%%PREFIX%%din the first part of the curve.%%HIGHLIGHT%% ==This phenomenon is known as double descent. For some datasets like MNIST, it ispresent with the original data (figure 8.10c). For others, like MNIST-1D and CIFAR-100(figure 8.10d), it emerges or becomes more prominent when we add noise to the labels. Notebook 8.3Double descentThe first part of the curve is referred to as the classical or under-parameterized regime,and the second part as the modern or over-parameterized regime. The central part wherethe error increases is termed the critical regime.== %%POSTFIX%%8.4.1 ExplanationThe discovery o*
>%%LINK%%[[#^49azx5yzc6j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^49azx5yzc6j


>%%
>```annotation-json
>{"created":"2024-11-01T12:20:43.703Z","updated":"2024-11-01T12:20:43.703Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":281988,"end":282518},{"type":"TextQuoteSelector","exact":"Once more, the training error decreases to zero. This time, there ismore randomness, and the model requires almost as many parameters as there are datapoints to memorize the data. The test error does show the typical bias-variance trade-offas we increase the capacity to the point where the model fits the training data exactly.However, then it does something unexpected; it starts to decrease again. Indeed, if weadd enough capacity, the test loss reduces to below the minimal level that we achievedin the first part of the curve","prefix":"ble descent 129training labels. ","suffix":".This phenomenon is known as dou"}]}]}
>```
>%%
>*%%PREFIX%%ble descent 129training labels.%%HIGHLIGHT%% ==Once more, the training error decreases to zero. This time, there ismore randomness, and the model requires almost as many parameters as there are datapoints to memorize the data. The test error does show the typical bias-variance trade-offas we increase the capacity to the point where the model fits the training data exactly.However, then it does something unexpected; it starts to decrease again. Indeed, if weadd enough capacity, the test loss reduces to below the minimal level that we achievedin the first part of the curve== %%POSTFIX%%.This phenomenon is known as dou*
>%%LINK%%[[#^ybq6t1ulj99|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ybq6t1ulj99


>%%
>```annotation-json
>{"created":"2024-11-01T12:22:44.846Z","updated":"2024-11-01T12:22:44.846Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":283039,"end":285298},{"type":"TextQuoteSelector","exact":"The discovery of double descent is recent, unexpected, and somewhat puzzling. It resultsfrom an interaction of two phenomena. First, the test performance becomes temporarilyworse when the model has just enough capacity to memorize the data. Second, the testperformance continues to improve with capacity even after the training performance isperfect. The first phenomenon is exactly as predicted by the bias-variance trade-off. Thesecond phenomenon is more confusing; it’s unclear why performance should be better inthe over-parameterized regime, given that there are now not even enough training datapoints to constrain the model parameters uniquely.To understand why performance continues to improve as we add more parameters,note that once the model has enough capacity to drive the training loss to near zero,the model fits the training data almost perfectly. This implies that further capacity Problems 8.4–8.5cannot help the model fit the training data any better; any change must occur betweenthe training points. The tendency of a model to prioritize one solution over another asit extrapolates between data points is known as its inductive bias.The model’s behavior between data points is critical because, in high-dimensionalspace, the training data are extremely sparse. The MNIST-1D dataset has 40 dimensions,and we trained with 10,000 examples. If this seems like plenty of data, consider whatwould happen if we quantized each input dimension into 10 bins. There would be 1040bins in total, constrained by only 105 examples. Even with this coarse quantization,there will only be one data point in every 1035 bins! The tendency of the volume ofhigh-dimensional space to overwhelm the number of training points is termed the curseof dimensionality.The implication is that problems in high dimensions might look more like figure 8.11a;there are small regions of the input space where we observe data with significant gapsbetween them. The putative explanation for double descent is that as we add capacityto the model, it interpolates between the nearest data points increasingly smoothly. Inthe absence of information about what happens between the training points, assumingsmoothness is sensible and will probably generalize reasonably to new data","prefix":"ritical regime.8.4.1 Explanation","suffix":".Draft: please send errata to ud"}]}]}
>```
>%%
>*%%PREFIX%%ritical regime.8.4.1 Explanation%%HIGHLIGHT%% ==The discovery of double descent is recent, unexpected, and somewhat puzzling. It resultsfrom an interaction of two phenomena. First, the test performance becomes temporarilyworse when the model has just enough capacity to memorize the data. Second, the testperformance continues to improve with capacity even after the training performance isperfect. The first phenomenon is exactly as predicted by the bias-variance trade-off. Thesecond phenomenon is more confusing; it’s unclear why performance should be better inthe over-parameterized regime, given that there are now not even enough training datapoints to constrain the model parameters uniquely.To understand why performance continues to improve as we add more parameters,note that once the model has enough capacity to drive the training loss to near zero,the model fits the training data almost perfectly. This implies that further capacity Problems 8.4–8.5cannot help the model fit the training data any better; any change must occur betweenthe training points. The tendency of a model to prioritize one solution over another asit extrapolates between data points is known as its inductive bias.The model’s behavior between data points is critical because, in high-dimensionalspace, the training data are extremely sparse. The MNIST-1D dataset has 40 dimensions,and we trained with 10,000 examples. If this seems like plenty of data, consider whatwould happen if we quantized each input dimension into 10 bins. There would be 1040bins in total, constrained by only 105 examples. Even with this coarse quantization,there will only be one data point in every 1035 bins! The tendency of the volume ofhigh-dimensional space to overwhelm the number of training points is termed the curseof dimensionality.The implication is that problems in high dimensions might look more like figure 8.11a;there are small regions of the input space where we observe data with significant gapsbetween them. The putative explanation for double descent is that as we add capacityto the model, it interpolates between the nearest data points increasingly smoothly. Inthe absence of information about what happens between the training points, assumingsmoothness is sensible and will probably generalize reasonably to new data== %%POSTFIX%%.Draft: please send errata to ud*
>%%LINK%%[[#^8j7f7noncit|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8j7f7noncit


>%%
>```annotation-json
>{"created":"2024-11-01T12:24:31.211Z","updated":"2024-11-01T12:24:31.211Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":287534,"end":288228},{"type":"TextQuoteSelector","exact":"This argument is plausible. It’s certainly true that as we add more capacity to themodel, it will have the capability to create smoother functions. Figures 8.11b–f show thesmoothest possible functions that still pass through the data points as we increase thenumber of hidden units. When the number of parameters is very close to the numberof training data examples (figure 8.11b), the model is forced to contort itself to fit thetraining data exactly, resulting in erratic predictions. This explains why the peak in thedouble descent curve is so pronounced. As we add more hidden units, the model has theability to construct smoother functions that are likely to generalize better to new data.","prefix":"is figure, it is not obliged to.","suffix":"However, this does not explain w"}]}]}
>```
>%%
>*%%PREFIX%%is figure, it is not obliged to.%%HIGHLIGHT%% ==This argument is plausible. It’s certainly true that as we add more capacity to themodel, it will have the capability to create smoother functions. Figures 8.11b–f show thesmoothest possible functions that still pass through the data points as we increase thenumber of hidden units. When the number of parameters is very close to the numberof training data examples (figure 8.11b), the model is forced to contort itself to fit thetraining data exactly, resulting in erratic predictions. This explains why the peak in thedouble descent curve is so pronounced. As we add more hidden units, the model has theability to construct smoother functions that are likely to generalize better to new data.== %%POSTFIX%%However, this does not explain w*
>%%LINK%%[[#^5q92xqsmyx7|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5q92xqsmyx7


>%%
>```annotation-json
>{"created":"2024-11-01T12:25:55.894Z","updated":"2024-11-01T12:25:55.894Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":289316,"end":289816},{"type":"TextQuoteSelector","exact":"he answer to this question is uncertain, but there are two likely possibilities. First,the network initialization may encourage smoothness, and the model never departs fromthe sub-domain of smooth function during the training process. Second, the trainingalgorithm may somehow “prefer” to converge to smooth functions. Any factor thatbiases a solution toward a subset of equivalent solutions is known as a regularizer, so onepossibility is that the training algorithm acts as an implicit regularizer ","prefix":"t in panel (a), are encouraged.T","suffix":"(see section 9.2).8.5 Choosing h"}]}]}
>```
>%%
>*%%PREFIX%%t in panel (a), are encouraged.T%%HIGHLIGHT%% ==he answer to this question is uncertain, but there are two likely possibilities. First,the network initialization may encourage smoothness, and the model never departs fromthe sub-domain of smooth function during the training process. Second, the trainingalgorithm may somehow “prefer” to converge to smooth functions. Any factor thatbiases a solution toward a subset of equivalent solutions is known as a regularizer, so onepossibility is that the training algorithm acts as an implicit regularizer== %%POSTFIX%%(see section 9.2).8.5 Choosing h*
>%%LINK%%[[#^w9fdht9fmt|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^w9fdht9fmt


>%%
>```annotation-json
>{"created":"2024-11-01T12:33:04.915Z","updated":"2024-11-01T12:33:04.915Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":289862,"end":290377},{"type":"TextQuoteSelector","exact":"In the previous section, we discussed how test performance changes with model capac-ity. Unfortunately, in the classical regime, we don’t have access to either the bias (whichrequires knowledge of the true underlying function) or the variance (which requires mul-tiple independently sampled datasets to estimate). In the modern regime, there is noway to tell how much capacity should be added before the test error stops improving.This raises the question of exactly how we should choose model capacity in practice.","prefix":".2).8.5 Choosing hyperparameters","suffix":"For a deep network, the model ca"}]}]}
>```
>%%
>*%%PREFIX%%.2).8.5 Choosing hyperparameters%%HIGHLIGHT%% ==In the previous section, we discussed how test performance changes with model capac-ity. Unfortunately, in the classical regime, we don’t have access to either the bias (whichrequires knowledge of the true underlying function) or the variance (which requires mul-tiple independently sampled datasets to estimate). In the modern regime, there is noway to tell how much capacity should be added before the test error stops improving.This raises the question of exactly how we should choose model capacity in practice.== %%POSTFIX%%For a deep network, the model ca*
>%%LINK%%[[#^11tzi5lysvr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^11tzi5lysvr


>%%
>```annotation-json
>{"created":"2024-11-01T12:33:48.717Z","updated":"2024-11-01T12:33:48.717Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":290377,"end":290884},{"type":"TextQuoteSelector","exact":"For a deep network, the model capacity depends on the numbers of hidden layersand hidden units per layer as well as other aspects of architecture that we have yet tointroduce. Furthermore, the choice of learning algorithm and any associated parameters(learning rate, etc.) also affects the test performance. These elements are collectivelytermed hyperparameters. The process of finding the best hyperparameters is termedhyperparameter search or (when focused on network structure) neural architecture search","prefix":"oose model capacity in practice.","suffix":".This work is subject to a Creat"}]}]}
>```
>%%
>*%%PREFIX%%oose model capacity in practice.%%HIGHLIGHT%% ==For a deep network, the model capacity depends on the numbers of hidden layersand hidden units per layer as well as other aspects of architecture that we have yet tointroduce. Furthermore, the choice of learning algorithm and any associated parameters(learning rate, etc.) also affects the test performance. These elements are collectivelytermed hyperparameters. The process of finding the best hyperparameters is termedhyperparameter search or (when focused on network structure) neural architecture search== %%POSTFIX%%.This work is subject to a Creat*
>%%LINK%%[[#^qlw16wvq0b9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^qlw16wvq0b9


>%%
>```annotation-json
>{"created":"2024-11-01T12:34:41.432Z","updated":"2024-11-01T12:34:41.432Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":290978,"end":291748},{"type":"TextQuoteSelector","exact":"Hyperparameters are typically chosen empirically; we train many models with differ-ent hyperparameters on the same training set, measure their performance, and retain thebest model. However, we do not measure their performance on the test set; this wouldadmit the possibility that these hyperparameters just happen to work well for the testset but don’t generalize to further data. Instead, we introduce a third dataset knownas a validation set. For every choice of hyperparameters, we train the associated modelusing the training set and evaluate performance on the validation set. Finally, we selectthe model that worked best on the validation set and measure its performance on thetest set. In principle, this should give a reasonable estimate of the true performance","prefix":"e. (C) MIT Press.8.6 Summary 133","suffix":".The hyperparameter space is gen"}]}]}
>```
>%%
>*%%PREFIX%%e. (C) MIT Press.8.6 Summary 133%%HIGHLIGHT%% ==Hyperparameters are typically chosen empirically; we train many models with differ-ent hyperparameters on the same training set, measure their performance, and retain thebest model. However, we do not measure their performance on the test set; this wouldadmit the possibility that these hyperparameters just happen to work well for the testset but don’t generalize to further data. Instead, we introduce a third dataset knownas a validation set. For every choice of hyperparameters, we train the associated modelusing the training set and evaluate performance on the validation set. Finally, we selectthe model that worked best on the validation set and measure its performance on thetest set. In principle, this should give a reasonable estimate of the true performance== %%POSTFIX%%.The hyperparameter space is gen*
>%%LINK%%[[#^tm8g57p35ke|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^tm8g57p35ke


>%%
>```annotation-json
>{"created":"2024-11-01T12:35:33.979Z","updated":"2024-11-01T12:35:33.979Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":291749,"end":292495},{"type":"TextQuoteSelector","exact":"The hyperparameter space is generally smaller than the parameter space but stilltoo large to try every combination exhaustively. Unfortunately, many hyperparametersare discrete (e.g., the number of hidden layers), and others may be conditional on oneanother (e.g., we only need to specify the number of hidden units in the tenth hiddenlayer if there are ten or more layers). Hence, we cannot rely on gradient descent methodsas we did for learning the model parameters. Hyperparameter optimization algorithmsintelligently sample the space of hyperparameters, contingent on previous results. Thisprocedure is computationally expensive since we must train an entire model and measurethe validation performance for each combination of hyperparameters","prefix":"stimate of the true performance.","suffix":".8.6 SummaryTo measure performan"}]}]}
>```
>%%
>*%%PREFIX%%stimate of the true performance.%%HIGHLIGHT%% ==The hyperparameter space is generally smaller than the parameter space but stilltoo large to try every combination exhaustively. Unfortunately, many hyperparametersare discrete (e.g., the number of hidden layers), and others may be conditional on oneanother (e.g., we only need to specify the number of hidden units in the tenth hiddenlayer if there are ten or more layers). Hence, we cannot rely on gradient descent methodsas we did for learning the model parameters. Hyperparameter optimization algorithmsintelligently sample the space of hyperparameters, contingent on previous results. Thisprocedure is computationally expensive since we must train an entire model and measurethe validation performance for each combination of hyperparameters== %%POSTFIX%%.8.6 SummaryTo measure performan*
>%%LINK%%[[#^ltlohhy76|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ltlohhy76


>%%
>```annotation-json
>{"created":"2024-11-01T12:36:16.786Z","updated":"2024-11-01T12:36:16.786Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":292507,"end":293613},{"type":"TextQuoteSelector","exact":"To measure performance, we use a separate test set. The degree to which performance ismaintained on this test set is known as generalization. Test errors can be explained bythree factors: noise, bias, and variance. These combine additively in regression problemswith least squares losses. Adding training data decreases the variance. When the modelcapacity is less than the number of training examples, increasing the capacity decreasesbias but increases variance. This is known as the bias-variance trade-off, and there is acapacity where the trade-off is optimal.However, this is balanced against a tendency for performance to improve with ca-pacity, even when the parameters exceed the training examples. Together, these twophenomena create the double descent curve. It is thought that the model interpolatesmore smoothly between the training data points in the over-parameterized “modernregime,” although it is unclear what drives this. To choose the capacity and other modeland training algorithm hyperparameters, we fit multiple models and evaluate their per-formance using a separate validation set.","prefix":"n of hyperparameters.8.6 Summary","suffix":"NotesBias-variance trade-off: We"}]}]}
>```
>%%
>*%%PREFIX%%n of hyperparameters.8.6 Summary%%HIGHLIGHT%% ==To measure performance, we use a separate test set. The degree to which performance ismaintained on this test set is known as generalization. Test errors can be explained bythree factors: noise, bias, and variance. These combine additively in regression problemswith least squares losses. Adding training data decreases the variance. When the modelcapacity is less than the number of training examples, increasing the capacity decreasesbias but increases variance. This is known as the bias-variance trade-off, and there is acapacity where the trade-off is optimal.However, this is balanced against a tendency for performance to improve with ca-pacity, even when the parameters exceed the training examples. Together, these twophenomena create the double descent curve. It is thought that the model interpolatesmore smoothly between the training data points in the over-parameterized “modernregime,” although it is unclear what drives this. To choose the capacity and other modeland training algorithm hyperparameters, we fit multiple models and evaluate their per-formance using a separate validation set.== %%POSTFIX%%NotesBias-variance trade-off: We*
>%%LINK%%[[#^mwu97t20d2m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mwu97t20d2m


>%%
>```annotation-json
>{"created":"2024-11-01T12:37:28.759Z","updated":"2024-11-01T12:37:28.759Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":294325,"end":294341},{"type":"TextQuoteSelector","exact":"Cross-validation","prefix":"hold to be classified correctly.","suffix":": We saw that it is typical to d"}]}]}
>```
>%%
>*%%PREFIX%%hold to be classified correctly.%%HIGHLIGHT%% ==Cross-validation== %%POSTFIX%%: We saw that it is typical to d*
>%%LINK%%[[#^3ya5r6q3yka|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^3ya5r6q3yka


>%%
>```annotation-json
>{"created":"2024-11-01T12:38:05.210Z","updated":"2024-11-01T12:38:05.210Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":295501,"end":295509},{"type":"TextQuoteSelector","exact":"Capacity","prefix":"model, therebyreducing variance.","suffix":": We have used the term capacity"}]}]}
>```
>%%
>*%%PREFIX%%model, therebyreducing variance.%%HIGHLIGHT%% ==Capacity== %%POSTFIX%%: We have used the term capacity*
>%%LINK%%[[#^xapy0iufsdg|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xapy0iufsdg


>%%
>```annotation-json
>{"created":"2024-11-01T12:39:18.272Z","updated":"2024-11-01T12:39:18.272Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":296620,"end":296634},{"type":"TextQuoteSelector","exact":"Double descent","prefix":"ms of the Rademacher complexity.","suffix":": The term “double descent” was "}]}]}
>```
>%%
>*%%PREFIX%%ms of the Rademacher complexity.%%HIGHLIGHT%% ==Double descent== %%POSTFIX%%: The term “double descent” was*
>%%LINK%%[[#^nk9008j72h|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^nk9008j72h


>%%
>```annotation-json
>{"created":"2024-11-01T12:40:40.363Z","updated":"2024-11-01T12:40:40.363Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":298894,"end":298917},{"type":"TextQuoteSelector","exact":"Curse of dimensionality","prefix":"n be found in Dar et al. (2021).","suffix":": As dimensionality increases, t"}]}]}
>```
>%%
>*%%PREFIX%%n be found in Dar et al. (2021).%%HIGHLIGHT%% ==Curse of dimensionality== %%POSTFIX%%: As dimensionality increases, t*
>%%LINK%%[[#^4h4ssog9ik4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4h4ssog9ik4


>%%
>```annotation-json
>{"created":"2024-11-01T12:42:31.319Z","updated":"2024-11-01T12:42:31.319Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":300573,"end":300596},{"type":"TextQuoteSelector","exact":"Real-world performance:","prefix":"999) and Aggarwal et al. (2001).","suffix":" In this chapter, we argued that"}]}]}
>```
>%%
>*%%PREFIX%%999) and Aggarwal et al. (2001).%%HIGHLIGHT%% ==Real-world performance:== %%POSTFIX%%In this chapter, we argued that*
>%%LINK%%[[#^o8s0rwze80m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^o8s0rwze80m


>%%
>```annotation-json
>{"created":"2024-11-01T12:42:50.880Z","updated":"2024-11-01T12:42:50.880Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":301783,"end":301804},{"type":"TextQuoteSelector","exact":"Hyperparameter search","prefix":" in Moreno-Torres et al. (2012).","suffix":": Finding the best hyperparamete"}]}]}
>```
>%%
>*%%PREFIX%%in Moreno-Torres et al. (2012).%%HIGHLIGHT%% ==Hyperparameter search== %%POSTFIX%%: Finding the best hyperparamete*
>%%LINK%%[[#^q5kvic0rf0e|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^q5kvic0rf0e


>%%
>```annotation-json
>{"created":"2024-12-11T16:37:36.746Z","updated":"2024-12-11T16:37:36.746Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":308718,"end":308820},{"type":"TextQuoteSelector","exact":"These are a family of methods thatreduce the generalization gap between training and test performance.","prefix":"sses regularization techniques. ","suffix":" Strictly speaking,regularizatio"}]}]}
>```
>%%
>*%%PREFIX%%sses regularization techniques.%%HIGHLIGHT%% ==These are a family of methods thatreduce the generalization gap between training and test performance.== %%POSTFIX%%Strictly speaking,regularizatio*
>%%LINK%%[[#^ma2swzu2da|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^ma2swzu2da


>%%
>```annotation-json
>{"created":"2024-12-11T16:37:43.240Z","updated":"2024-12-11T16:37:43.240Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":308821,"end":308943},{"type":"TextQuoteSelector","exact":"Strictly speaking,regularization involves adding explicit terms to the loss function that favor certain pa-rameter choices","prefix":" training and test performance. ","suffix":". However, in machine learning, "}]}]}
>```
>%%
>*%%PREFIX%%training and test performance.%%HIGHLIGHT%% ==Strictly speaking,regularization involves adding explicit terms to the loss function that favor certain pa-rameter choices== %%POSTFIX%%. However, in machine learning,*
>%%LINK%%[[#^z39y3arhzfk|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^z39y3arhzfk


>%%
>```annotation-json
>{"created":"2024-12-11T16:38:13.419Z","updated":"2024-12-11T16:38:13.419Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":309335,"end":309423},{"type":"TextQuoteSelector","exact":"These include early stopping, ensembling, dropout, labelsmoothing, and transfer learning","prefix":"s thatimprove test performance. ","suffix":".9.1 Explicit regularizationCons"}]}]}
>```
>%%
>*%%PREFIX%%s thatimprove test performance.%%HIGHLIGHT%% ==These include early stopping, ensembling, dropout, labelsmoothing, and transfer learning== %%POSTFIX%%.9.1 Explicit regularizationCons*
>%%LINK%%[[#^kqgpx3he5z|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kqgpx3he5z


>%%
>```annotation-json
>{"created":"2024-12-11T18:39:57.409Z","updated":"2024-12-11T18:39:57.409Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":309428,"end":309451},{"type":"TextQuoteSelector","exact":"Explicit regularization","prefix":"hing, and transfer learning.9.1 ","suffix":"Consider fitting a model f[x,φ] "}]}]}
>```
>%%
>*%%PREFIX%%hing, and transfer learning.9.1%%HIGHLIGHT%% ==Explicit regularization== %%POSTFIX%%Consider fitting a model f[x,φ]*
>%%LINK%%[[#^m9q1bp1prb|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^m9q1bp1prb


>%%
>```annotation-json
>{"created":"2024-12-11T18:42:11.062Z","updated":"2024-12-11T18:42:11.062Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":310968,"end":310996},{"type":"TextQuoteSelector","exact":"Probabilistic interpretation","prefix":"meter values (figure 9.1).9.1.1 ","suffix":"Regularization can be viewed fro"}]}]}
>```
>%%
>*%%PREFIX%%meter values (figure 9.1).9.1.1%%HIGHLIGHT%% ==Probabilistic interpretation== %%POSTFIX%%Regularization can be viewed fro*
>%%LINK%%[[#^y2aa6q6o6r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^y2aa6q6o6r


>%%
>```annotation-json
>{"created":"2024-12-11T18:43:10.104Z","updated":"2024-12-11T18:43:10.104Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":311634,"end":311651},{"type":"TextQuoteSelector","exact":"L2 regularization","prefix":"hat λ ·g[φ] = −log[Pr(φ)].9.1.2 ","suffix":"This discussion has sidestepped "}]}]}
>```
>%%
>*%%PREFIX%%hat λ ·g[φ] = −log[Pr(φ)].9.1.2%%HIGHLIGHT%% ==L2 regularization== %%POSTFIX%%This discussion has sidestepped*
>%%LINK%%[[#^4yf9p8sp0hw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4yf9p8sp0hw


>%%
>```annotation-json
>{"created":"2024-12-11T18:44:03.495Z","updated":"2024-12-11T18:44:03.495Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":311971,"end":312041},{"type":"TextQuoteSelector","exact":"L2 norm, which penalizesthe sum of the squares of the parameter values","prefix":"used regularization term is the ","suffix":":ˆφ = argminφI∑i=1ℓi[xi,yi] + "}]}]}
>```
>%%
>*%%PREFIX%%used regularization term is the%%HIGHLIGHT%% ==L2 norm, which penalizesthe sum of the squares of the parameter values== %%POSTFIX%%:ˆφ = argminφI∑i=1ℓi[xi,yi] +*
>%%LINK%%[[#^xusx6ox2pf|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xusx6ox2pf


>%%
>```annotation-json
>{"created":"2024-12-11T18:44:18.576Z","updated":"2024-12-11T18:44:18.576Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":312120,"end":312268},{"type":"TextQuoteSelector","exact":"This is also referred to as Tikhonov regularization orProblems 9.1–9.2 ridge regression, or (when applied to matrices) Frobenius norm regularization","prefix":"where j indexes the parameters. ","suffix":".For neural networks, L2 regular"}]}]}
>```
>%%
>*%%PREFIX%%where j indexes the parameters.%%HIGHLIGHT%% ==This is also referred to as Tikhonov regularization orProblems 9.1–9.2 ridge regression, or (when applied to matrices) Frobenius norm regularization== %%POSTFIX%%.For neural networks, L2 regular*
>%%LINK%%[[#^9xjmcm4p7jm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9xjmcm4p7jm


>%%
>```annotation-json
>{"created":"2024-12-11T18:44:50.379Z","updated":"2024-12-11T18:44:50.379Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":312290,"end":312407},{"type":"TextQuoteSelector","exact":"L2 regularization is usually applied to the weights but notthe biases and is hence referred to as a weight decay term","prefix":"larization.For neural networks, ","suffix":". The effect is to encouragesmal"}]}]}
>```
>%%
>*%%PREFIX%%larization.For neural networks,%%HIGHLIGHT%% ==L2 regularization is usually applied to the weights but notthe biases and is hence referred to as a weight decay term== %%POSTFIX%%. The effect is to encouragesmal*
>%%LINK%%[[#^2zcwnmz2eia|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^2zcwnmz2eia


>%%
>```annotation-json
>{"created":"2024-12-11T18:47:35.631Z","updated":"2024-12-11T18:47:35.631Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":313325,"end":313696},{"type":"TextQuoteSelector","exact":"f the network is overfitting, then adding the regularization term means that thenetwork must trade off slavish adherence to the data against the desire to besmooth. One way to think about this is that the error due to variance reduces (themodel no longer needs to pass through every data point) at the cost of increasedbias (the model can only describe smooth functions).","prefix":" performance for two reasons:• I","suffix":"• When the network is over-param"}]}]}
>```
>%%
>*%%PREFIX%%performance for two reasons:• I%%HIGHLIGHT%% ==f the network is overfitting, then adding the regularization term means that thenetwork must trade off slavish adherence to the data against the desire to besmooth. One way to think about this is that the error due to variance reduces (themodel no longer needs to pass through every data point) at the cost of increasedbias (the model can only describe smooth functions).== %%POSTFIX%%• When the network is over-param*
>%%LINK%%[[#^7ydzf38bpus|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7ydzf38bpus


>%%
>```annotation-json
>{"created":"2024-12-11T18:48:09.655Z","updated":"2024-12-11T18:48:09.655Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":313699,"end":313994},{"type":"TextQuoteSelector","exact":"hen the network is over-parameterized, some of the extra model capacity de-scribes areas with no training data. Here, the regularization term will favor func-tions that smoothly interpolate between the nearby points. This is reasonablebehavior in the absence of knowledge about the true function","prefix":"y describe smooth functions).• W","suffix":".This work is subject to a Creat"}]}]}
>```
>%%
>*%%PREFIX%%y describe smooth functions).• W%%HIGHLIGHT%% ==hen the network is over-parameterized, some of the extra model capacity de-scribes areas with no training data. Here, the regularization term will favor func-tions that smoothly interpolate between the nearby points. This is reasonablebehavior in the absence of knowledge about the true function== %%POSTFIX%%.This work is subject to a Creat*
>%%LINK%%[[#^16c0zbd01a8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^16c0zbd01a8


>%%
>```annotation-json
>{"created":"2024-12-11T18:49:29.972Z","updated":"2024-12-11T18:49:29.972Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":314650,"end":314673},{"type":"TextQuoteSelector","exact":"Implicit regularization","prefix":" truth, so the fit is worse.9.2 ","suffix":"An intriguing recent finding is "}]}]}
>```
>%%
>*%%PREFIX%%truth, so the fit is worse.9.2%%HIGHLIGHT%% ==Implicit regularization== %%POSTFIX%%An intriguing recent finding is*
>%%LINK%%[[#^p35n2l4ivz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^p35n2l4ivz


>%%
>```annotation-json
>{"created":"2024-12-11T18:59:05.149Z","updated":"2024-12-11T18:59:05.149Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":319574,"end":319607},{"type":"TextQuoteSelector","exact":"Heuristics to improve performance","prefix":"likely to generalize better.9.3 ","suffix":"We’ve seen that adding explicit "}]}]}
>```
>%%
>*%%PREFIX%%likely to generalize better.9.3%%HIGHLIGHT%% ==Heuristics to improve performance== %%POSTFIX%%We’ve seen that adding explicit*
>%%LINK%%[[#^am21jqrwh4g|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^am21jqrwh4g


>%%
>```annotation-json
>{"created":"2024-12-11T19:00:44.562Z","updated":"2024-12-11T19:00:44.562Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":320619,"end":320633},{"type":"TextQuoteSelector","exact":"Early stopping","prefix":"y the same model capacity.9.3.1 ","suffix":"Early stopping refers to stoppin"}]}]}
>```
>%%
>*%%PREFIX%%y the same model capacity.9.3.1%%HIGHLIGHT%% ==Early stopping== %%POSTFIX%%Early stopping refers to stoppin*
>%%LINK%%[[#^g5oxzhc5y9e|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^g5oxzhc5y9e


>%%
>```annotation-json
>{"created":"2024-12-11T19:03:15.769Z","updated":"2024-12-11T19:03:15.769Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":321813,"end":321823},{"type":"TextQuoteSelector","exact":"Ensembling","prefix":"ance was best is selected.9.3.2 ","suffix":"Another approach to reducing the"}]}]}
>```
>%%
>*%%PREFIX%%ance was best is selected.9.3.2%%HIGHLIGHT%% ==Ensembling== %%POSTFIX%%Another approach to reducing the*
>%%LINK%%[[#^244uiwaq5xw|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^244uiwaq5xw


>%%
>```annotation-json
>{"created":"2024-12-11T19:08:25.003Z","updated":"2024-12-11T19:08:25.003Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":323263,"end":323620},{"type":"TextQuoteSelector","exact":"One way to train different models is just to use different random initializations. Thismay help in regions of input space far from the training data. Here, the fitted functionNotebook 9.3Ensembling is relatively unconstrained, and different models may produce different predictions, sothe average of several models may generalize better than any single mode","prefix":"ake the predictions more robust.","suffix":"l.A second approach is to genera"}]}]}
>```
>%%
>*%%PREFIX%%ake the predictions more robust.%%HIGHLIGHT%% ==One way to train different models is just to use different random initializations. Thismay help in regions of input space far from the training data. Here, the fitted functionNotebook 9.3Ensembling is relatively unconstrained, and different models may produce different predictions, sothe average of several models may generalize better than any single mode== %%POSTFIX%%l.A second approach is to genera*
>%%LINK%%[[#^lal2vk2fk8q|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^lal2vk2fk8q


>%%
>```annotation-json
>{"created":"2024-12-11T19:08:33.526Z","updated":"2024-12-11T19:08:33.526Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":323622,"end":323833},{"type":"TextQuoteSelector","exact":"A second approach is to generate several different datasets by re-sampling the train-ing data with replacement and training a different model from each. This is known asbootstrap aggregating or bagging for short","prefix":"ze better than any single model.","suffix":" (figure 9.7). It has the effect"}]}]}
>```
>%%
>*%%PREFIX%%ze better than any single model.%%HIGHLIGHT%% ==A second approach is to generate several different datasets by re-sampling the train-ing data with replacement and training a different model from each. This is known asbootstrap aggregating or bagging for short== %%POSTFIX%%(figure 9.7). It has the effect*
>%%LINK%%[[#^bwyk5v2933j|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bwyk5v2933j


>%%
>```annotation-json
>{"created":"2024-12-11T19:09:37.600Z","updated":"2024-12-11T19:09:37.600Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":324793,"end":324800},{"type":"TextQuoteSelector","exact":"Dropout","prefix":"ferent families of models.9.3.3 ","suffix":"Dropout randomly clamps a subset"}]}]}
>```
>%%
>*%%PREFIX%%ferent families of models.9.3.3%%HIGHLIGHT%% ==Dropout== %%POSTFIX%%Dropout randomly clamps a subset*
>%%LINK%%[[#^car1apzsdrm|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^car1apzsdrm


>%%
>```annotation-json
>{"created":"2024-12-11T20:18:39.624Z","updated":"2024-12-11T20:18:39.624Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":326662,"end":326964},{"type":"TextQuoteSelector","exact":"At test time, we can run the network as usual with all the hidden units active;however, the network now has more hidden units than it was trained with at any giveniteration, so we multiply the weights by one minus the dropout probability to compensate.This is known as the weight scaling inference rule","prefix":"othing to the loss (figure 9.9).","suffix":". A different approach to infere"}]}]}
>```
>%%
>*%%PREFIX%%othing to the loss (figure 9.9).%%HIGHLIGHT%% ==At test time, we can run the network as usual with all the hidden units active;however, the network now has more hidden units than it was trained with at any giveniteration, so we multiply the weights by one minus the dropout probability to compensate.This is known as the weight scaling inference rule== %%POSTFIX%%. A different approach to infere*
>%%LINK%%[[#^kn4g904r1iq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kn4g904r1iq


>%%
>```annotation-json
>{"created":"2024-12-11T20:21:54.906Z","updated":"2024-12-11T20:21:54.906Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":328414,"end":328428},{"type":"TextQuoteSelector","exact":"Applying noise","prefix":" of the dropout mechanism.9.3.4 ","suffix":"Dropout can be interpreted as ap"}]}]}
>```
>%%
>*%%PREFIX%%of the dropout mechanism.9.3.4%%HIGHLIGHT%% ==Applying noise== %%POSTFIX%%Dropout can be interpreted as ap*
>%%LINK%%[[#^mo14gm2m79o|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^mo14gm2m79o


>%%
>```annotation-json
>{"created":"2024-12-11T20:23:12.374Z","updated":"2024-12-11T20:23:12.374Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":328925,"end":329158},{"type":"TextQuoteSelector","exact":"An extreme variant is adversarial training, in which the optimization algorithmactively searches for small perturbations of the input that cause large changes to theoutput. These can be thought of as worst-case additive noise vectors","prefix":"utput with respect toits input. ","suffix":".A second possibility is to add "}]}]}
>```
>%%
>*%%PREFIX%%utput with respect toits input.%%HIGHLIGHT%% ==An extreme variant is adversarial training, in which the optimization algorithmactively searches for small perturbations of the input that cause large changes to theoutput. These can be thought of as worst-case additive noise vectors== %%POSTFIX%%.A second possibility is to add*
>%%LINK%%[[#^8af32ux6ww8|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8af32ux6ww8


>%%
>```annotation-json
>{"created":"2024-12-11T20:25:40.892Z","updated":"2024-12-11T20:25:40.892Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":330729,"end":330747},{"type":"TextQuoteSelector","exact":"Bayesian inference","prefix":"tion in diverse scenarios.9.3.5 ","suffix":"The maximum likelihood approach "}]}]}
>```
>%%
>*%%PREFIX%%tion in diverse scenarios.9.3.5%%HIGHLIGHT%% ==Bayesian inference== %%POSTFIX%%The maximum likelihood approach*
>%%LINK%%[[#^d0kq33kbafs|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^d0kq33kbafs


>%%
>```annotation-json
>{"created":"2024-12-11T20:29:31.479Z","updated":"2024-12-11T20:29:31.479Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":333270,"end":333311},{"type":"TextQuoteSelector","exact":"Transfer learning and multi-task learning","prefix":"to learning and inference.9.3.6 ","suffix":"When training data are limited, "}]}]}
>```
>%%
>*%%PREFIX%%to learning and inference.9.3.6%%HIGHLIGHT%% ==Transfer learning and multi-task learning== %%POSTFIX%%When training data are limited,*
>%%LINK%%[[#^7rt1fz7ahf5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^7rt1fz7ahf5


>%%
>```annotation-json
>{"created":"2024-12-11T20:31:07.176Z","updated":"2024-12-11T20:31:07.176Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":334672,"end":334696},{"type":"TextQuoteSelector","exact":"Self-supervised learning","prefix":"ance for each may improve.9.3.7 ","suffix":"The above discussion assumes tha"}]}]}
>```
>%%
>*%%PREFIX%%ance for each may improve.9.3.7%%HIGHLIGHT%% ==Self-supervised learning== %%POSTFIX%%The above discussion assumes tha*
>%%LINK%%[[#^8z1cdfix45n|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8z1cdfix45n


>%%
>```annotation-json
>{"created":"2024-12-11T20:33:40.971Z","updated":"2024-12-11T20:33:40.971Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":336066,"end":336078},{"type":"TextQuoteSelector","exact":"Augmentation","prefix":"ches from the same image).9.3.8 ","suffix":"Transfer learning improves perfo"}]}]}
>```
>%%
>*%%PREFIX%%ches from the same image).9.3.8%%HIGHLIGHT%% ==Augmentation== %%POSTFIX%%Transfer learning improves perfo*
>%%LINK%%[[#^30ogdbyohlc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^30ogdbyohlc


>%%
>```annotation-json
>{"created":"2024-12-11T21:43:02.561Z","updated":"2024-12-11T21:43:02.561Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":617035,"end":617075},{"type":"TextQuoteSelector","exact":"Taxonomy of unsupervised learning models","prefix":"ows, and diffusion models.114.1 ","suffix":"A common strategy in unsupervise"}]}]}
>```
>%%
>*%%PREFIX%%ows, and diffusion models.114.1%%HIGHLIGHT%% ==Taxonomy of unsupervised learning models== %%POSTFIX%%A common strategy in unsupervise*
>%%LINK%%[[#^slekch7izpc|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^slekch7izpc


>%%
>```annotation-json
>{"created":"2024-12-11T21:50:48.678Z","updated":"2024-12-11T21:50:48.678Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":620075,"end":620110},{"type":"TextQuoteSelector","exact":"What makes a good generative model?","prefix":" dataset or is an outlier.214.2 ","suffix":"Generative models based on laten"}]}]}
>```
>%%
>*%%PREFIX%%dataset or is an outlier.214.2%%HIGHLIGHT%% ==What makes a good generative model?== %%POSTFIX%%Generative models based on laten*
>%%LINK%%[[#^n76aknd5n1|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^n76aknd5n1


>%%
>```annotation-json
>{"created":"2024-12-11T21:50:57.729Z","updated":"2024-12-11T21:50:57.729Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":621189,"end":622140},{"type":"TextQuoteSelector","exact":"Eﬀicient sampling: Generating samples from the model should be computation-ally inexpensive and take advantage of the parallelism of modern hardware.• High-quality sampling: The samples should be indistinguishable from the realdata with which the model was trained.• Coverage: Samples should represent the entire training distribution. It is insuf-ficient to generate samples that all look like a subset of the training examples.• Well-behaved latent space: Every latent variable z corresponds to a plausibledata example x. Smooth changes in z correspond to smooth changes in x.• Disentangled latent space: Manipulating each dimension of z should correspondto changing an interpretable property of the data. For example, in a model oflanguage, it might change the topic, tense, or verbosity.• Eﬀicient likelihood computation: If the model is probabilistic, we would liketo be able to calculate the probability of new examples eﬀiciently and accurately","prefix":"robability of new data points.• ","suffix":".This naturally leads to the que"}]}]}
>```
>%%
>*%%PREFIX%%robability of new data points.•%%HIGHLIGHT%% ==Eﬀicient sampling: Generating samples from the model should be computation-ally inexpensive and take advantage of the parallelism of modern hardware.• High-quality sampling: The samples should be indistinguishable from the realdata with which the model was trained.• Coverage: Samples should represent the entire training distribution. It is insuf-ficient to generate samples that all look like a subset of the training examples.• Well-behaved latent space: Every latent variable z corresponds to a plausibledata example x. Smooth changes in z correspond to smooth changes in x.• Disentangled latent space: Manipulating each dimension of z should correspondto changing an interpretable property of the data. For example, in a model oflanguage, it might change the topic, tense, or verbosity.• Eﬀicient likelihood computation: If the model is probabilistic, we would liketo be able to calculate the probability of new examples eﬀiciently and accurately== %%POSTFIX%%.This naturally leads to the que*
>%%LINK%%[[#^8t3hnwywpts|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8t3hnwywpts


>%%
>```annotation-json
>{"created":"2024-12-11T21:52:50.150Z","updated":"2024-12-11T21:52:50.150Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":622981,"end":623004},{"type":"TextQuoteSelector","exact":"Quantifying performance","prefix":"nt of desirable properties.14.3 ","suffix":"The previous section discussed t"}]}]}
>```
>%%
>*%%PREFIX%%nt of desirable properties.14.3%%HIGHLIGHT%% ==Quantifying performance== %%POSTFIX%%The previous section discussed t*
>%%LINK%%[[#^6su0i2a17aj|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6su0i2a17aj


>%%
>```annotation-json
>{"created":"2024-12-11T21:53:55.967Z","updated":"2024-12-11T21:53:55.967Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":623366,"end":623382},{"type":"TextQuoteSelector","exact":"Test likelihood:","prefix":"ese metricsonly apply to images.","suffix":" One way to compare probabilisti"}]}]}
>```
>%%
>*%%PREFIX%%ese metricsonly apply to images.%%HIGHLIGHT%% ==Test likelihood:== %%POSTFIX%%One way to compare probabilisti*
>%%LINK%%[[#^alp54j1rh9d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^alp54j1rh9d


>%%
>```annotation-json
>{"created":"2024-12-11T21:54:29.154Z","updated":"2024-12-11T21:54:29.154Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":624463,"end":624478},{"type":"TextQuoteSelector","exact":"Inception score","prefix":"computed exactly and eﬀiciently.","suffix":": The inception score (IS) is sp"}]}]}
>```
>%%
>*%%PREFIX%%computed exactly and eﬀiciently.%%HIGHLIGHT%% ==Inception score== %%POSTFIX%%: The inception score (IS) is sp*
>%%LINK%%[[#^kfogqvyaq3|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^kfogqvyaq3


>%%
>```annotation-json
>{"created":"2024-12-11T21:57:15.860Z","updated":"2024-12-11T21:57:15.860Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":626463,"end":626489},{"type":"TextQuoteSelector","exact":"Fréchet inception distance","prefix":"realistic example of each class.","suffix":": This measure is also intended "}]}]}
>```
>%%
>*%%PREFIX%%realistic example of each class.%%HIGHLIGHT%% ==Fréchet inception distance== %%POSTFIX%%: This measure is also intended*
>%%LINK%%[[#^u7wli3f70r|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^u7wli3f70r


>%%
>```annotation-json
>{"created":"2024-12-11T21:58:39.999Z","updated":"2024-12-11T21:58:39.999Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":627762,"end":627787},{"type":"TextQuoteSelector","exact":"Manifold precision/recall","prefix":"ntto generate realistic samples.","suffix":": Fréchet inception distance is "}]}]}
>```
>%%
>*%%PREFIX%%ntto generate realistic samples.%%HIGHLIGHT%% ==Manifold precision/recall== %%POSTFIX%%: Fréchet inception distance is*
>%%LINK%%[[#^js09j5um2qr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^js09j5um2qr


>%%
>```annotation-json
>{"created":"2024-12-11T22:05:23.243Z","updated":"2024-12-11T22:05:23.243Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":742163,"end":742185},{"type":"TextQuoteSelector","exact":"Latent variable models","prefix":"al applications of the VAE.17.1 ","suffix":"Latent variable models take an i"}]}]}
>```
>%%
>*%%PREFIX%%al applications of the VAE.17.1%%HIGHLIGHT%% ==Latent variable models== %%POSTFIX%%Latent variable models take an i*
>%%LINK%%[[#^xabzjqdtnff|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xabzjqdtnff


>%%
>```annotation-json
>{"created":"2024-12-12T08:17:42.901Z","updated":"2024-12-12T08:17:42.901Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":751777,"end":751792},{"type":"TextQuoteSelector","exact":"ELBO properties","prefix":"s this quantity is the VAE.17.4 ","suffix":"When first encountered, the ELBO"}]}]}
>```
>%%
>*%%PREFIX%%s this quantity is the VAE.17.4%%HIGHLIGHT%% ==ELBO properties== %%POSTFIX%%When first encountered, the ELBO*
>%%LINK%%[[#^5feqxguvtc4|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^5feqxguvtc4


>%%
>```annotation-json
>{"created":"2024-12-12T08:17:47.222Z","updated":"2024-12-12T08:17:47.222Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":752377,"end":752395},{"type":"TextQuoteSelector","exact":"Tightness of bound","prefix":"d function (figure 17.6).17.4.1 ","suffix":"The ELBO is tight when, for a fi"}]}]}
>```
>%%
>*%%PREFIX%%d function (figure 17.6).17.4.1%%HIGHLIGHT%% ==Tightness of bound== %%POSTFIX%%The ELBO is tight when, for a fi*
>%%LINK%%[[#^o01gq1e1p5n|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^o01gq1e1p5n


>%%
>```annotation-json
>{"created":"2024-12-12T08:17:57.501Z","updated":"2024-12-12T08:17:57.501Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":747944,"end":747971},{"type":"TextQuoteSelector","exact":"Evidence lower bound (ELBO)","prefix":" a particular value of x.17.3.1 ","suffix":"To make progress, we define a lo"}]}]}
>```
>%%
>*%%PREFIX%%a particular value of x.17.3.1%%HIGHLIGHT%% ==Evidence lower bound (ELBO)== %%POSTFIX%%To make progress, we define a lo*
>%%LINK%%[[#^08x85je1z04m|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^08x85je1z04m


>%%
>```annotation-json
>{"created":"2024-12-12T08:18:01.926Z","updated":"2024-12-12T08:18:01.926Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":748324,"end":748343},{"type":"TextQuoteSelector","exact":"Jensen’s inequality","prefix":"need Jensen’s inequality.17.3.2 ","suffix":"Jensen’s inequality says that a "}]}]}
>```
>%%
>*%%PREFIX%%need Jensen’s inequality.17.3.2%%HIGHLIGHT%% ==Jensen’s inequality== %%POSTFIX%%Jensen’s inequality says that a*
>%%LINK%%[[#^rbzm0996h9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^rbzm0996h9


>%%
>```annotation-json
>{"created":"2024-12-12T08:18:05.627Z","updated":"2024-12-12T08:18:05.627Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":747444,"end":747452},{"type":"TextQuoteSelector","exact":"Training","prefix":"urve,log[E[y]] > E[log[y]].17.3 ","suffix":"To train the model, we maximize "}]}]}
>```
>%%
>*%%PREFIX%%urve,log[E[y]] > E[log[y]].17.3%%HIGHLIGHT%% ==Training== %%POSTFIX%%To train the model, we maximize*
>%%LINK%%[[#^pjx55zqclxr|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^pjx55zqclxr


>%%
>```annotation-json
>{"created":"2024-12-12T08:18:09.764Z","updated":"2024-12-12T08:18:09.764Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":745516,"end":745526},{"type":"TextQuoteSelector","exact":"Generation","prefix":"uts f[z,φ] (figure 17.2).17.2.1 ","suffix":"A new example x∗ can be generate"}]}]}
>```
>%%
>*%%PREFIX%%uts f[z,φ] (figure 17.2).17.2.1%%HIGHLIGHT%% ==Generation== %%POSTFIX%%A new example x∗ can be generate*
>%%LINK%%[[#^txep07bwl29|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^txep07bwl29


>%%
>```annotation-json
>{"created":"2024-12-12T08:18:15.373Z","updated":"2024-12-12T08:18:15.373Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":744019,"end":744050},{"type":"TextQuoteSelector","exact":"Nonlinear latent variable model","prefix":"alprobability distribution.17.2 ","suffix":"In the nonlinear latent variable"}]}]}
>```
>%%
>*%%PREFIX%%alprobability distribution.17.2%%HIGHLIGHT%% ==Nonlinear latent variable model== %%POSTFIX%%In the nonlinear latent variable*
>%%LINK%%[[#^8gsuly8yl8d|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^8gsuly8yl8d


>%%
>```annotation-json
>{"created":"2024-12-12T13:44:22.279Z","updated":"2024-12-12T13:44:22.279Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":750752,"end":750769},{"type":"TextQuoteSelector","exact":"Deriving the boun","prefix":"e current colored curve).17.3.3 ","suffix":"dWe now use Jensen’s inequality "}]}]}
>```
>%%
>*%%PREFIX%%e current colored curve).17.3.3%%HIGHLIGHT%% ==Deriving the boun== %%POSTFIX%%dWe now use Jensen’s inequality*
>%%LINK%%[[#^m12vsb2dbio|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^m12vsb2dbio


>%%
>```annotation-json
>{"created":"2024-12-12T13:48:24.463Z","updated":"2024-12-12T13:48:24.463Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":756874,"end":756901},{"type":"TextQuoteSelector","exact":"The variational autoencoder","prefix":" variational approximation.17.6 ","suffix":"Finally, we can describe the VAE"}]}]}
>```
>%%
>*%%PREFIX%%variational approximation.17.6%%HIGHLIGHT%% ==The variational autoencoder== %%POSTFIX%%Finally, we can describe the VAE*
>%%LINK%%[[#^wdhyum18nz|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wdhyum18nz


>%%
>```annotation-json
>{"created":"2024-12-12T13:50:06.211Z","updated":"2024-12-12T13:50:06.211Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":758661,"end":758674},{"type":"TextQuoteSelector","exact":"VAE algorithm","prefix":"lity of the latent space.17.6.1 ","suffix":"To summarize, we aim to build a "}]}]}
>```
>%%
>*%%PREFIX%%lity of the latent space.17.6.1%%HIGHLIGHT%% ==VAE algorithm== %%POSTFIX%%To summarize, we aim to build a*
>%%LINK%%[[#^jih5813ekai|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^jih5813ekai


>%%
>```annotation-json
>{"created":"2024-12-12T13:54:55.989Z","updated":"2024-12-12T13:54:55.989Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":761497,"end":761525},{"type":"TextQuoteSelector","exact":"The reparameterization trick","prefix":"e variational distribution.17.7 ","suffix":"There is one more complication; "}]}]}
>```
>%%
>*%%PREFIX%%e variational distribution.17.7%%HIGHLIGHT%% ==The reparameterization trick== %%POSTFIX%%There is one more complication;*
>%%LINK%%[[#^boitynf6yw9|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^boitynf6yw9


>%%
>```annotation-json
>{"created":"2024-12-12T13:58:09.422Z","updated":"2024-12-12T13:58:09.422Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":762517,"end":762549},{"type":"TextQuoteSelector","exact":"Approximating sample probability","prefix":"lications for image data.17.8.1 ","suffix":"In section 17.3, we argued that "}]}]}
>```
>%%
>*%%PREFIX%%lications for image data.17.8.1%%HIGHLIGHT%% ==Approximating sample probability== %%POSTFIX%%In section 17.3, we argued that*
>%%LINK%%[[#^6m98d2m6wka|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^6m98d2m6wka


>%%
>```annotation-json
>{"created":"2024-12-12T14:01:14.626Z","updated":"2024-12-12T14:01:14.626Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":765145,"end":765155},{"type":"TextQuoteSelector","exact":"Generation","prefix":"ibution or are anomalous.17.8.2 ","suffix":"VAEs build a probabilistic model"}]}]}
>```
>%%
>*%%PREFIX%%ibution or are anomalous.17.8.2%%HIGHLIGHT%% ==Generation== %%POSTFIX%%VAEs build a probabilistic model*
>%%LINK%%[[#^h29ji7v2xji|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^h29ji7v2xji


>%%
>```annotation-json
>{"created":"2024-12-12T14:03:29.407Z","updated":"2024-12-12T14:03:29.407Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":766285,"end":766296},{"type":"TextQuoteSelector","exact":"Resynthesis","prefix":"ery high-quality samples.17.8.3 ","suffix":"VAEs can also be used to modify "}]}]}
>```
>%%
>*%%PREFIX%%ery high-quality samples.17.8.3%%HIGHLIGHT%% ==Resynthesis== %%POSTFIX%%VAEs can also be used to modify*
>%%LINK%%[[#^j0z2s1hzqvs|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^j0z2s1hzqvs


>%%
>```annotation-json
>{"created":"2024-12-12T14:05:35.721Z","updated":"2024-12-12T14:05:35.721Z","document":{"title":"understanding_deep_learning.pdf","link":[{"href":"urn:x-pdf:92169c80fb831197e9ad75eb80bb5471"},{"href":"vault:/500 - attachments/understanding_deep_learning.pdf"}],"documentFingerprint":"92169c80fb831197e9ad75eb80bb5471"},"uri":"vault:/500 - attachments/understanding_deep_learning.pdf","target":[{"source":"vault:/500 - attachments/understanding_deep_learning.pdf","selector":[{"type":"TextPositionSelector","start":767656,"end":767671},{"type":"TextQuoteSelector","exact":"Disentanglement","prefix":"nds to the observed data.17.8.4 ","suffix":"In the resynthesis example above"}]}]}
>```
>%%
>*%%PREFIX%%nds to the observed data.17.8.4%%HIGHLIGHT%% ==Disentanglement== %%POSTFIX%%In the resynthesis example above*
>%%LINK%%[[#^yo5iisne3a|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^yo5iisne3a
