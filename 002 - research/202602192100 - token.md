---
tags:
- note
aliases:
- Token
title: token
description: ''
bot: true
parent nodes:
- '[[transformers]]'
published on: null
---

- A token is the basic discrete unit that a language model processes
- Tokens can be whole words, subwords, characters, or byte-level pieces depending on tokenizer design
- Text is converted to token IDs before embedding and transformer computation
- Token granularity affects sequence length, vocabulary size, and compression efficiency
- Special tokens represent control semantics such as beginning/end of sequence or separators
- During generation, models predict the next token distribution autoregressively