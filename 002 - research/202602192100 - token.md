---
tags:
  - nlp
aliases:
  - Token
title: token
description: ""
bot: false
parent nodes:
  - "[[202602061133 - natural language processing|Natural Language Processing]]"
published on:
---

- [ ] What is a tokenizer?

---
- <mark style="background: #ABF7F7A6;">A token is the basic discrete unit that a language model processes</mark>
- Tokens can be:
	- Whole words
	- Subwords
	- Characters
	- Byte-level pieces depending on tokenizer design
- Text is converted to token IDs before [[202602192103 - embedding|embedding]] and [[202602102143 - transformer|transformer]] computation
- Token granularity affects:
	- <mark style="background: #BBFABBA6;">Sequence length</mark>
	- <mark style="background: #FF5582A6;">Vocabulary size</mark>
	- <mark style="background: #FFF3A3A6;">Compression efficiency</mark>
- Special tokens represent control semantics, such as the beginning/end of sequence or separators
- During generation, models predict the next token distribution [[202602050141 - autoregressive|autoregressively]]