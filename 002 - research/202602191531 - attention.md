---
tags:
  - transformers
aliases:
  - Attention
title: attention
description: ""
bot: false
parent nodes:
  - "[[202602102143 - transformer|Transformer]]"
  - "[[attention]]"
published on:
---

- [ ] What is a token?
- [ ] What is a sequence model?

---
- Attention is a mechanism that lets each token weigh information from other tokens based on relevance
- It computes context-aware representations by comparing <mark style="background: #BBFABBA6;">queries</mark> with <mark style="background: #FF5582A6;">keys</mark> and mixing values
- In transformers, self-attention enables direct token-to-token interaction without recurrence
- Multi-head attention runs several attention projections in parallel to capture different relation patterns
- <mark style="background: #D2B3FFA6;">Scaled dot-product attention</mark> uses [[202602111530 - softmax|softmax]]-normalised similarity scores to form weighted sums
- Given input matrices $Q$, $K$, and $V$, the attention output is calculated as:

> [!MATH] Scaled Dot-Product Attention
> $$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$
> 
> **The Components:**
> 1.  **$Q$ (Query)**: "What am I looking for?" (The current word's representation)
> 2.  **$K$ (Key)**: "What do I contain?" (The representation of all other words)
> 3.  **$V$ (Value)**: "What information do I offer?" (The actual content to be extracted)
> 4.  **$d_k$**: The dimension of the keys (used for scaling)

- Attention improves long-range dependency modelling and parallel computation in sequence models


[^1]: [StatQuest - Attention for Neural Networks, Clearly Explained!!!](https://www.youtube.com/watch?v=PSs6nxngL6k&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=19)
[^2]: [Attention in transformers, step-by-step | Deep Learning Chapter 6](https://www.youtube.com/watch?v=eMlx5fFNoYc&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=7)