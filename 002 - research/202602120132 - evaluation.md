---
tags:
  - deep_learning
  - evaluation
aliases:
  - Evaluation
title: evaluation
description: ""
bot: false
parent nodes:
  - "[[202602061150 - deep learning|Deep Learning]]"
published on:
---

- [ ] What is MAE?
- [ ] What is RMSE?
- [ ] What is selection bias?

---
- Evaluation measures how well a [[202602111335 - training|trained]] [[202602010044 - model|model]] performs on data not used for [[202602111314 - model parameters|parameter]] updates
- It <mark style="background: #BBFABBA6;">estimates generalisation quality and supports model comparison and selection</mark>
- Metrics must match the task type, such as [[202602011507 - accuracy|accuracy]]/[[202602011551 - f1|F1]] for [[202602120054 - classification|classification]] and MAE/RMSE for [[202602120056 - regression|regression]]
- Robust evaluation uses held-out validation and test splits to reduce selection bias
- Error analysis by slices and failure cases helps diagnose weakness beyond a single scalar score
- Good evaluation also checks calibration, robustness, and cost-latency trade-offs when relevant