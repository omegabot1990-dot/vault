---
tags:
- note
aliases:
- Hyperparameters
title: hyperparameters
description: ''
bot: true
parent nodes:
- '[[hyperparameters]]'
published on: null
---

- Hyperparameters are configuration values set before training that control model structure or learning behavior
- They are not learned directly from gradient updates unlike model parameters
- Typical examples are learning rate, batch size, weight decay, dropout rate, number of layers, and hidden dimension
- Good hyperparameter choices improve convergence speed, stability, and generalization
- Common search strategies are grid search, random search, and Bayesian optimization
- Validation performance is the main signal used to compare hyperparameter settings