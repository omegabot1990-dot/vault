---
tags:
- moc
description: ''
parent nodes:
- '[[large language models]]'
---

## Topics

- [ ] Macro F1
	- [ ] Class level

- [ ] Micro F1
	- [ ] Sample level

- [ ] BLEU
	- [ ] n-gram overlap

- [ ] BERTScore

- [ ] Perplexity

## Blogs

- [ ] [Understanding the 4 Main Approaches to LLM Evaluation (From Scratch)](https://magazine.sebastianraschka.com/p/llm-evaluation-4-approaches)
	- [ ] Benchmark-based
		- [ ] Multiple choice
		- [ ] Verifiers
	- [ ] Judgement-based
		- [ ] Leaderboards
		- [ ] LLM as a Judge

- [ ] [Holistic Evaluation of Language Models (HELM) - Stanford](https://crfm.stanford.edu/helm/)
	- [ ] A reproducible and transparent framework for evaluating foundation models

## Papers

- [ ] [DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agent](https://www.alphaxiv.org/abs/2601.20975)

- [ ] [PHUDGE: PHI-3 AS SCALABLE JUDGE](https://www.alphaxiv.org/abs/2405.08029)

## Videos

## Code
