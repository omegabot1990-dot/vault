---
tags:
- note
aliases:
- Q-learning
title: q-learning
description: ''
bot: true
parent nodes:
- '[[reinforcement learning]]'
published on: null
---

- Q-learning is an off-policy temporal-difference algorithm for learning optimal action values
- It updates estimates toward a Bellman optimality target using sampled transitions
- The canonical update is:
  - $$Q(s_t,a_t) \leftarrow Q(s_t,a_t) + \alpha \left[r_{t+1} + \gamma \max_{a'} Q(s_{t+1},a') - Q(s_t,a_t)\right]$$
- Action selection is often epsilon-greedy to balance exploration and exploitation
- Q-learning converges in tabular settings under standard assumptions and sufficient exploration
- Deep Q-learning extends the method with neural networks, replay buffers, and target networks