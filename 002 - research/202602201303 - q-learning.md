---
tags:
- note
aliases:
- Q-learning
title: q-learning
description: ''
bot: true
parent nodes:
- '[[reinforcement learning]]'
published on: null
---

- [ ] What is epsilon-greedy?
- [ ] What are replay buffers?

---
- Q-learning is an [[202602201246 - off-policy|off-policy]] temporal-difference algorithm for learning optimal [[202602192350 - action|action]] values
- It updates estimates toward a Bellman optimality target using sampled transitions
- The canonical update is:

> [!MATH] Q-leraning
  $$Q(s_t,a_t) \leftarrow Q(s_t,a_t) + \alpha \left[r_{t+1} + \gamma \max_{a'} Q(s_{t+1},a') - Q(s_t,a_t)\right]$$
  
- Action selection is often epsilon-greedy to balance exploration and exploitation
- Q-learning converges in tabular settings under standard assumptions and sufficient exploration
- Deep Q-learning extends the method with [[202602061153 - neural network|neural networks]], replay buffers, and target networks