---
tags:
- note
aliases:
- Bias
title: bias
description: ''
bot: true
parent nodes:
- '[[neural networks]]'
published on: null
---

- In neural networks, bias is an additive parameter that shifts neuron pre-activation values
- It allows affine transformations instead of purely linear mappings through the origin
- For a layer output, a common form is $y = Wx + b$, where $b$ is the bias vector
- Bias terms increase representational flexibility, especially when inputs are zero-centered
- Bias is learned jointly with weights during backpropagation and gradient-based optimization
- Poorly regularized biases can contribute to overfitting, but they are usually essential for good fit