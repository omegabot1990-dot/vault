---
tags:
  - deep_learning
aliases:
  - Overfitting
title: overfitting
description: ""
parent nodes:
  - "[[202602111335 - training|Training]]"
published on:
---

- [ ] What is early stopping?
- [ ] What is data augmentation?

---
- Overfitting is when a [[202602010044 - model|model]] performs well on [[202602111335 - training|training]] data but does not generalise to unseen data (test data)
- Overfitting happens when a model memorises training-specific patterns
- It is characterised by low training error but higher validation or test error
- Common causes include excessive [[202602111314 - model parameters|model capacity]], weak [[202602111636 - regularization|regularization]], and limited or noisy data
- Signs include a <mark style="background: #BBFABBA6;">widening train-validation gap as training continues</mark>
- Typical mitigations are regularization, early stopping, data augmentation, and increased data quality or quantity
- Overfitting contrasts with [[202602111639 - underfitting|underfitting]], where both training and validation errors remain high