---
tags:
- note
aliases:
- Model-free
title: model-free
description: ''
bot: true
parent nodes:
- '[[reinforcement learning]]'
published on: null
---

- Model-free reinforcement learning learns behavior directly from experience without an explicit dynamics model
- It avoids learning $P(s'\mid s,a)$ and instead estimates value functions, policies, or both
- Classical model-free methods include Q-learning, SARSA, REINFORCE, and PPO-style actor-critic variants
- It is often simpler to deploy but may require more environment interactions than model-based methods
- Experience replay, target networks, and advantage estimation are common stabilizing techniques
- Model-free methods are widely used when accurate environment models are unavailable