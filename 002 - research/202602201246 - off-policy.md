---
tags:
- note
aliases:
- Off-policy
title: off-policy
description: ''
bot: true
parent nodes:
- '[[reinforcement learning]]'
published on: null
---

- Off-policy reinforcement learning learns a target policy from data generated by a different behavior policy
- It enables reuse of past experience and improves sample efficiency via replay buffers or logged trajectories
- Q-learning and many actor-critic variants are off-policy methods
- Distribution mismatch between behavior and target policies can introduce bias or instability
- Importance sampling and conservative update rules are common corrections for off-policy drift
- Off-policy learning is central when interaction is expensive or large offline datasets are available