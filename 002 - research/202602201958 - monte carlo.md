---
tags:
- note
aliases:
- Monte Carlo
title: monte carlo
description: ''
bot: true
parent nodes:
- '[[reinforcement learning]]'
published on: null
---

- Monte Carlo methods estimate values or returns from complete sampled trajectories
- They do not bootstrap from current value estimates, instead using realized episodic outcomes
- A state or action value is updated toward empirical average return from visits
- Monte Carlo estimates are unbiased in expectation but can have high variance
- First-visit and every-visit variants differ by how repeated state occurrences are handled in an episode
- Monte Carlo policy evaluation and control are foundational for understanding temporal-difference methods