---
tags:
- note
aliases:
- Transformer
title: transformer
description: ''
bot: true
parent nodes:
- '[[transformers]]'
published on: null
---

- Transformer is a neural network architecture for sequence modelling built around attention
- Replaces recurrence with parallel token-to-token interactions via self-attention
- Often used as the backbone for modern language models

- Core building blocks
	- Token embeddings plus positional information
	- Self-attention to mix information across positions
	- Feed-forward network applied per token
	- Residual connections and layer normalization for stable training

- Encoder decoder vs decoder only
	- Encoder decoder maps an input sequence to an output sequence
	- Decoder only predicts next tokens autoregressively

- Multi-head attention
	- Runs several attention heads in parallel
	- Lets different heads focus on different relations

- Scaling behaviour
	- Larger models and more data tend to yield better generalization
	- Inference cost scales with sequence length due to attention
