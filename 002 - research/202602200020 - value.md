---
tags:
- note
aliases:
- Value
title: value
description: ''
bot: true
parent nodes:
- '[[reinforcement learning]]'
published on: null
---

- In reinforcement learning, value denotes expected return associated with states or state-action pairs
- State value $V^\pi(s)$ is expected return when starting at state $s$ and following policy $\pi$
- Action value $Q^\pi(s,a)$ is expected return after taking action $a$ in state $s$ then following $\pi$
- Value functions guide policy improvement by scoring long-term consequences of decisions
- Bellman equations relate values recursively through immediate rewards and next-state values
- Value approximation is central in dynamic programming, temporal-difference learning, and actor-critic methods