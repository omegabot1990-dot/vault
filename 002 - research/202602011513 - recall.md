---
tags:
  - evaluation
aliases:
  - Recall
title: recall
description: ""
parent nodes:
  - "[[evaluation]]"
published on:
---

- The <mark style="background: #BBFABBA6;">proportion of actual positives that were correctly identified</mark>
- Also called <mark style="background: #FFF3A3A6;">sensitivity</mark>

> [!MATH] Recall
$$\text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}$$

- <mark style="background: #FF5582A6;">Precision and recall often have an inverse relationship</mark>; increasing one often decreases the other

| Metric        | Focus Question                                   |                 Formula                 | Best Used When...              |
| :------------ | :----------------------------------------------- | :-------------------------------------: | :----------------------------- |
| **Accuracy**  | How often is the model correct overall?          | $\frac{(TP + TN)}{(TP + TN + FP + FN)}$ | Classes are balanced (50/50)   |
| **Precision** | Of all predicted positives, how many were right? |         $\frac{TP}{(TP + FP)}$          | You want to avoid False Alarms |
| **Recall**    | Of all actual positives, how many were caught?   |         $\frac{TP}{(TP + FN)}$          | You want to avoid Missed Cases |
#### Confusion Matrix
$$
\begin{array}{l|c|c}
 & \text{Predicted Positive} & \text{Predicted Negative} \\
\hline
\text{Actual Positive} & \text{TP} & \text{FN} \\
\hline
\text{Actual Negative} & \text{FP} & \text{TN} \\
\end{array}
$$