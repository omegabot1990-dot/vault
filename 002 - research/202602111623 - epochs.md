---
tags:
- note
aliases:
- Epochs
title: epochs
description: ''
bot: true
parent nodes:
- '[[hyperparameters]]'
published on: null
---

- An epoch is one full pass through the entire training dataset
- Number of epochs is a training hyperparameter that sets how many full passes are run
- More epochs usually reduce training loss, but too many can increase overfitting
- Epoch count interacts with dataset size, batch size, and optimizer settings
- Validation metrics are used across epochs to decide early stopping or checkpoint selection
- In mini-batch training, one epoch contains multiple parameter updates