---
tags:
- note
aliases:
- Training
title: training
description: ''
bot: true
parent nodes:
- '[[training]]'
published on: null
---

- Training is the process of fitting model parameters to data by minimizing a loss function
- A training loop repeatedly runs forward pass, loss computation, backpropagation, and parameter updates
- Optimization algorithms like SGD or Adam control how updates are applied
- Validation is used during training to monitor generalization and tune hyperparameters
- Regularization methods like weight decay and dropout help reduce overfitting
- Training stops when convergence criteria or budget limits are reached