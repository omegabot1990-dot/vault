---
tags:
  - training
aliases:
  - Training
title: training
description: ""
bot: false
parent nodes:
  - "[[training]]"
published on:
---

- [ ] What is Adam?

---
- Training is the process of fitting [[202602111314 - model parameters|model parameters]] to data by minimising a [[202602010047 - objective function|loss function]]
- A training loop repeatedly runs <mark style="background: #BBFABBA6;">forward pass</mark>, <mark style="background: #FF5582A6;">loss computation</mark>, backpropagation, and <mark style="background: #FFF3A3A6;">parameter updates</mark>
- [[202602111605 - optimization algorithms|Optimization algorithms]] like [[202602111845 - stochastic gradient descent|Stochastic Gradient Descent (SGD)]] or Adam control how updates are applied
- Validation is used during training to monitor generalisation and tune [[202602111256 - hyperparameters|hyperparameters]]
- [[202602111636 - regularization|Regularization]] methods like [[202602111634 - weight decay|weight decay]] and [[202602111640 - dropout|dropout]] help reduce [[202602010049 - overfitting|overfitting]]
- Training stops when convergence criteria or budget limits are reached