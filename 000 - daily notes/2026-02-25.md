---
tags:
- meta
description: ''
parent nodes:
- '[[research.base]]'
aliases: null
published on: null
---

- Date: 2026-02-25

## Latest papers

- [ ] [TradingAgents: Multi-Agents LLM Financial Trading Framework](https://arxiv.org/abs/2412.20138)
	- Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs)
- [ ] [Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory](https://arxiv.org/abs/2504.19413)
	- Large Language Models (LLMs) have demonstrated remarkable prowess in generating contextually coherent responses, yet their fixed context windows pose fundamental challenges for maintaining consistency over prolonged multi-session dialogues
- [ ] [Adapting Web Agents with Synthetic Supervision](https://arxiv.org/abs/2511.06101)
	- Web agents struggle to adapt to new websites due to the scarcity of environment specific tasks and demonstrations
- [ ] [Efficient Memory Management for Large Language Model Serving with PagedAttention](https://arxiv.org/abs/2309.06180)
	- High throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time

## TLDR top papers

- [ ] 1) TradingAgents: Multi-Agents LLM Financial Trading Framework — https://arxiv.org/abs/2412.20138
- [ ] summary: Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs)
- [ ] 2) Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory — https://arxiv.org/abs/2504.19413
- [ ] summary: Large Language Models (LLMs) have demonstrated remarkable prowess in generating contextually coherent responses, yet their fixed context windows pose fundamental challenges for maintaining consistency over prolonged multi-session dialogues
- [ ] 3) Adapting Web Agents with Synthetic Supervision — https://arxiv.org/abs/2511.06101
- [ ] summary: Web agents struggle to adapt to new websites due to the scarcity of environment specific tasks and demonstrations
- [ ] 4) Efficient Memory Management for Large Language Model Serving with PagedAttention — https://arxiv.org/abs/2309.06180
- [ ] summary: High throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time
