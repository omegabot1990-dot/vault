---
tags:
- meta
description: ''
parent nodes:
- '[[research.base]]'
aliases: null
published on: null
---

- Date: 2026-02-27

## Latest papers

- [ ] [TradingAgents: Multi-Agents LLM Financial Trading Framework](https://arxiv.org/abs/2412.20138)
	- Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs)
- [ ] [Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory](https://arxiv.org/abs/2504.19413)
	- Large Language Models (LLMs) have demonstrated remarkable prowess in generating contextually coherent responses, yet their fixed context windows pose fundamental challenges for maintaining consistency over prolonged multi-session dialogues
- [ ] [PyVision-RL: Forging Open Agentic Vision Models via RL](https://arxiv.org/abs/2602.20739)
	- Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior
- [ ] [Efficient Memory Management for Large Language Model Serving with PagedAttention](https://arxiv.org/abs/2309.06180)
	- High throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time

## TLDR top papers

- [ ] 1) TradingAgents: Multi-Agents LLM Financial Trading Framework — https://arxiv.org/abs/2412.20138
- [ ] summary: Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs)
- [ ] 2) Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory — https://arxiv.org/abs/2504.19413
- [ ] summary: Large Language Models (LLMs) have demonstrated remarkable prowess in generating contextually coherent responses, yet their fixed context windows pose fundamental challenges for maintaining consistency over prolonged multi-session dialogues
- [ ] 3) PyVision-RL: Forging Open Agentic Vision Models via RL — https://arxiv.org/abs/2602.20739
- [ ] summary: Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior
- [ ] 4) Efficient Memory Management for Large Language Model Serving with PagedAttention — https://arxiv.org/abs/2309.06180
- [ ] summary: High throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time
